[{"body":" To meet the requirements of open verification environments, we have developed the Picker tool for converting RTL designs into multi-language interfaces for verification. We will use the environment generated by the Picker tool as the basis for our verification. Next, we will introduce the Picker tool and its basic usage.\nPicker 简介 picker is a chip verification auxiliary tool, aimed at encapsulating RTL design verification modules (.v/.scala/.sv) and exposing Pin-Level operations in other programming languages. Future plans include supporting automated generation of Transaction-Level primitives. Other programming languages supported include c++ (natively supported), python (supported), java (to be improved), and golang (to be improved) programming language interfaces. This tool allows users to perform chip UT verification based on existing software testing frameworks, such as pytest, junit, TestNG, and go test.\nThe advantages of using picker for verification are as follows:\nNo RTL Design Leakage: After conversion by Picker, the original design file (.v) is transformed into a binary file (.so). Even after detaching from the original design file, verification can still be performed, and the verifier cannot obtain the RTL source code. Reduced Compilation Time: When the DUT (Design Under Test) is stable, compilation only needs to be done once (packaged into .so). Broad User Base: Provides multiple programming interfaces, covering developers of different languages (traditional IC verification uses only System Verilog). Rich Software Ecosystem: Can use python3, java, golang, and other ecosystems. Currently, picker supports the following simulators: verilator、synopsys vcs\nWorking Principle of Picker\nThe main function of Picker is to convert Verilog code into C++ or Python code. Taking the processor developed using Chisel as an example: first, use the tools provided by Chisel to convert it into Verilog code, and then use Picker to provide a high-level programming language interface based on the generated C++ or Python code.\nGenerating Python Modules Process of Generating Modules The way Picker exports Python Modules is based on C++.\nPicker is a code generation tool that generates project files first and then compiles them into binary files using make. Picker first uses a simulator to compile the RTL code into a C++ Class and compile it into a dynamic library. (See C++ step details) Based on the Swig tool, using the header file definition generated in the previous step, export the dynamic library as a Python Module. Finally, export the generated module to a directory and clean up or retain other intermediate files as needed. Swig is a tool for exporting C/C++ to other high-level languages. The tool parses C++ header files and generates corresponding intermediate code. For more details about the generation process, please refer to the Swig official documentation. If you want to know how Picker generates C++ classes, please refer to C++.\nThis module is the same as a standard Python module, can be imported and called by other Python programs, and the file structure is no different from a normal Python module. Using Python Modules The parameter --language python or -l python is used to specify the generation of the Python base library. The parameter --example, -e is used to generate an executable file that includes example projects. The parameter --verbose, -v is used to retain intermediate files generated during project generation. Generating Python DUT Classes After entering the compilation command for Picker, a basic class for Python is automatically generated, which we call the DUT class. Taking the previously verified adder as an example, users need to write test cases, i.e., import the Python Module generated in the previous section, and call its methods to operate on the hardware module. The directory structure is as follows: picker_out_adder |-- UT_Adder # Project generated by Picker tool | |-- Adder.fst.hier | |-- _UT_Adder.so | |-- __init__.py | |-- libDPIAdder.a | |-- libUTAdder.so | `-- libUT_Adder.py `-- example.py # Code to be written by the user User writes test cases in Python, importing the generated Python Module and calling its methods to operate on hardware modules. Below is a brief introduction to the methods and attributes of the DUT. # Initialize DUT, DUT() has two parameters: # DUT(waveform_filename=\"report/uftb_with_ftq.fst\", coverage_filename=\"report/uftb_with_ftq_coverage.dat\") # By default, if not specified, it will use the name specified when generating the Python class with Picker, and if the parameters are not specified in the command, the test report and waveform will not be generated dut = DUT() # Access signals, assuming the name of the pin is a dut.a.value = 1 # Equivalent to dut.xdata.a.value # Bind clk to the simulator's clock dut.init_clock(\"clk\") # Equivalent to self.xclock.Add(\"clk\") # Clock advance dut.Step(n) # Equivalent to dut.xclock.Step(n) # Add rising edge callback, parameter is the callback function # Equivalent to dut.xclock.StepRis(...) dut.StepRis(lambda c, x, y: print(\"lambda ris: \", c, x, y), (1, 2)) # Add falling edge callback, parameter is the callback function # Equivalent to dut.xclock.StepFal(...) dut.StepFal(lambda c, x, y: print(\"lambda fal: \", c, x, y), (3, 4)) # Asynchronous method, wait for clock events, the program will continue to execute downwards when the clock event is triggered. dut.astep(n) # Equivalent to await self.xclock.AStep(n) # Asynchronous method, check if conditions are met each time a clock event is triggered, and continue downwards only if the conditions are met. dut.acondition(lambda: dut.signal_1.value == 1) # Equivalent to await dut.xclock.ACondition(lambda: dut.signal_1.value == 1) # Asynchronous method, clock event, each time a clock is driven, the clock event is triggered once, and other coroutines can know that the clock has been driven by listening to the clock event. dut.runstep(n) # Equivalent to dut..xclock.RunStep(n) The DUT class is a directly usable class created after the circuit is encapsulated. To use the DUT class, you first need to initialize it. For synchronous circuits, you also need to connect the clock signal to the analog clock. This allows us to control the circuit by calling the Step method, and access the signal by .value. Next, we will use the adder verified in the previous chapter as an example to explain in detail how to use the generated DUT class. from UT_Adder import * # Import module from python package import random if __name__ == \"__main__\": dut = DUTAdder() # Initialize DUT # dut.init_clock(\"clk\") # If the module has a clock, you need to initialize the clock, bind the clock signal to the simulator's clock, and automatically drive it # reset # dut.reset.value = 1 # dut.Step(1) # This step performs the initialization assignment operation # dut.reset.value = 0 # Remember to reset the original signal after setting! # For example, for the adder, operations on signals dut.a.value = 1 # Assign input signal of dut, need to use .value dut.b.value = 2 dut.cin.value = 0 dut.Step(1) # Update signal print(f\"sum = {dut.sum.value}, cout = {dut.cout.value}\") # Read the output signal of dut, need to use .value # Clear the object and complete the output work of coverage and waveform files (write to file) dut.finalize() We can directly access certain methods through DUT, but most methods are encapsulated in three main data types of DUT class: XData, XPort, and XClock. These types represent different types of signals in the circuit. Through these data types, we can access and manipulate various signals in the circuit for simulation testing. In the following content, we will delve into the definition, source, and usage of these data types in actual simulation. XDATA Generally, there are four states for a circuit: 0, 1, Z, and X. We define a data type named XData, bind it with the pins of the circuit, and read/write the IO interface of the circuit through DPI. This allows us to stimulate the circuit using software. Initialization\n# The initialization steps are automatically completed by Picker. This is just an introduction to the usage # Initialize using XData, parameters are width and data direction (XData.In, XData.Out, XData.InOut) a = XData(32, XData.In) a.ReInit(16, XData.In) # ReInit method can reinitialize the XData instance # Bind DPI, take the adder as an example, parameter is the C function self.a.BindDPIRW(DPIRa, DPIWa) self.b.BindDPIRW(DPIRb, DPIWb) self.cin.BindDPIRW(DPIRcin, DPIWcin) self.sum.BindDPIRW(DPIRsum, DPIWsum) self.cout.BindDPIRW(DPIRcout, DPIWcout) Main methods\n# Using .value for access, there are multiple assignment methods a.value = 12345 # Decimal assignment a.value = 0b11011 # Binary assignment a.value = 0o12345 # Octal assignment a.value = 0x12345 # Hexadecimal assignment a.value = '::ffff' # String assignment in ASCII code d = XData(32,XData.In) # Same type assignment d = a a.value = 0xffffffff # Using with the ctype library a.W(); # Convert to uint32 a.U(); # Convert to uint64 a.S(); # Convert to int64 a.B(); # Convert to bool a.String() # Convert to string # .value supports access using [] by subscript, with the index starting from 0 as the least significant bit a[31] = 0 # a.value = 0x7ffffffff a.value = \"x\" # Assign high impedance state # When outputting high impedance and indeterminate states, use string output # print(f\"expected x, actual {a.String()}\") # a.value = \"000000??\" # 000000?? represents an indeterminate and high impedance state, and when this result appears, the circuit is generally problematic a.value = \"z\" # Assign indeterminate state # a.value = \"000000??\" # Set pin mode: XData.Imme for immediate writing, XData.Rise for rising edge writing, XData.Fall # for falling edge writing. XData defaults to rising edge writing. In immediate write mode, true timing circuits can be simulated without the need for the Step method to directly update values a.SetWriteMode(XData.Imme) XPORT When dealing with a few XData pins, directly manipulating XData is clearer and more intuitive. However, when dealing with multiple XData, batch management is not very convenient. XPort is an encapsulation of XData, which allows us to operate on multiple XData in a centralized manner. We also provide some methods to facilitate batch management. Initialization and adding pins\nport = XPort(\"p\") #Create an instance of XPort Main methods\n# Use the Add method to add pins port.Add(\"a\",a) # Add pin port.Add(\"b\",b) # Add pin # Access pins using [] port[\"b\"] # Using [].value to access the value of the pin port[\"b\"].value = 1 # Connect method to connect two Ports. If both connected ports are InOut types, the data flow direction is Port_2-\u003ePort_1 # If one is In and one is Out, the data flow direction is Out-\u003eIn. The connection should be named as: xx_A Connect yy_A a = XData(32,XData.In) b = XData(32,XData.Out) port_1 = XPort(\"p\") port_2 = XPort(\"p1\") port_1.Add(\"c\",a) port_2.Add(\"c\",b) port_2.Connect(port_1) # Return the number of pins port.PortCount() # Flip method to flip the pin input and output mode port.Flip() # AsBiIo method to change the pin direction to bidirectional a.AsBiIO() # Write all rising edge pins with DPI port.WriteOnRise() # Write all falling edge pins with DPI port.WriteOnFall() # Use ReadFresh to refresh the value of the read pin port.ReadFresh(XData.In) # Use SetZero method to set the value of the pin to 0 port.SetZero() print(f\"expected 0, actual {port['a'].value}\") # port['a'].value = 0 XClock XClock is an encapsulation of the circuit clock, used to drive the circuit. In traditional simulation tools (such as Verilator), you need to manually assign values to clk and update the state through the step_eval function. However, in our tool, we provide corresponding methods that can directly bind the clock to XClock. Just use our Step() method to update both clk and the circuit state at the same time. Initialization and adding pins\n# Initialization clk = XClock(lambda a: 1 if print(\"lambda stp: \", a) else 0) #The stepfunc parameter is the circuit advancement method provided by the DUT backend, such as verilator's step_eval, etc. Main methods\n# Use the Add method to add pins clk.Add(XData) # Add clk pin # In the generated DUT, we automatically generate the init_clock(self,name:str) function, call dut.init_clock(name:str), and can also be bound, for example: dut.init_clock(clk) clk.Add(XPort) # Add Port # Update state clk.Step(1) # Parameter is UInt i, indicating advance i steps # Reset clk.Reset() # Drive the circuit execution without updating the waveform (for combinatorial logic, use with caution) clk.eval() # Drive the circuit execution and update the waveform (not recommended) clk.eval_t() # Add rising edge callback, parameter is callback function clk.StepRis(lambda c, x, y: print(\"lambda ris: \", c, x, y), (1, 2)) # Add falling edge callback, parameter is callback function clk.StepFal(lambda c, x, y: print(\"lambda fal: \", c, x, y), (3, 4)) Although the callback for rising or falling edges can effectively verify, as mentioned earlier, the traditional callback mode, especially when nested multiple layers, can make the code difficult to read and maintain, often referred to as “callback hell”. Therefore, we also provide asynchronous methods for verification, which can simplify the code structure and improve readability.\nAsync \u0026 Event In Python, asynchronous programming is replaced by the asyncio library and the async/await syntax, replacing the traditional callback mode. This approach provides a more intuitive and concise way to handle asynchronous operations, especially when multiple asynchronous operations need to be executed in sequence.\nThe asyncio library introduces coroutines, which are lightweight threads implemented through generators. Coroutines allow concurrent execution within a single Python thread without the need for multithreading or multiprocessing, avoiding the overhead of thread switching and the complexity of inter-process communication. If you want to learn more about the asyncio library, you can refer to the asyncio official documentation.\nUsing the async/await syntax, you can write asynchronous code in a way that is as intuitive as synchronous code. You can use async to define a function as a coroutine, and then use await inside the function to suspend and wait for the completion of an asynchronous operation. This way, when a coroutine is waiting, the event loop can continue to execute other coroutines until the current coroutine can continue to execute. Here’s a brief introduction on how to use asynchronous programming for verification.\nClock Events (Event)\nThe generated Python module provides basic asynchronous functions to facilitate the writing of asynchronous test cases.\nSpecifically, we set a clock event in each Python module generated by Picker, and provide asynchronous interfaces around this event. This clock event can be obtained by accessing the event attribute of each instance, such as dut.event.\nAlso, the event can be obtained from each interface of dut. This is because we define the interface as XPin, which contains the xdata of the interface and the global clock event, so you can get the global clock signal corresponding to the interface by dut.signal_1.event. This helps us to get the global clock signal corresponding to the interface when we can only access one interface.\nUsing Async\nThe clock event mentioned above is the core of the asynchronous function. Here we will introduce how to use the clock event to achieve asynchronous functionality.\nFirst, we need to create a coroutine object and add it to the event loop to drive the global clock. This can be done as follows:\nasyncio.create_task(dut.xclock.RunStep(10)) This will drive the clock 10 times in the “background” without blocking the currently executing code. But how do other coroutines know that the clock has been driven once? This is where the clock event comes in. In the RunStep function, each time the clock is driven, the clock event is triggered, and other coroutines can learn that the clock has been driven by listening to the clock event. For example:\nasync def other_task(): # Loop 10 times for _ in range(10): # Wait for a clock step await dut.xclock.AStep(1) # Print a message after each step print(f\"Clock has been ticked\") dut.xclock.AStep encapsulates waiting for the clock event, and the program will continue to execute after the clock event is triggered. We can also directly use await dut.event.wait() to wait for the clock event directly. Through this asynchronous method, we can create multiple tasks at the same time, each task can wait for the clock event to be triggered, thus achieving the concurrent execution of multiple tasks.\nWe have done the necessary work to ensure that all tasks that can be executed before the next clock event will be executed, and will be blocked by the next clock event.\nHere is a complete example:\nimport asyncio # Create the device instance dut = UT_mydut() # Initialize the device clock dut.init_clock(\"clk\") # Define an asynchronous function to simulate other tasks async def other_task(): for _ in range(10): # Wait for clock stepping await dut.xclock.AStep(1) # Print a message indicating the clock has stepped print(f\"Clock has been ticked\") # Define an asynchronous test function async def my_test(): # Create and start a clock task clock_task = asyncio.create_task(dut.xclock.RunStep(10)) # Create and start other tasks asyncio.create_task(other_task()) # Wait for the clock task to complete await clock_task asyncio.run(my_test()) In addition to RunStep and AStep, we also provide a utility function xclock.ACondition for more complex conditional waits, such as await dut.xclock.ACondition(lambda: dut.signal_1.value == 1). This will check if the condition is met every time a clock event is triggered, and continue execution if it is.\nCustom Asynchronous Events\nIf you need to instantiate several Event or Queue objects for certain functionalities during asynchronous use, you should use the Event and Queue implementations provided in the xspcomm library, rather than using asyncio.Event and asyncio.Queue from the Python standard library. This ensures that all triggerable custom events will be triggered before the next cycle arrives.\nEasier Asynchronous Use\nThe dut provided by Picker only provides basic asynchronous functionality. If you need more convenient asynchronous usage, you can refer to the documentation of the mlvp library, which provides more rich asynchronous interfaces.\n","categories":["Tutorial"],"description":"Basic usage of the verification tool.","excerpt":"Basic usage of the verification tool.","ref":"/mlvp/en/docs/env_usage/picker_usage/","tags":["docs"],"title":"Basic Usage"},{"body":"Callbacks Overview Hardware description languages differ from high-level software programming languages like C++/Python. They have a unique “clock” characteristic. When using picker tools for verification, you may encounter situations where you want to trigger an operation on the rising edge of the clock. To achieve this, you need to use callback functions.\nA callback function is a function that is passed as a parameter. In the C language, callback functions can only be implemented using function pointers. In more modern programming languages like C++, Python, and ECMAScript, you can also use functors or anonymous functions. A callback function is a function or procedure provided by the caller to be used by the callee. The typical usage is:\nMethod a() calls method b() After b() completes, it proactively calls the provided callback() method In the example below, we implement a simple callback. We define a method print_result for printing results, and a method add() for adding two numbers. After add completes, it calls the print_result() method to print the result.\ndef add(x, y): return x + y def sub(x, y): return x - y def mul(x, y): return x * y def div(x, y): return x / y def calc(x, y, func): return func(x, y) # Pass the function as a parameter and then call the function print(calc(1, 2, add)) \u003e\u003e\u003e 3 Advantages of Callback Functions Advantages\nCallback functions help separate code logic, making the code more modular and maintainable. They improve reusability and flexibility: Callback functions allow you to pass one function as a parameter to another function, enabling modular programming and enhancing code reusability and flexibility. Decoupling: Callback functions can decouple relationships between different modules, making the code easier to maintain and extend. Asynchronous execution: Callback functions can be executed after asynchronous operations are completed, avoiding thread blocking and improving application efficiency. For example, in the following example, we define two callback functions addOne and addTwo to generate x+1 and x+2, respectively. We also define an intermediate function to generate reciprocals.\nWe can use an intermediate function to call addOne and addTwo to generate numbers in the form of 1/(x+1) and 1/(x+2). We can also use an anonymous function to generate a number in the form of 1/(x+3). def addOne(x): return x + 1 def addTwo(x): return x + 2 from even import * # Intermediate function # Accepts a callback function as a parameter and returns its reciprocal def getNumber(k, getEvenNumber): return 1 / getEvenNumber(k) if __name__ == \"__main__\": x = 1 # When we need to generate a number in the form of 1/(x+1) print(getNumber(x, addOne)) # When we need a number in the form of 1/(x+2) print(getNumber(x, addTwo)) # When we need a number in the form of 1/(x+3) print(getNumber(x, lambda k: k +3)) Use Cases for Callback Functions Event Handling: Callback functions can handle various events such as mouse clicks, keyboard input, and network requests. Asynchronous Operations: Callback functions can be used for asynchronous operations like reading files, sending emails, and downloading files. Data Processing: Callback functions can process data, such as sorting, filtering, and mapping arrays. Triggering Operations on the Rising Edge of the Clock Using Callback Functions In the test codebelow, we use callback functions to test a random number generator.\nThroughout the test, we verify the random number generator’s results over 114514 clock cycles and count the numbers generated greater than the median and those less than or equal to the median. Verification and data collection occur on the rising edge of the clock.\nTestRandomGenerator is a class for testing the random number generator. Its attributes and methods include:\nself.dut is an instance of DUTRandomGenerator used for testing. self.ref is an instance of LFSR_16 used for result verification. callback1(self, clk) verifies the random number generator on the rising edge of the clock. callback2(self, clk) counts the distribution of generated random numbers, also on the rising edge of the clock. test_rg(self, callback3) method executes the entire test process and calls the callback3 function at the end. The DUT class generated by Picker includes a clock source self.xclock, as does DUTRandomGenerator.\nBefore testing, connect the clk pin of the module under test to the clock source using the pre-packaged method in dut:\nself.dut.init_clock(\"clk\") # Equivalent to self.xclock.Add(self.port[\"clk\"]) Then reset the generator and initialize the values:\nself.dut.reset.value = 1 self.dut.Step(1) # Wait one clock cycle, the next cycle will set dut's output to 0 self.dut.reset.value = 0 # Remember to reset the original signal after setting! After initialization, add the callback functions triggered on the rising edge of the clock for verification and statistics:\nself.dut.StepRis(self.callback1) # Add the callback function triggered on the rising edge of the clock self.dut.StepRis(self.callback2) # Multiple callbacks can be added Then wait for 114514 clock cycles, during which each rising edge verifies the result and counts the random number distribution:\nself.dut.Step(114514) Finally, complete the process and call median_distribution_stats to output the random number distribution:\nself.dut.finalize() callback3(self.greater, self.less_equal, self.MEDIAN) The test is now complete.\nRandom Number Generator Test Code from UT_RandomGenerator import * import random def median_distribution_stats(gt, le, mid) -\u003e None: # Output the count of numbers greater than and less than or equal to the median. print(f\"There are {gt} numbers \u003e {mid} and {le} numbers \u003c= {mid}\") # 16-bit Linear Feedback Shift Register Simulation Class class LFSR_16: def __init__(self, seed): self.state = seed \u0026 ((1 \u003c\u003c 16) - 1) def step(self): new_bit = (self.state \u003e\u003e 15) ^ (self.state \u003e\u003e 14) \u0026 1 self.state = ((self.state \u003c\u003c 1) | new_bit) \u0026 ((1 \u003c\u003c 16) - 1) class TestRandomGenerator: def __init__(self) -\u003e None: self.MEDIAN = 2**15 self.SEED = random.randint(0, 2**16 - 1) self.greater = 0 self.less_equal = 0 self.ref = LFSR_16(self.SEED) self.dut = DUTRandomGenerator() def test_rg(self, callback3) -\u003e None: # Connect the clk pin to the clock source self.dut.init_clock(\"clk\") self.dut.seed.value = self.SEED # Reset operation self.dut.reset.value = 1 self.dut.Step(1) # Wait one clock cycle, the next cycle will set dut's output to 0 self.dut.reset.value = 0 # Remember to reset the original signal after setting! # Set the callback functions self.dut.StepRis(self.callback1) # Add the callback function triggered on the rising edge of the clock self.dut.StepRis(self.callback2) # Multiple callbacks can be added # Test, start! self.dut.Step(114514) # Wait for 114514 clock cycles # End self.dut.finalize() callback3(self.greater, self.less_equal, self.MEDIAN) pass def callback1(self, clk): # Verify if the result matches the expectation assert self.dut.random_number.value == self.ref.state, \"Mismatch\" print( f\"Cycle {clk}, DUT: {self.dut.random_number.value:x},\" + f\" REF: {self.ref.state:x}\" ) self.ref.step() def callback2(self, clk): # Count the distribution of generated random numbers greater than and less than or equal to the median if self.dut.random_number.value \u003e self.MEDIAN: self.greater += 1 else: self.less_equal += 1 if __name__ == \"__main__\": TestRandomGenerator().test_rg(median_distribution_stats) pass Adding Callback Functions When Verifying the Adder Define a 32-bit adder RisAdder that updates its output only on the rising edge of the clock. The RTL code is:\nmodule RisAdder #( parameter WIDTH = 32 ) ( input clk, input [WIDTH-1:0] a, input [WIDTH-1:0] b, input cin, output [WIDTH-1:0] sum, output cout ); reg Cout; reg [WIDTH-1:0] Sum; always @(posedge clk) begin {Cout, Sum} \u003c= a + b + cin; end assign {cout, sum} = {Cout, Sum}; endmodule In the following test code, we will use a callback function in the adder test.\nBefore the test begins, create an instance dut of the DUTRisAdder class and an instance ref of the SimpleRisAdder class. The ref object simulates the expected behavior of the adder as a reference adder.\nThe DUT class generated by Picker will include a clock source self.xclock for the driving circuit, and DUTRisAdder is no exception.\nBefore the test starts, connect the clk pin of the device under test to the clock source:\ndut.init_clock(\"clk\") # Equivalent to self.xclock.Add(self.port[name]) Set the input of the adder to 0 so that its output will be 0 in the next cycle:\ndut.a.value = 0 dut.b.value = 0 dut.cin.value = 0 dut.Step(1) # Wait for the clock to enter the next cycle Next, add a callback function test_adder(clk: int, dut: DUTRisAdder, ref: SimpleRisAdder) -\u003e None, and pass the dut and ref objects to test_adder:\n# Test function to verify the correctness of the adder output def test_adder(clk: int, dut: DUTRisAdder, ref: SimpleRisAdder) -\u003e None: # Get the inputs and outputs of the adder a = dut.a.value b = dut.b.value cin = dut.cin.value cout = dut.cout.value sum = dut.sum.value # Check if the output of the adder matches the expected result isEqual = (cout, sum) == (ref.cout, ref.sum) # Print test results print(f\"Cycle: {clk}, Input(a, b, cin) = ({a:x}, {b:x}, {cin:x})\") print( FONT_GREEN + \"Pass.\" # Print \"Pass.\" in green if the test passes if isEqual else FONT_RED + f\"MisMatch! Expect cout: {ref.cout:x}, sum: {ref.sum:x}.\" + FONT_COLOR_RESET + f\"Get cout: {cout:x}, sum: {sum:x}.\" ) assert isEqual # Trigger an assertion error if the test fails if __name__ == \"__main__\": ... dut.StepRis(test_adder, (dut, ref)) # Add a callback function triggered on the rising edge of the clock, passing the dut and ref objects to the callback function ... The test_adder function will compare the outputs of dut and ref at the rising edge of the clock to verify if the RTL code implementation meets our expectations.\nFinally, the test will run for 114,514 cycles, with each test data signal lasting for one cycle:\n# Test for 114,514 cycles for _ in range(114514): a = random.randint(0, (1\u003c\u003cWIDTH) - 1) b = random.randint(0, (1\u003c\u003cWIDTH) - 1) cin = random.randint(0, 1) dut.a.value = a dut.b.value = b dut.cin.value = cin ref.step(a, b, cin) # Update the reference adder's state dut.Step(1) # Wait for the clock to enter the next cycle dut.finalize() Code for Adder Updated on Rising Edge from UT_RisAdder import * import random # Font color control FONT_GREEN = \"\\033[0;32m\" FONT_RED = \"\\033[0;31m\" FONT_COLOR_RESET = \"\\033[0m\" class SimpleRisAdder: \"\"\" SimpleRisAdder class acts as a reference adder, simulating the expected behavior of our RisAdder \"\"\" def __init__(self, width) -\u003e None: self.WIDTH = width # Adder width # Port definitions self.a = 0 # Input port a self.b = 0 # Input port b self.cin = 0 # Input port cin self.cout = 0 # Output port cout self.sum = 0 # Output port sum def step(self, a, b, cin): \"\"\" Simulate the output update on the rising edge: first update the output with the input from the last cycle, then update the input \"\"\" sum = self.a + self.b + self.cin self.cout = sum \u003e\u003e self.WIDTH # Calculate carry-out self.sum = sum \u0026 ((1 \u003c\u003c self.WIDTH) - 1) # Calculate sum self.a = a # Update input a self.b = b # Update input b self.cin = cin # Update input cin # Test function to verify if the adder's output is correct def test_adder(clk: int, dut: DUTRisAdder, ref: SimpleRisAdder) -\u003e None: # Get adder inputs and outputs a = dut.a.value b = dut.b.value cin = dut.cin.value cout = dut.cout.value sum = dut.sum.value # Verify if the output meets expectations isEqual = (cout, sum) == (ref.cout, ref.sum) # Output test result print(f\"Cycle: {clk}, Input(a, b, cin) = ({a:x}, {b:x}, {cin:x})\") print( FONT_GREEN + \"Pass.\" if isEqual else FONT_RED + f\"MisMatch! Expect cout: {ref.cout:x}, sum: {ref.sum:x}.\", FONT_COLOR_RESET + f\"Get cout: {cout:x}, sum: {sum:x}.\", ) assert isEqual # Trigger an assertion error if the test fails if __name__ == \"__main__\": WIDTH = 32 # Set adder width ref = SimpleRisAdder(WIDTH) # Create a reference adder dut = DUTRisAdder() # Create the adder under test # Bind clock signal dut.init_clock(\"clk\") # Equivalent to self.xclock.Add(self.port[name]) # Initialize dut input signals to 0 dut.a.value = 0 dut.b.value = 0 dut.cin.value = 0 dut.Step(1) # Wait for the clock to enter the next cycle dut.StepRis(test_adder, (dut, ref)) # Add a callback function triggered on the rising edge of the clock, passing dut and ref to the callback # Test for 114,514 cycles for _ in range(114514): # Generate random inputs a = random.randint(0, (1\u003c\u003cWIDTH) - 1) b = random.randint(0, (1\u003c\u003cWIDTH) - 1) cin = random.randint(0, 1) ref.step(a, b, cin) # Update the reference adder's state dut.a.value = a # Set input a of the adder under test dut.b.value = b # Set input b of the adder under test dut.cin.value = cin # Set input cin of the adder under test dut.Step(1) # Wait for the clock to enter the next cycle dut.finalize() pass Eventloop Overview **Event Loop：**The event loop mechanism is a programming model that allows a program to wait for events (such as input, timers, network events) to occur in a non-blocking manner. It is used to wait for and distribute messages and events, running in a single-threaded way without blocking. The core of the event loop mechanism is the event loop itself, where the program continuously polls the event queue for pending events and executes corresponding callback functions to handle them. The program can achieve asynchronous, non-blocking programming, improving responsiveness and efficiency.\nBasic Principles The workflow of an event loop typically follows these steps:\nStart the program and execute synchronous code until asynchronous code is encountered. Place the callback functions of asynchronous code into the event queue to be executed when the event occurs. After all synchronous code has been executed, start the event loop and continuously check for events. If the event queue is not empty, execute the associated callback functions. Return to step 4 and continue looping to handle events. In pseudo-code form: while(1) { events = getEvents(); for (e in events) processEvent(e); } Event Loop in Python The asyncio module in Python provides the following methods to manage the event loop:\nloop = get_event_loop(): Get the current event loop. asyncio.set_event_loop(): Set the event loop for the current context. asyncio.new_event_loop(): Create a new event loop based on this policy and return it. loop.call_at(): Run at a specified time. loop.call_later(delay, callback, arg): Execute the callback method after a delay of delay seconds. loop.call_soon(callback, argument): Call the callback method as soon as possible; after the call to call_soon() ends and the main thread returns to the event loop, callback will be called immediately. loop.time(): Return the internal time of the current event loop. loop.run_forever(): Run until stop() is called. In the following example, we define a callback method to print the parameters and the internal time of the loop to observe the order of function definition and execution:\nIn the main method, first, we get the current event loop loop and the current time. Then, we call the callback method in order, setting different start times for execution. import asyncio def callback(a, loop): print(\"My parameter is {0}，executed at time {1}\".format(a,loop.time())) if __name__ == \"__main__\": try: loop = asyncio.get_event_loop() now = loop.time() loop.call_later(5, callback, 5, loop) loop.call_at(now+2, callback, 2, loop) loop.call_at(now+1, callback, 1, loop) loop.call_at(now+3, callback, 3, loop) loop.call_soon(callback, 4, loop) loop.run_forever() #Use this to run run_forever except KeyboardInterrupt: print(\"Goodbye!\") The output will be:\nMy parameter is 4, executed at time 266419.843 My parameter is 1, executed at time 266420.843 My parameter is 2, executed at time 266421.859 My parameter is 3, executed at time 266422.859 My parameter is 5, executed at time 266424.843 Drawbacks of Callback Functions and Event Loop Despite the advantages, callback functions have some drawbacks, leading to the introduction of the asynchronous concept in the next section. Drawbacks include:\nExcessive Nesting: Too many nested callback functions make the code difficult to maintain. Race Conditions: If there are shared resources accessed within the callback functions, race conditions can easily occur, causing program errors. Poor Readability: The use of callback functions may disrupt the structure and readability of the code, especially when handling large amounts of data. ","categories":["Sample Projects","Tutorials"],"description":"Using Callbacks to Handle Circuit Events","excerpt":"Using Callbacks to Handle Circuit Events","ref":"/mlvp/en/docs/advance_func/callback/","tags":["examples","docs"],"title":"Callback Functions"},{"body":" This page provides a brief introduction to chip verification, including concepts used in examples such as DUT (Design Under Test) and RM (Reference Model).\nThe chip verification process needs to align with the actual situation of the company or team. There is no absolute standard that meets all requirements and must be referenced.\nWhat is Chip Verification? The chip design-to-production process involves three main stages: chip design, chip manufacturing, and chip packaging/testing. Chip design is further divided into front-end and back-end design. Front-end design, also known as logic design, aims to achieve the desired circuit logic functionality. Back-end design, or physical design, focuses on optimizing layout and routing to reduce chip area, lower power consumption, and increase frequency. Chip verification is a critical step in the chip design process. Its goal is to ensure that the designed chip meets the specified requirements in terms of functionality, performance, and power consumption. The verification process typically includes functional verification, timing verification, and power verification, using methods and tools such as simulation, formal verification, hardware acceleration, and prototyping. For this tutorial, chip verification refers only to the verification of the front-end design to ensure that the circuit logic meets the specified requirements (“Does this proposed design do what is intended?”), commonly known as functional verification. This does not include back-end design aspects like power and frequency.\nFor chip products, design errors that make it to production can be extremely costly to fix, as it might require recalling products and remanufacturing chips, incurring significant financial and time costs. Here are some classic examples of failures due to inadequate chip verification: Intel Pentium FDIV Bug：In 1994, Intel’s Pentium processor was found to have a severe division error known as the FDIV bug. This error was due to incorrect entries in a lookup table within the chip’s floating-point unit. Although it rarely affected most applications, it caused incorrect results in specific calculations. Intel had to recall a large number of processors, leading to significant financial losses.\nAriane 5 Rocket Failure：Though not a chip example, this highlights the importance of hardware verification. In 1996, the European Space Agency’s Ariane 5 rocket exploded shortly after launch due to an overflow when converting a 64-bit floating-point number to a 16-bit integer in the navigation system, causing the system to crash. This error went undetected during design and led to the rocket’s failure.\nAMD Barcelona Bug：In 2007, AMD’s Barcelona processor had a severe Translation Lookaside Buffer (TLB) error that could cause system crashes or reboots. AMD had to mitigate this by lowering the processor’s frequency and releasing BIOS updates, which negatively impacted their reputation and financial status.\nThese cases emphasize the importance of chip verification. Errors detected and fixed during the design phase can prevent these costly failures. Insufficient verification continues to cause issues today, such as a new entrant in the ASIC chip market rushing a 55nm chip without proper verification, leading to three failed tape-outs and approximately $500,000 in losses per failure.\nChip Verification Process The coupling relationship between chip design and verification is shown in the diagram above. Both design and verification have the same input: the specification document. Based on this document, both design and verification teams independently code according to their understanding and requirements. The design team needs to ensure that the RTL code is “synthesizable,” considering circuit characteristics, while the verification team mainly focuses on whether the functionality meets the requirements, with fewer coding constraints. After both teams complete module development, a sanity test is conducted to check if the functionality matches. If there are discrepancies, collaborative debugging is done to identify and fix issues before retesting. Due to the high coupling between chip design and verification, some companies directly couple their design and verification teams, assigning verification teams to each design submodule. The coupling process in the diagram is coarse-grained, with specific chips (e.g., SoC, DDR) and companies having their cooperation models.\nIn the above comparison test, the module produced by the design team is usually called DUT (Design Under Test), while the model developed by the verification team is called RM (Reference Model). The verification process includes: writing a verification plan, creating a verification platform, organizing functional points, constructing test cases, running and debugging, collecting bugs/coverage, regression testing, and writing test reports.\nVerification Plan： The verification plan describes how verification will be carried out and how verification quality will be ensured to meet functional verification requirements. It typically includes verification goals, strategies, environment, items, process, risk mitigation, resources, schedule, results, and reports. Verification goals specify the functions or performance metrics to be verified, directly extracted from the chip specification. Verification strategy outlines the methods to be used, such as simulation, formal verification, FPGA acceleration, etc., and how to organize the verification tasks. The verification environment details the specific testing environment, including verification tools and versions. The verification item library lists specific items to be verified and expected results. Verification plans can be general or specific to sub-tasks.\nPlatform Setup： The verification platform is the execution environment for specific verification tasks. Similar verification tasks can use the same platform. Setting up the platform is a key step, including choosing verification tools (e.g., software simulation, formal verification, hardware acceleration), configuring the environment (e.g., server, FPGA), creating the test environment, and basic test cases. Initial basic test cases are often called “smoke tests.” Subsequent test codes are based on this platform, so it must be reusable. The platform includes the test framework, the code being tested, and basic signal stimuli.\nOrganizing Functional Points： This involves listing the DUT’s basic functions based on the specification manual and detailing how to test each function. Functional points are prioritized based on importance, risk, and complexity. They also need to be tracked for status, with updates synchronized to the plan if changes occur.\nTest Cases These are conditions or variables used to determine if the DUT meets specific requirements and operates correctly. Each case includes test conditions, input data, expected results, actual results, and test outcomes. Running test cases and comparing expected vs. actual results help verify the system or application’s correct implementation of functions or requirements. Test cases are crucial tools for verifying chip design against specifications.\nCoding Implementation： This is the execution of test cases, including generating test data, selecting the test framework, programming language, and writing the reference model. This phase requires a deep understanding of functional points and test cases. Misunderstandings can lead to the DUT being undrivable or undetected bugs.\nCollecting Bugs/Coverage： The goal of verification is to find design bugs early, so collected bugs need unique identifiers, severity ratings, and status tracking with design engineers. Discovering bugs is ideal, but since not every test finds bugs, coverage is another metric to evaluate verification thoroughness. Sufficient verification is indicated when coverage (e.g., code coverage \u003e90%) exceeds a threshold.\nRegression Testing： As verification and design are iterative, regression tests ensure the modified DUT still functions correctly after bug fixes. This catches new errors or reactivates old ones due to changes. Regression tests can be comprehensive or selective, covering all functions or specific parts.\nTest Report： This summarizes the entire verification process, providing a comprehensive view of the testing activities, including objectives, executed test cases, discovered issues, coverage, and efficiency.\nLevels of Chip Verification Chip verification typically includes four levels based on the object size: UT, BT, IT, and ST.\nUnit Testing（UT）： The lowest verification level, focusing on single modules or components to ensure their functionality is correct.\nBlock Testing (BT) ： Modules often have tight coupling, making isolated UT testing complex. BT merges several coupled modules into one DUT block for testing.\nIntegration Testing (IT) ： Builds on UT by combining multiple modules or components to verify their collaborative functionality, usually testing subsystem functionality.\nSystem Testing (ST) ： Also called Top verification, ST combines all modules or components into a complete system to verify overall functionality and performance requirements.\nIn theory, these levels follow a bottom-up order, each building on the previous level. However, practical verification activities depend on the scale, expertise, and functional needs of the enterprise, so not all levels are always involved. At each level, relevant test cases are written, tests run, and results analyzed to ensure the chip design’s correctness and quality.\nChip Verification Metrics Verification metrics typically include functional correctness, test coverage, defect density, verification efficiency, and verification cost. Functional correctness is the fundamental metric, ensuring the chip executes its designed functions correctly. This is validated through functional test cases, including normal and robustness tests. Test coverage indicates the extent to which test cases cover design functionality, with higher coverage implying higher verification quality. Coverage can be further divided into code coverage, functional coverage, condition coverage, etc. Defect density measures the number of defects found in a given design scale or code volume, with lower density indicating higher design quality. Verification efficiency measures the amount of verification work completed within a given time and resource frame, with higher efficiency indicating higher productivity. Verification cost encompasses all resources required for verification, including manpower, equipment, and time, with lower costs indicating higher cost-effectiveness.\nFunctional correctness is the absolute benchmark for verification. However, in practice, it is often impossible to determine if the test plan is comprehensive and if all test spaces have been adequately covered. Therefore, a quantifiable metric is needed to guide whether verification is sufficient and when it can be concluded. This metric is commonly referred to as “test coverage.” Test coverage typically includes code coverage (lines, functions, branches) and functional coverage.\nCode Line Coverage： This indicates how many lines of the DUT design code were executed during testing.\nFunction Coverage： This indicates how many functions of the DUT design code were executed during testing.\nBranch Coverage： This indicates how many branches (if-else) of the DUT design code were executed during testing.\nFunctional Coverage： This indicates how many predefined functions were triggered during testing.\nHigh code coverage can improve the quality and reliability of verification but does not guarantee complete correctness since it cannot cover all input and state combinations. Therefore, in addition to pursuing high code coverage, other testing methods and metrics, such as functional testing, performance testing, and defect density, should be combined.\nChip Verification Management Chip verification management is a comprehensive process that encompasses all activities in the chip verification process, including the development of verification strategies, the setup of the verification environment, the writing and execution of test cases, the collection and analysis of results, and the tracking and resolution of issues and defects. The goal of chip verification management is to ensure that the chip design meets all functional and performance requirements, as well as specifications and standards.\nIn chip verification management, the first step is to formulate a detailed verification strategy, including objectives, scope, methods, and schedules. Then, a suitable verification environment must be set up, including hardware, software tools, and test data. Next, a series of test cases covering all functional and performance points must be written and executed, with results collected and analyzed to identify problems and defects. Finally, these issues and defects need to be tracked and fixed until all test cases pass.\nChip verification management is a complex process requiring a variety of skills and knowledge, including chip design, testing methods, and project management. It requires close collaboration with other activities, such as chip design, production, and sales, to ensure the quality and performance of the chip. The effectiveness of chip verification management directly impacts the success of the chip and the company’s competitiveness. Therefore, chip verification management is a crucial part of the chip development process.\nThe chip verification management process can be based on a “project management platform” and a “bug management platform,” with platform-based management typically being significantly more efficient than manual management.\nCurrent State of Chip Verification Currently, chip verification is typically completed within chip design companies. This process is not only technically complex but also entails significant costs. Given the close relationship between acceptance and design, chip verification inevitably involves the source code of the chip design. However, chip design companies usually consider the source code as a trade secret, necessitating internal personnel to perform the verification, making outsourcing difficult.\nThe importance of chip verification lies in ensuring that the designed chip operates reliably under various conditions. Verification is not only for meeting technical specifications but also for addressing the growing complexity and emerging technology demands. As the semiconductor industry evolves, the workload of chip verification has been continuously increasing, especially for complex chips, where verification work has exceeded design work, accounting for more than 70%. This means that in terms of engineer personnel ratio, verification engineers are usually twice the number of design engineers (e.g., in a team of three thousand at Zeku, there are about one thousand design engineers and two thousand verification engineers. Similar or higher ratios apply to other large chip design companies).\nDue to the specificity of verification work, which requires access to the chip design source code, it significantly limits the possibility of outsourcing chip verification. The source code is considered the company’s core trade secret, involving technical details and innovations, thus making it legally and securely unfeasible to share with external parties. Consequently, internal personnel must shoulder the verification work, increasing the internal workload and costs.\nGiven the current situation, the demand for chip verification engineers continues to grow. They need a solid technical background, familiarity with various verification tools and methods, and keen insight into emerging technologies. Due to the complexity of verification work, verification teams typically need a large scale, contrasting sharply with the design team size.\nTo meet this challenge, the industry may need to continuously explore innovative verification methods and tools to improve efficiency and reduce costs.\nSummary: Complex Chip Verification Costs High Verification Workload： For complex chips, verification work accounts for over 70% of the entire chip design work.\nHigh Labor Costs： The number of verification engineers is twice that of design engineers, with complex tasks requiring thousands of engineers.\nInternal Verification： To ensure trade secrets (chip design code) are not leaked, chip design companies can only hire a large number of verification engineers to perform verification work internally.\nCrowdsourcing Chip Verification In contrast to hardware, the software field has already made testing outsourcing (subcontracting) a norm to reduce testing costs. This business is highly mature, with a market size in the billions of yuan, advancing towards the trillion-yuan scale. From the content perspective, software testing and hardware verification share significant similarities (different targets with the same system objective). Is it feasible to subcontract hardware verification in the same way as software?\nCrowdsourcing chip verification faces many challenges, such as: Small Number of Practitioners： Compared to the software field, the number of hardware developers is several orders of magnitude smaller. For instance, according to GitHub statistics (https://madnight.github.io/githut/#/pull_requests/2023/2), traditional software programming languages (Python, Java, C++, Go) account for nearly 50%, whereas hardware description languages like Verilog account for only 0.076%, reflecting the disparity in developer numbers.\nCommercial Verification Tools： The verification tools used in enterprises (simulators, formal verification, data analysis) are almost all commercial tools, which are nearly invisible to ordinary people and difficult to self-learn.\nLack of Open Learning Materials： Chip verification involves accessing the chip design source code, which is typically regarded as the company’s trade secrets and proprietary technology. Chip design companies may be unwilling to disclose detailed verification processes and techniques, limiting the availability of learning materials.\nFeasibility Analysis Although the chip verification field has been relatively closed, from a technical perspective, adopting a subcontracting approach for verification is a feasible option due to several factors:\nFirstly, with the gradual increase of open-source chip projects, the source code involved in verification has become more open and transparent. These open-source projects do not have concerns about trade secrets in their design and verification process, providing more possibilities for learning and research. Even if some projects involve trade secrets, encryption and other methods can be used to hide design codes, addressing trade secret issues to a certain extent and making verification easier to achieve.\nSecondly, many fundamental verification tools have emerged in the chip verification field, such as Verilator and SystemC. These tools provide robust support for verification engineers, helping them perform verification work more efficiently. These tools alleviate some of the complexity and difficulty of the verification process, providing a more feasible technical foundation for adopting subcontracted verification methods.\nIn the open-source software field, some successful cases can be referenced. For example, the Linux kernel verification process adopts a subcontracting approach, with different developers and teams responsible for verifying different modules, ultimately forming a complete system. Similarly, in the machine learning field, the ImageNet project adopted a crowdsourced annotation strategy, completing large-scale image annotation tasks through crowdsourcing. These cases provide successful experiences for the chip verification field, proving the potential of subcontracted verification to improve efficiency and reduce costs.\nTherefore, despite the chip verification field being relatively closed compared to other technical fields, technological advances and the increase of open-source projects offer new possibilities for adopting subcontracted verification. By drawing on successful experiences from other fields and utilizing existing verification tools, we can promote the application of more open and efficient verification methods in chip verification, further advancing the industry. This openness and flexibility in technology will provide more choices for verification engineers, promoting innovative and diverse development in the chip verification field.\nTechnical Route To overcome challenges and engage more people in chip verification, this project continuously attempts the following technical directions:\nProvide Multi-language Verification Tools： Traditional chip verification is based on the System Verilog programming language, which has a small user base. To allow other software development/testing professionals to participate in chip verification, this project provides multi-language verification conversion tools Picker, enabling verifiers to use familiar programming languages (e.g., C++, Python, Java, Go) with open-source verification tools.\nProvide Verification Learning Materials： The scarcity of chip verification learning materials is mainly due to the improbability of commercial companies disclosing internal data. Therefore, this project will continuously update learning materials, allowing verifiers to learn the necessary skills online for free.\nProvide Real Chip Verification Cases： To make the learning materials more practical, this project uses the “Xiangshan Kunming Lake (an industrial-grade high-performance RISC-V processor) IP core” as a basis, continuously updating verification cases by extracting modules from it.\nOrganize Chip Design Subcontracted Verification： Applying what is learned is the goal of every learner. Therefore, this project periodically organizes subcontracted chip design verification, allowing everyone (whether you are a university student, verification expert, software developer, tester, or high school student) to participate in real chip design work.\nThe goal of this project is to achieve the following vision: “Open the black box of traditional verification modes, allowing anyone interested to participate in chip verification anytime, anywhere, using their preferred programming language.”\n","categories":"","description":"Basic concepts of chip verification\n","excerpt":"Basic concepts of chip verification\n","ref":"/mlvp/en/docs/basic/ic_verify/","tags":"","title":"Chip Verification"},{"body":"Verification Report https://github.com/yzcccccccccc/XS-MLVP-NutShellCache/blob/master/report/nutshell_cache_report_demo.pdf\nVerification Environment \u0026 Test Case Code https://github.com/yzcccccccccc/XS-MLVP-NutShellCache\n","categories":["Example Projects","Tutorials"],"description":"Verification of Nutshell Cache using Python.","excerpt":"Verification of Nutshell Cache using Python.","ref":"/mlvp/en/docs/advance_case/nutshellcache/","tags":["examples","docs"],"title":"Complete Verification of Nutshell Cache"},{"body":" This page will briefly introduce what verification is, as well as concepts used in the examples, such as DUT (Design Under Test) and RM (Reference Model).\nChip Verification Chip verification is a crucial step to ensure the correctness and reliability of chip designs, including functional verification, formal verification, and physical verification. This material only covers functional verification, focusing on simulation-based chip functional verification. The processes and methods of chip functional verification have many similarities with software testing, such as unit testing, system testing, black-box testing, and white-box testing. They also share similar metrics, such as functional coverage and code coverage. In essence, apart from the different tools and programming languages used, their goals and processes are almost identical. Thus, software test engineers should be able to perform chip verification without considering the tools and programming languages. However, in practice, software testing and chip verification are two completely separate fields, primarily due to the different verification tools and languages, making it difficult for software test engineers to crossover. In chip verification, hardware description languages (e.g., Verilog or SystemVerilog) and specialized commercial tools for circuit simulation are commonly used. Hardware description languages differ from high-level software programming languages like C++/Python, featuring a unique “clock” characteristic, which poses a high learning curve for software engineers.\nTo bridge the gap between chip verification and traditional software testing, allowing more people to participate in chip verification, this project provides the following content:\nMulti-language verification tools (Picker), allowing users to use their preferred programming language for chip verification. Verification framework (MLVP), enabling functional verification without worrying about the clock.\nIntroduction to basic circuits and verification knowledge, helping software enthusiasts understand circuit characteristics more easily.\nBasic learning materials for fundamental verification knowledge.\nReal high-performance chip verification cases, allowing enthusiasts to participate in verification work remotely.\nBasic Terms DUT: Design Under Test, usually referring to the designed RTL code.\nRM: Reference Model, a standard error-free model corresponding to the unit under test.\nRTL: Register Transfer Level, typically referring to the Verilog or VHDL code corresponding to the chip design.\nCoverage: The percentage of the test range relative to the entire requirement range. In chip verification, this typically includes line coverage, function coverage, and functional coverage.\nDV: Design Verification, referring to the collaboration of design and verification.\nDifferential Testing (difftest): Selecting two (or more) functionally identical units under test, submitting the same test cases that meet the unit’s requirements to observe whether there are differences in the execution results.\nTool Introduction The core tool used in this material is Picker（https://github.com/XS-MLVP/picker）. Its purpose is to automatically provide high-level programming language interfaces (Python/C++) for RTL-written design modules. Based on this tool, verification personnel with a software development (testing) background can perform chip verification without learning hardware description languages like Verilog/VHDL.\nSystem Requirements Recommended operating system: Ubuntu 22.04 LTS\nIn the development and research of system architecture, Linux is the most commonly used platform, mainly because Linux has a rich set of software and tool resources. Due to its open-source nature, important tools and software (such as Verilator) can be easily developed for Linux. In this course, multi-language verification tools like Picker and Swig can run stably on Linux. ","categories":["Sample Projects","Tutorials"],"description":"How to use the open verification platform to participate in hardware verification.","excerpt":"How to use the open verification platform to participate in hardware …","ref":"/mlvp/en/docs/quick-start/","tags":["examples","docs"],"title":"Quick Start"},{"body":"Source Installation of Picker Tool Dependency Installation cmake ( \u003e=3.11 ) gcc (Supports c++20, at least version 10, recommended 11 or above ) python3 ( \u003e=3.8 ) verilator ( ==4.218 ) verible-verilog-format ( \u003e=0.0-3428-gcfcbb82b ) swig ( \u003e=4.2.0, for multi-language support) Please ensure that the paths of tools like verible-verilog-format are added to the environment variable $PATH so they can be invoked directly from the command line.\nDownload Source Code git clone https://github.com/XS-MLVP/picker.git cd picker make init Build and Install cd picker export BUILD_XSPCOMM_SWIG=python # Specify supported language via BUILD_XSPCOMM_SWIG make sudo -E make install The default installation target path is /usr/local, with binaries placed in /usr/local/bin and template files in /usr/local/share/picker. The installation will automatically install the xspcomm base library, which encapsulates the basic types of RTL modules and is located in /usr/local/lib/libxspcomm.so. You might need to manually set the linking directory parameter (-L) during compilation. Additionally, if Python support is enabled, the xspcomm Python package will be installed in /usr/local/share/picker/python/xspcomm/. To generate HTML files for test coverage, you also need to install lcov (genhtml). You can directly install it using apt-get.\nInstallation Test Run the command and check the output:\n➜ picker git:(master) picker XDut Generate. Convert DUT(*.v/*.sv) to C++ DUT libs. Notice that [file] option allow only one file. Usage: XDut Gen [file] [OPTION...] -f, --filelist arg DUT .v/.sv source files, contain the top module, split by comma. Or use '*.txt' file with one RTL file path per line to specify the file list (default: \"\") --sim arg vcs or verilator as simulator, default is verilator (default: verilator) -l, --language arg Build example project, default is cpp, choose cpp or python (default: cpp) -s, --source_dir arg Template Files Dir, default is ${picker_install_path}/../picker/template (default: /usr/local/share/picker/template) -t, --target_dir arg Render files to target dir, default is ./picker_out (default: ./picker_out) -S, --source_module_name arg Pick the module in DUT .v file, default is the last module in the -f marked file (default: \"\") -T, --target_module_name arg Set the module name and file name of target DUT, default is the same as source. For example, -T top, will generate UTtop.cpp and UTtop.hpp with UTtop class (default: \"\") --internal arg Exported internal signal config file, default is empty, means no internal pin (default: \"\") -F, --frequency arg Set the frequency of the **only VCS** DUT, default is 100MHz, use Hz, KHz, MHz, GHz as unit (default: 100MHz) -w, --wave_file_name arg Wave file name, emtpy mean don't dump wave (default: \"\") -c, --coverage Enable coverage, default is not selected as OFF -V, --vflag arg User defined simulator compile args, passthrough. Eg: '-v -x-assign=fast -Wall --trace' || '-C vcs -cc -f filelist.f' (default: \"\") -C, --cflag arg User defined gcc/clang compile command, passthrough. Eg:'-O3 -std=c++17 -I./include' (default: \"\") -v, --verbose Verbose mode -e, --example Build example project, default is OFF -h, --help Print usage Parameter Explanation [file]: Required. Verilog or SystemVerilog source file of the DUT containing the top module. --filelist, -f: Optional. Verilog or SystemVerilog source files of the DUT, separated by commas. Alternatively, use a *.txt file with one RTL file path per line to specify the file list. --sim: Optional. Simulator type, can be vcs or verilator, default is verilator. --language, -l: Optional. Language for building the example project, can be cpp or python, default is cpp. --source_dir, -s: Optional. Template files directory, default is ${mcv_install_path}/../mcv/template. --target_dir, -t: Optional. Target directory for rendered files, default is ./mcv_out. --source_module_name, -S: Optional. Pick the module in the DUT’s Verilog file, default is the last module in the file marked with -f. --target_module_name, -T: Optional. Set the module name and file name of the target DUT, default is the same as the source. For example, -T top will generate UTtop.cpp and UTtop.hpp with UTtop class. --internal: Optional. Exported internal signal configuration file, default is empty, meaning no internal pins. --frequency, -F: Optional. Set the frequency of the only VCS DUT, default is 100MHz, can use Hz, KHz, MHz, GHz as units. --wave_file_name, -w: Optional. Wave file name, empty means don’t export waves. --coverage, -c: Optional. Enable coverage, generates .dat coverage data after test completion. --vflag, -V: Optional. User-defined simulator compile arguments, passthrough. For example: ‘-v -x-assign=fast -Wall –trace’ or ‘-f filelist.f’. --cflag, -C: Optional. User-defined gcc/clang compile arguments, passthrough. For example: ‘-O3 -std=c++17 -I./include’. --verbose, -v: Optional. Verbose mode, keeps intermediate files. --example, -e: Optional. Build example project, default is OFF. --help, -h: Optional. Print usage help. Functional Testing cd picker # Enter the project root directory, i.e., the directory where git clone was executed ./example/Adder/release-verilator.sh -l cpp -e The program should output similar content, indicating a successful installation:\n... [cycle 114515] a=0xa9c430d2942bd554, b=0xe26feda874dac8b7, cin=0x0 DUT: sum=0x8c341e7b09069e0b, cout=0x1 REF: sum=0x8c341e7b09069e0b, cout=0x1 Test Passed, destory UTAdder ... At this point, the Picker tool installation is complete.\n","categories":["Tutorial"],"description":"Install relevant dependencies, download, build, and install the corresponding tools.","excerpt":"Install relevant dependencies, download, build, and install the …","ref":"/mlvp/en/docs/quick-start/installer/","tags":["docs"],"title":"Setting Up the Verification Environment"},{"body":"Principle Introduction Basic Library In this chapter, we will introduce how to use Picker to compile RTL code into a C++ class and compile it into a dynamic library.\nFirst, the Picker tool parses the RTL code, creates a new module based on the specified Top Module, encapsulates the module’s input and output ports, and exports DPI/API to operate the input ports and read the output ports.\nThe tool determines the module to be encapsulated by specifying the file and Module Name of the Top Module. At this point, you can understand Top as the main function in software programming.\nNext, the Picker tool uses the specified simulator to compile the RTL code and generate a DPI library file. This library file contains the logic required to simulate running the RTL code (i.e., the hardware simulator).\nFor VCS, this library file is a .so (dynamic library) file, and for Verilator, it is a .a (static library) file. DPI stands for Direct Programming Interface，which can be understood as an API specification.\nThen, the Picker tool renders the base class defined in the source code according to the configuration parameters, generates a base class (wrapper) for interfacing with the simulator and hides simulator details, and links the base class with the DPI library file to generate a UT dynamic library file.\nAt this point, the UT library file uses the unified API provided by the Picker tool template. Compared with the simulator-specific API in the DPI library file, the UT library file provides a unified API interface for the hardware simulator generated by the simulator. The generated UT library file is common across different languages! Unless otherwise specified, other high-level languages will operate the hardware simulator by calling the UT dynamic library. Finally, based on the configuration parameters and parsed RTL code, the Picker tool generates a C++ class source code. This source code is the definition (.hpp) and implementation (.cpp) of the RTL hardware module in the software. Instantiating this class is equivalent to creating a hardware module.\nThis class inherits from the base class and implements the pure virtual functions in the base class to instantiate the hardware in software. There are two reasons for not encapsulating this class implementation into the dynamic library:\nSince the UT library file needs to be common across different languages, and different languages have different ways to implement classes, for universality, the class implementation is not encapsulated into the dynamic library. To facilitate debugging, enhance code readability, and make it easier for users to repackage and modify. Generating Executable Files In this chapter, we will introduce how to write test cases and generate executable files based on the basic library generated in the previous chapter (including dynamic libraries, class declarations, and definitions).\nFirst, users need to write test cases, which means instantiating the class generated in the previous chapter and calling the methods in the class to operate the hardware module. Details can be found in [Random Number Generator Verification - Configure Test Code](docs/quick-start/examples/rmg/#Configure Test Code) for instantiation and initialization process.\nSecond, users need to apply different linking parameters to generate executable files based on the different simulators applied in the basic library. The corresponding parameters are defined in template/cpp/cmake/*.cmake.\nFinally, according to the configured linking parameters, the compiler will link the basic library and generate an executable file.\nTaking Adder Verification as an example, picker_out_adder/cpp/cmake/*.cmake is a copy of the template described in item 2 above. vcs.cmake defines the linking parameters of the basic library generated using the VCS simulator, and verilator.cmake defines the linking parameters of the basic library generated using the Verilator simulator.\nUsage The parameter --language cpp or -l cpp is used to specify the generation of the C++ basic library. The parameter -e is used to generate an executable file containing an example project. The parameter -v is used to retain intermediate files when generating the project. #include \"UT_Adder.hpp\" int64_t random_int64() { static std::random_device rd; static std::mt19937_64 generator(rd()); static std::uniform_int_distribution\u003cint64_t\u003e distribution(INT64_MIN, INT64_MAX); return distribution(generator); } int main() { #if defined(USE_VCS) UTAdder *dut = new UTAdder(\"libDPIAdder.so\"); #elif defined(USE_VERILATOR) UTAdder *dut = new UTAdder(); #endif // dut-\u003einitClock(dut-\u003eclock); dut-\u003exclk.Step(1); printf(\"Initialized UTAdder\\n\"); struct input_t { uint64_t a; uint64_t b; uint64_t cin; }; struct output_t { uint64_t sum; uint64_t cout; }; for (int c = 0; c \u003c 114514; c++) { input_t i; output_t o_dut, o_ref; i.a = random_int64(); i.b = random_int64(); i.cin = random_int64() \u0026 1; auto dut_cal = [\u0026]() { dut-\u003ea = i.a; dut-\u003eb = i.b; dut-\u003ecin = i.cin; dut-\u003exclk.Step(1); o_dut.sum = (uint64_t)dut-\u003esum; o_dut.cout = (uint64_t)dut-\u003ecout; }; auto ref_cal = [\u0026]() { uint64_t sum = i.a + i.b; bool carry = sum \u003c i.a; sum += i.cin; carry = carry || sum \u003c i.cin; o_ref.sum = sum; o_ref.cout = carry ; }; dut_cal(); ref_cal(); printf(\"[cycle %llu] a=0x%lx, b=0x%lx, cin=0x%lx\\n\", dut-\u003exclk.clk, i.a, i.b, i.cin); printf(\"DUT: sum=0x%lx, cout=0x%lx\\n\", o_dut.sum, o_dut.cout); printf(\"REF: sum=0x%lx, cout=0x%lx\\n\", o_ref.sum, o_ref.cout); Assert(o_dut.sum == o_ref.sum, \"sum mismatch\"); } delete dut; printf(\"Test Passed, destory UTAdder\\n\"); return 0; } Generating Waveforms In C++, the destructor of the DUT automatically calls dut.finalize(), so you only need to delete dut after the test ends to perform post-processing (write waveform, coverage files, etc.).\n#include \"UT_Adder.hpp\" int main() { UTAdder *dut = new UTAdder(\"libDPIAdder.so\"); printf(\"Initialized UTAdder\\n\"); for (int c = 0; c \u003c 114514; c++) { auto dut_cal = [\u0026]() { dut-\u003ea = c * 2; dut-\u003eb = c / 2; dut-\u003ecin = i.cin; dut-\u003exclk.Step(1); o_dut.sum = (uint64_t)dut-\u003esum; o_dut.cout = (uint64_t)dut-\u003ecout; }; dut_cal(); printf(\"[cycle %llu] a=0x%lx, b=0x%lx, cin=0x%lx\\n\", dut-\u003exclk.clk, i.a, i.b, i.cin); printf(\"DUT: sum=0x%lx, cout=0x%lx\\n\", o_dut.sum, o_dut.cout); } delete dut; // automatically call dut.finalize() in ~UTAdder() printf(\"Simulation finished\\n\"); return 0; } ","categories":["Tutorials"],"description":"Encapsulate the DUT hardware runtime environment with C++ and compile it into a dynamic library.","excerpt":"Encapsulate the DUT hardware runtime environment with C++ and compile …","ref":"/mlvp/en/docs/multi-lang/cpp/","tags":["docs"],"title":"Using C++"},{"body":"源码安装Picker工具 依赖安装 cmake ( \u003e=3.11 ) gcc ( 支持c++20,至少为gcc版本10, 建议11及以上 ) python3 ( \u003e=3.8 ) verilator ( ==4.218 ) verible-verilog-format ( \u003e=0.0-3428-gcfcbb82b ) swig ( \u003e=4.2.0, 用于多语言支持 ) 请注意，请确保verible-verilog-format等工具的路径已经添加到环境变量$PATH中，可以直接命令行调用。\n下载源码 git clone https://github.com/XS-MLVP/picker.git cd picker make init 构建并安装 cd picker export BUILD_XSPCOMM_SWIG=python # 通过BUILD_XSPCOMM_SWIG指定支持语言 make sudo -E make install 默认的安装的目标路径是 /usr/local， 二进制文件被置于 /usr/local/bin，模板文件被置于 /usr/local/share/picker。 安装时会自动安装 xspcomm 基础库，该基础库是用于封装 RTL 模块的基础类型，位于 /usr/local/lib/libxspcomm.so。 可能需要手动设置编译时的链接目录参数(-L) 同时如果开启了python支持，还会安装 xspcomm 的python包，位于 /usr/local/share/picker/python/xspcomm/。 为了后续生成测试覆盖率html文件，还需要安装lcov(genhtml)。直接使用apt-get安装即可。\n安装测试 执行命令并检查输出：\n➜ picker git:(master) picker export Export RTL Projects Sources as Software libraries such as C++/Python Usage: picker export [OPTIONS] file Positionals: file TEXT REQUIRED DUT .v/.sv source file, contain the top module Options: -h,--help Print this help message and exit --fs,--filelist TEXT DUT .v/.sv source files, contain the top module, split by comma. Or use '*.txt' file with one RTL file path per line to specify the file list --sim TEXT [verilator] vcs or verilator as simulator, default is verilator --lang,--language TEXT [python] Build example project, default is python, choose cpp, java or python --sdir,--source_dir TEXT [/usr/local/share/picker/template] Template Files Dir, default is ${picker_install_path}/../picker/template --tdir,--target_dir TEXT [./picker_out] Codegen render files to target dir, default is ./picker_out --sname,--source_module_name TEXT Pick the module in DUT .v file, default is the last module in the -f marked file --tname,--target_module_name TEXT Set the module name and file name of target DUT, default is the same as source. For example, -T top, will generate UTtop.cpp and UTtop.hpp with UTtop class --internal TEXT Exported internal signal config file, default is empty, means no internal pin -F,--frequency TEXT [100MHz] Set the frequency of the **only VCS** DUT, default is 100MHz, use Hz, KHz, MHz, GHz as unit -w,--wave_file_name TEXT Wave file name, emtpy mean don't dump wave -c,--coverage Enable coverage, default is not selected as OFF -V,--vflag TEXT User defined simulator compile args, passthrough. Eg: '-v -x-assign=fast -Wall --trace' || '-C vcs -cc -f filelist.f' -C,--cflag TEXT User defined gcc/clang compile command, passthrough. Eg:'-O3 -std=c++17 -I./include' --verbose Verbose mode -e,--example Build example project, default is OFF --autobuild [1] Auto build the generated project, default is true file is required Run with --help for more information. 参数解释 [file]: 必需。DUT 的 Verilog 或 SystemVerilog 源文件，包含顶层模块 --filelist, -fs: 可选。DUT 的 Verilog 或 SystemVerilog 源文件，逗号分隔。也可以使用 *.txt 文件，每行指定一个 RTL 文件路径，来指定文件列表。 --sim: 可选。模拟器类型，可以是 vcs 或 verilator，默认是 verilator。 --language, --lang: 可选。构建示例项目的语言，可以是 cpp 或 python，默认是 cpp。 --source_dir, -sdir: 可选。模板文件目录，默认是 ${mcv_install_path}/../mcv/template。 --target_dir, -tdir: 可选。渲染文件的目标目录，默认是 ./mcv_out。 --source_module_name, -sname: 可选。在 DUT 的 Verilog 文件中选择模块，默认是 标记的文件中的最后一个模块。 --target_module_name, -tname: 可选。设置目标 DUT 的模块名和文件名，默认与源相同。例如，-T top 将生成 UTtop.cpp 和 UTtop.hpp，并包含 UTtop 类。 --internal: 可选。导出的内部信号配置文件，默认为空，表示没有内部引脚。 --frequency, -F: 可选。设置 仅 VCS DUT 的频率，默认是 100MHz，可以使用 Hz、KHz、MHz、GHz 作为单位。 --wave_file_name, -w: 可选。波形文件名，为空表示不导出波形。 --coverage, -c: 可选。打开之后在测试完成后生成.dat的覆盖率数据。 --vflag, -V: 可选。用户定义的模拟器编译参数，透传。例如：’-v -x-assign=fast -Wall –trace’ 或 ‘-f filelist.f’。 --cflag, -C: 可选。用户定义的 gcc/clang 编译参数，透传。例如：’-O3 -std=c++17 -I./include’。 --verbose, -v: 可选。详细模式，保留生成的中间文件。 --example, -e: 可选。构建示例项目，默认是 OFF。 --autobuild: 可选。自动构建生成的项目，默认是true。 --help, -h: 可选。打印使用帮助。 功能测试 cd picker # 进入项目根目录，即git clone的目录 bash example/Adder/release-verilator.sh --lang cpp 程序应当输出类似的内容，表示安装成功：\n... [cycle 114515] a=0xa9c430d2942bd554, b=0xe26feda874dac8b7, cin=0x0 DUT: sum=0x8c341e7b09069e0b, cout=0x1 REF: sum=0x8c341e7b09069e0b, cout=0x1 Test Passed, destory UTAdder ... 至此，picker工具安装完成。\n","categories":["教程"],"description":"安装相关依赖，**下载、构建并安装**对应的工具。","excerpt":"安装相关依赖，**下载、构建并安装**对应的工具。","ref":"/mlvp/docs/quick-start/installer/","tags":["docs"],"title":"搭建验证环境"},{"body":"回调 概述 硬件描述语言不同于C++/Python等高级软件编程语言，具有独特的“时钟”特性，在使用picker工具进行验证时，我们可能会遇到想在时钟的上升沿触发某种操作的情况，要想实现这个过程，就要会使用回调函数\n回调函数就是一个被作为参数传递的函数。 在C语言中，回调函数只能使用函数指针实现。 在C++、Python、ECMAScript等更现代的编程语言中还可以使用仿函数或匿名函数。 回调函数是一个函数或过程，不过它是一个由调用方自己实现，供被调用方使用的特殊函数，一般使用方法如下\n在a()方法中调用了b()方法 在b方法执行完毕主动调用提供的callback()方法 这个下面的例子中，实现了一个简单的callback 示例，我们定一个了一个打印结果的方法 print_result，一个两数相加的方法add (), 当完成add 后，调用 print_result（）方法将结果打印出来\ndef add(x, y): return x + y def sub(x, y): return x - y def mul(x, y): return x * y def div(x, y): return x / y def calc(x, y, func): return func(x, y) # 将函数作为参数传入，再调用函数 print(calc(1, 2, add)) \u003e\u003e\u003e 3 回调函数的优点 优点\n回调函数的作用是将代码逻辑分离出来使得代码更加模块化和可维护。。 提高代码的复用性和灵活性：回调函数可以将一个函数作为参数传递给另一个函数，从而实现模块化编程，提高代码的复用性和灵活性。 解耦合：回调函数可以将不同模块之间的关系解耦，使得代码更易于维护和扩展。 可以异步执行：回调函数可以在异步操作完成后被执行，这样避免了阻塞线程，提高应用程序的效率。 例如在下面这个例子中，我们定义了两个回调函数addOne和addTwo,一个是生成x+1，另一个是生成x+2，还有一个生成倒数的中间函数\n我们可以通过一个中间函数，来分别调用addOne和addTwo来生成形如1/(x+1)和1/(x+2)形式的数 也可以使用匿名函数的形式生成1/(x+3)形式的数 def addOne(x): return x + 1 def addTwo(x): return x + 2 from even import * # 中间函数 # 接受一个回调函数作为参数,返回它的倒数 def getNumber(k, getEvenNumber): return 1 / getEvenNumber(k) if __name__ == \"__main__\": x = 1 # 当需要生成一个1/(x+1)形式的数时 print(getNumber(x, addOne)) # 当需要一个1/(x+2)形式的数时 print(getNumber(x, addTwo)) # 当需要一个1/(x+3)形式数 print(getNumber(x, lambda k: k +3)) 回调函数的使用场景包括 事件处理：回调函数可以用于处理各种事件，例如鼠标点击、键盘输入、网络请求等。 异步操作：回调函数可以用于异步操作，例如读取文件、发送邮件、下载文件等。 数据处理：回调函数可以用于处理数据，例如对数组进行排序、过滤、映射等。 使用回调函数在时钟上升沿触发操作 下面的测试代码里，我们将在随机数生成器的测试中使用回调函数。\n在整个测试过程中，我们会在114514个时钟周期内验证随机数生成器的结果，并统计生成的随机数中大于中位数和小于等于中位数的数量。其中，结果的验证和数据的统计都在时钟上升沿进行。\nTestRandomGenerator是对随机数生成器进行测试的类，在它的属性和方法中：\nself.dut是用于测试的实例化DUTRandomGenerator对象。 self.ref是用于验证结果的实例化LFSR_16对象。 callback1(self, clk)会对随机数生成器进行验证，在时钟上升沿触发。 callback2(self, clk)会统计生成随机数的分布，也在时钟上升沿触发。 test_rg(self, callback3)方法会执行整个测试流程，最后执行callback3函数。 Picker生成的DUT类会包含一个驱动电路的时钟源self.xclock，DUTRandomGenerator也同样如此。\n测试前需要把待测模块的clk引脚接入时钟源，我们可以调用dut中已经封装好的方法：\nself.dut.init_clock(\"clk\") # 等价于 self.xclock.Add(self.port[\"clk\"]) 之后再对生成器进行复位，进行初始化赋值：\nself.dut.reset.value = 1 self.dut.Step(1) # 时钟等待一个周期，下个周期dut的输出会置为0 self.dut.reset.value = 0 # 设置完成后需要记得复位原信号！ 完成初始化后，添加在时钟上升沿触发的回调函数，用于验证与统计：\nself.dut.StepRis(self.callback1) # 添加在时钟上升沿触发的回调函数 self.dut.StepRis(self.callback2) # 当然可也添加多个 然后等待时钟经过114514个周期，期间每个时钟的上升沿会对结果进行验证并统计生成随机数的分布：\nself.dut.Step(114514) 最后进行收尾工作，以回调函数的形式调用median_distribution_stats输出随机数的分布情况：\nself.dut.finalize() callback3(self.greater, self.less_equal, self.MEDIAN) 至此，测试完成。\n随机数生成器测试代码 from UT_RandomGenerator import * import random def median_distribution_stats(gt, le, mid) -\u003e None: # 输出产生结果中大于中位数的个数和小于等于中位数的个数。 print(f\"There are {gt} numbers \u003e {mid} and {le} numbers \u003c= {mid}\") # 16位线性移位寄存器模拟类 class LFSR_16: def __init__(self, seed): self.state = seed \u0026 ((1 \u003c\u003c 16) - 1) def step(self): new_bit = (self.state \u003e\u003e 15) ^ (self.state \u003e\u003e 14) \u0026 1 self.state = ((self.state \u003c\u003c 1) | new_bit) \u0026 ((1 \u003c\u003c 16) - 1) class TestRandomGenerator: def __init__(self) -\u003e None: self.MEDIAN = 2**15 self.SEED = random.randint(0, 2**16 - 1) self.greater = 0 self.less_equal = 0 self.ref = LFSR_16(self.SEED) self.dut = DUTRandomGenerator() def test_rg(self, callback3) -\u003e None: # clk引脚接入时钟源 self.dut.init_clock(\"clk\") self.dut.seed.value = self.SEED # 复位操作 self.dut.reset.value = 1 self.dut.Step(1) # 时钟等待一个周期，下个周期dut的输出会置为0 self.dut.reset.value = 0 # 设置完成后需要记得复位原信号！ # 设置回调函数 self.dut.StepRis(self.callback1) # 添加在时钟上升沿触发的回调函数 self.dut.StepRis(self.callback2) # 当然可也添加多个 # 测试，启动！ self.dut.Step(114514) # 等待时钟经过114514个周期 # 结束 self.dut.finalize() callback3(self.greater, self.less_equal, self.MEDIAN) pass def callback1(self, clk): # 比对结果是否符合预期 assert self.dut.random_number.value == self.ref.state, \"Mismatch\" print( f\"Cycle {clk}, DUT: {self.dut.random_number.value:x},\" + f\" REF: {self.ref.state:x}\" ) self.ref.step() def callback2(self, clk): # 统计产生的随机数中，大于中位数和小于等于中位数的分布 if self.dut.random_number.value \u003e self.MEDIAN: self.greater += 1 else: self.less_equal += 1 if __name__ == \"__main__\": TestRandomGenerator().test_rg(median_distribution_stats) pass 在验证加法器时添加回调函数 在这里定义一个32位的加法器RisAdder，它只在时钟上升沿更新输出。RTL代码为：\nmodule RisAdder #( parameter WIDTH = 32 ) ( input clk, input [WIDTH-1:0] a, input [WIDTH-1:0] b, input cin, output [WIDTH-1:0] sum, output cout ); reg Cout; reg [WIDTH-1:0] Sum; always @(posedge clk) begin {Cout, Sum} \u003c= a + b + cin; end assign {cout, sum} = {Cout, Sum}; endmodule 下面的测试代码里，我们将在加法器的测试中使用回调函数。\n在测试开始前，先创建DUTRisAdder对象的实例dut和SimpleRisAdder对象的实例ref。其中，ref用于模拟加法器预期的行为，用作参考加法器。\nPicker生成的DUT类会包含一个驱动电路的时钟源self.xclock，DUTRisAdder也同样如此。\n在测试开始前，我们会把待测模块的clk引脚接入时钟源：\ndut.init_clock(\"clk\") # 等价于 self.xclock.Add(self.port[name]) 之给加法器的输入置为0，让它下个周期的输出为0：\ndut.a.value = 0 dut.b.value = 0 dut.cin.value = 0 dut.Step(1) # 等待时钟进入下个周期 随后，添加在时钟上升沿触发的回调函数test_adder(clk: int, dut: DUTRisAdder, ref: SimpleRisAdder) -\u003e None，并向test_adder传入dut和ref对象：\n# 测试函数，验证加法器的输出是否正确 def test_adder(clk: int, dut: DUTRisAdder, ref: SimpleRisAdder) -\u003e None: # 获取加法器的输入和输出 a = dut.a.value b = dut.b.value cin = dut.cin.value cout = dut.cout.value sum = dut.sum.value # 检查加法器的输出是否与预期一致 isEqual = (cout, sum) == (ref.cout, ref.sum) # 输出测试结果 print(f\"Cycle: {clk}, Input(a, b, cin) = ({a:x}, {b:x}, {cin:x})\") print( FONT_GREEN + \"Pass.\" # 输出绿色的“Pass.”，如果测试通过 if isEqual else FONT_RED + f\"MisMatch! Expect cout: {ref.cout:x}, sum: {ref.sum:x}.\" + FONT_COLOR_RESET + f\"Get cout: {cout:x}, sum: {sum:x}.\" ) assert isEqual # 如果测试失败，触发断言异常 if __name__ == \"__main__\": ... dut.StepRis(test_adder, (dut, ref)) # 添加在时钟上升沿触发的回调函数, 给回调函数传入dut和ref ... test_adder函数将会在时钟上升沿比较dut和ref的输出，验证RTL代码的实现是否符合我们的预期。\n最后，执行114514个周期的测试，每个测试数据的信号都会持续一个周期：\n# 测试114514个周期 for _ in range(114514): a = random.randint(0, (1\u003c\u003cWIDTH) - 1) b = random.randint(0, (1\u003c\u003cWIDTH) - 1) cin = random.randint(0, 1) dut.a.value = a dut.b.value = b dut.cin.value = cin ref.step(a, b, cin) # 更新参考加法器的状态 dut.Step(1) # 等待时钟进入下个周期 dut.finalize() 上升沿更新的加法器的代码 from UT_RisAdder import * import random # 控制字体颜色 FONT_GREEN = \"\\033[0;32m\" FONT_RED = \"\\033[0;31m\" FONT_COLOR_RESET = \"\\033[0m\" class SimpleRisAdder: \"\"\" SimpleRisAdder 类是一个作为参考的加法器类， 它模拟了我们预期的RisAdder的行为 \"\"\" def __init__(self, width) -\u003e None: self.WIDTH = width # 加法器的位宽 # 端口定义 self.a = 0 # 输入端口a self.b = 0 # 输入端口b self.cin = 0 # 输入端口cin self.cout = 0 # 输出端口cout self.sum = 0 # 输出端口sum def step(self, a, b, cin): \"\"\" 模拟上升沿更新输出: 先用上个周期的输入更新输出，之后再更新输入 \"\"\" sum = self.a + self.b + self.cin self.cout = sum \u003e\u003e self.WIDTH # 计算进位 self.sum = sum \u0026 ((1 \u003c\u003c self.WIDTH) - 1) # 计算和 self.a = a # 更新输入a self.b = b # 更新输入b self.cin = cin # 更新输入cin # 测试函数，验证加法器的输出是否正确 def test_adder(clk: int, dut: DUTRisAdder, ref: SimpleRisAdder) -\u003e None: # 获取加法器的输入和输出 a = dut.a.value b = dut.b.value cin = dut.cin.value cout = dut.cout.value sum = dut.sum.value # 验证输出是否符合预期 isEqual = (cout, sum) == (ref.cout, ref.sum) # 输出测试结果 print(f\"Cycle: {clk}, Input(a, b, cin) = ({a:x}, {b:x}, {cin:x})\") print( FONT_GREEN + \"Pass.\" if isEqual else FONT_RED + f\"MisMatch! Expect cout: {ref.cout:x}, sum: {ref.sum:x}.\", FONT_COLOR_RESET + f\"Get cout: {cout:x}, sum: {sum:x}.\", ) assert isEqual # 如果测试失败，触发断言异常 if __name__ == \"__main__\": WIDTH = 32 # 设置加法器的位宽 ref = SimpleRisAdder(WIDTH) # 创建一个参考加法器 dut = DUTRisAdder() # 创建被测试的加法器 # 绑定时钟信号 dut.init_clock(\"clk\") # 等价于 self.xclock.Add(self.port[name]) # dut输入信号置0 dut.a.value = 0 dut.b.value = 0 dut.cin.value = 0 dut.Step(1) # 等待时钟进入下个周期 dut.StepRis(test_adder, (dut, ref)) # 添加在时钟上升沿触发的回调函数, 给回调函数传入dut和ref # 测试114514个周期 for _ in range(114514): # 随机生成输入 a = random.randint(0, (1\u003c\u003cWIDTH) - 1) b = random.randint(0, (1\u003c\u003cWIDTH) - 1) cin = random.randint(0, 1) ref.step(a, b, cin) # 更新参考加法器的状态 dut.a.value = a # 设置被测试加法器的输入a dut.b.value = b # 设置被测试加法器的输入b dut.cin.value = cin # 设置被测试加法器的输入cin dut.Step(1) # 等待时钟进入下个周期 dut.finalize() pass Eventloop 概述 Event Loop：事件循环机制是一种计算机编程模型，其目的是使程序能够在一种非阻塞方式下等待事件(如输入、计时器、定时器、网络等)的发生，并在发生事件时被通知及时处理事件，用于等待和分配消息和事件，单线程运行时不会阻塞的一种机制，也就是实现异步的原理。作为一种单线程语言,事件循环机制的核心是事件循环，即程序会轮询事件队列中是否有待处理事件，如果有，就执行相应的回调函数来处理该事件。然后继续等待下一个事件。事件可以是来自外部资源（如网络套接字、文件、定时器等）的输入、用户输入、系统通知等。由此，程序就可以实现异步、非阻塞的编程方式，提高程序的响应速度和运行效率.\n基本原理 事件循环的工作流程通常如下：\n启动程序，执行同步代码直到遇到异步代码， 将异步代码的回调函数放入事件队列中，以便在事件发生时执行。 当所有同步代码执行完毕，开始事件循环，不断检查是否有事件发生。 如果有事件队列不为空，则执行与之关联的回调函数。 回到步骤 4，继续循环处理事件。 伪代码的形式如下 while(1) { events = getEvents(); for (e in events) processEvent(e); } Python中的Evenloop python中的Asyncio模块提供了以下方法来管理事件循环\nloop = get_event_loop() : 得到当前的事件循环。 asyncio.set_event_loop() : 为当前上下文设置事件循环。 asyncio.new_event_loop() : 根据此策略创建一个新的事件循环并返回。 loop.call_at():在指定时间的运行。 loop.call_later(delay, callback, arg) : 延迟delay 秒再执行 callback 方法。 loop.call_soon(callback, argument) : 尽可能快调用 callback方法, call_soon() 函数结束，主线程回到事件循环之后就会马上调用 callback 。 loop.time() : 返回当前事件循环的内部时间。 loop.run_forever() : 在调用 stop() 之前将一直运行。 在下面的例子中，我们定义了一个callback方法用于打印参数和loop内时间，以观察函数的定义顺序和执行顺序\n在main方法中，首先我们先获取当前的事件循环loop，和当前的时间 依次调用callback方法，设置不同的开始执行时间 import asyncio def callback(a, loop): print(\"我的参数为 {0}，执行的时间为{1}\".format(a,loop.time())) if __name__ == \"__main__\": try: loop = asyncio.get_event_loop() now = loop.time() loop.call_later(5, callback, 5, loop) loop.call_at(now+2, callback, 2, loop) loop.call_at(now+1, callback, 1, loop) loop.call_at(now+3, callback, 3, loop) loop.call_soon(callback, 4, loop) loop.run_forever() #要用这个run_forever运行 except KeyboardInterrupt: print(\"Goodbye!\") 运行结果为：\n我的参数为 4，执行的时间为266419.843 我的参数为 1，执行的时间为266420.843 我的参数为 2，执行的时间为266421.859 我的参数为 3，执行的时间为266422.859 我的参数为 5，执行的时间为266424.843 回调函数和Eventloop的缺点 回调函数也存在如下的一些缺点，因此在下一小节中引入了异步的概念， 缺点：\n回调函数嵌套过多会导致代码难以维护：如果回调函数嵌套层数过多，代码会变得非常复杂，难以维护。 回调函数容易造成竞态条件：如果回调函数中有共享资源访问，容易出现竞态条件，导致程序出错。 代码可读性差：回调函数的使用可能会破坏代码的结构和可读性，尤其是在处理大量数据时 ","categories":["示例项目","教程"],"description":"利用回调处理电路事件","excerpt":"利用回调处理电路事件","ref":"/mlvp/docs/advance_func/callback/","tags":["examples","docs"],"title":"回调函数"},{"body":" 为满足开放验证的环境要求，我们开发了 Picker 工具，用于将 RTL 设计转换为多语言接口，并在此基础上进行验证，我们将会使用 Picker 工具生成的环境作为基础的验证环境。接下来我们将介绍 Picker 工具，及其基础的使用方法。\nPicker 简介 picker是一个芯片验证辅助工具，其目标是将RTL设计验证模块(.v/.scala/.sv)进行封装，并使用其他编程语言暴露Pin-Level的操作，未来计划支持自动化的Transaction-Level原语生成。其他编程语言包括 c++ (原生支持), python(已支持), java(待完善), golang(待完善) 等编程语言接口。该辅助工具让用户可以基于现有的软件测试框架，例如pytest, junit，TestNG, go test等，进行芯片UT验证。\n基于picker进行验证具有如下优点：\n不泄露RTL设计。经过Picker转换后，原始的设计文件(.v)被转化成了二进制文件(.so)，脱离原始设计文件后，依旧可进行验证，且验证者无法获取RTL源代码。 减少编译时间。当DUT(Design Under Test)稳定时，只需要编译一次（打包成so）。 用户面广。提供的编程接口多，可覆盖不同语言的开发者（传统IC验证，只用System Verilog）。 可使用软件生态丰富。能使用python3, java, golang等生态。 目前picker支持以下模拟器： verilator、synopsys vcs\nPicker的工作原理\nPicker的主要功能就是将Verilog代码转换为C++或者Python代码，以Chisel开发的处理器为例:先通过Chisel自带的工具将其转换为Verilog代码，再通Picker提供高级编程语言接口。\nPython 模块生成 生成模块的过程 Picker 导出 Python Module 的方式是基于 C++ 的。\nPicker 是 代码生成(codegen)工具，它会先生成项目文件，再利用 make 编译出二进制文件。 Picker 首先会利用仿真器将 RTL 代码编译为 C++ Class，并编译为动态库。（见C++步骤详情） 再基于 Swig 工具，利用上一步生成的 C++ 的头文件定义，将动态库导出为 Python Module。 最终将生成的模块导出到目录，并按照需求清理或保留其他中间文件。 Swig 是一个用于将 C/C++ 导出为其他高级语言的工具。该工具会解析 C++ 头文件，并生成对应的中间代码。 如果希望详细了解生成过程，请参阅 Swig 官方文档。 如果希望知道 Picker 如何生成 C++ Class，请参阅 C++。\n该这个模块和标准的 Python 模块一样，可以被其他 Python 程序导入并调用，文件结构也与普通 Python 模块无异。 Python 模块使用 参数 --language python 或 -l python 用于指定生成Python基础库。 参数 --example, -e 用于生成包含示例项目的可执行文件。 参数 --verbose, -v 用于保留生成项目时的中间文件。 使用工具生成Python的DUT类 在键入Picker的编译命令后，会自动生成Python的一个基础类，我们称之为DUT类，以前述的加法器为例，用户需要编写测试用例，即导入上一章节生成的 Python Module，并调用其中的方法，以实现对硬件模块的操作。 目录结构为： picker_out_adder |-- UT_Adder # Picker 工具生成的项目 | |-- Adder.fst.hier | |-- _UT_Adder.so | |-- __init__.py | |-- libDPIAdder.a | |-- libUTAdder.so | `-- libUT_Adder.py `-- example.py # 用户需要编写的代码 用户使用 Python 编写测试用例，即导入上述生成的 Python Module，并调用其中的方法，以实现对硬件模块的操作。下面我们简单的介绍一下DUT的方法和属性。 # 初始化DUT,DUT()有两个参数: # DUT(waveform_filename=\"report/uftb_with_ftq.fst\", coverage_filename=\"report/uftb_with_ftq_coverage.dat\") # 缺省的时候为使用Picker生成Python类的时候指定的名称，如果命令里面没有指定则参数则不会生成测试报告和波形 dut = DUT() # 访问信号，假如引脚的名称为a dut.a.value = 1 # 等价于dut.xdata.a.value # 绑定clk到模拟器的时钟 dut.init_clock(\"clk\") # 等价于self.xclock.Add(“clk”) # 时钟推进 dut.Step(n) # 等价于dut.xclock.Step(n) # 添加上升沿回调，参数为回调函数 # 等价于dut.xclock.StepRis(...) dut.StepRis(lambda c, x, y: print(\"lambda ris: \", c, x, y), (1, 2)) # 添加下降沿回调，参数为回调函数 # 等价于dut.xclock.StepFal(...) dut.StepFal(lambda c, x, y: print(\"lambda fal: \", c, x, y), (3, 4)) # 异步方法，对时钟事件的等待，当时钟事件被触发时，程序才会继续向下执行。 dut.astep(n) # 等价于 await self.xclock.AStep(n) # 异步方法，每次时钟事件触发时检查条件是否满足，如果满足才继续向下执行。 dut.acondition(lambda: dut.signal_1.value == 1) # 等价于 await dut.xclock.ACondition(lambda: dut.signal_1.value == 1) # 异步方法，时钟事件，每驱动一次时钟，都会对时钟事件进行一次触发，其他协程可以通过监听时钟事件来得知时钟被驱动了。 dut.runstep(n) # 等价于 dut..xclock.RunStep(n) DUT类是电路封装完成后创建的一个可直接使用的类。要使用DUT类，首先需要初始化。对于时序电路，还需要把时钟信号与模拟时钟相连。这让我们可以通过调用Step方法来控制电路，而信号的访问则可以通过信号.value来实现，下面我们将以前一章验证过的加法器为例，来详细说明如何使用生成的DUT类。 from UT_Adder import * # 从python软件包里导入模块 import random if __name__ == \"__main__\": dut = DUTAdder() # 初始化 DUT # dut.init_clock(\"clk\") # 如果模块有时钟，需要初始化时钟，绑定时钟信号到模拟器的时钟，以自动驱动 # reset # dut.reset.value = 1 # dut.Step(1) # 该步进行了初始化赋值操作 # dut.reset.value = 0 # 设置完成后需要记得复位原信号！ # 以加法器为例，对信号的操作 dut.a.value = 1 #对dut的输入信号赋值，需要用到.value dut.b.value = 2 dut.cin.value = 0 dut.Step(1) #更新信号 print(f\"sum = {dut.sum.value}, cout = {dut.cout.value}\") #读取dut的输出信号，需要用到.value # 清空对象，并完成覆盖率和波形文件的输出工作（写入到文件） dut.finalize() 我们可以直接通过DUT访问某些方法，但大多数方法被封装在DUT类的三个主要数据类型：XData、XPort和XClock中。这些类型分别代表电路中的不同类型的信号。通过这些数据类型，我们能够接触和操纵电路中的各种信号，以便进行仿真测试。在后续的内容中，我们将深入探讨这些数据类型的定义、来源，以及它们在实际仿真中的使用方式。 XDATA 通常，电路有四种状态：0、1、Z和X。我们定义一种名为XData的数据类型，将其与电路的引脚绑定，并通过DPI读写电路的IO接口。这样，我们就能够使用软件来激励电路。 初始化\n# 初始化的步骤picker会为我们自动完成，此处只是介绍下用法 # 初始化使用XData，参数为位宽和数据方向(XData.In,XData.Out,XData.InOut) a = XData(32,XData.In) a.ReInit(16,XData.In) #ReInit方法可以重新初始化XData实例 # 绑定DPI，以加法器为例，参数为C函数 self.a.BindDPIRW(DPIRa, DPIWa) self.b.BindDPIRW(DPIRb, DPIWb) self.cin.BindDPIRW(DPIRcin, DPIWcin) self.sum.BindDPIRW(DPIRsum, DPIWsum) self.cout.BindDPIRW(DPIRcout, DPIWcout) 主要方法\n# 使用.value可以进行访问，有多种赋值方法 a.value = 12345 # 十进制赋值 a.value = 0b11011 # 二进制赋值 a.value = 0o12345 # 八进制赋值 a.value = 0x12345 # 十六进制赋值 a.value = '::ffff' # 字符串赋值ASCII码 d = XData(32,XData.In) # 同类型赋值 d = a a.value = 0xffffffff # 配合ctype库使用 a.W(); # 转 uint32 a.U(); # 转 uint64 a.S(); # 转 int64 a.B(); # 转 bool a.String() # 转 string #a.value支持使用[]按下标访问，下标从0开始为最低位 a[31] = 0 # a.value = 0x7ffffffff a.value = \"x\" # 赋值高阻态 # 输出高阻和不定态的时候需要用字符串输出 # print(f\"expected x, actual {a.String()}\") # a.value = \"000000??\" # 000000??表示不定态和高阻态，出现这种结果的时候电路一般是出问题了 a.value = \"z\" # 赋值不定态 # a.value = \"000000??\" # 设置引脚模式: XData.Imme 立即写入,XData.Rise 上升沿写入,XData.Fall #下降沿写入。XData默认情况下为上升沿写入。立即写入模式下，可以真正的模拟时序电路，不需要Step方法便能直接更新值 a.SetWriteMode(XData.Imme) XPORT 在处理少数几个XData引脚时，直接操作XData是比较清晰和直观的。但是，当涉及到多个XData时，进行批量管理就不太方便了。XPort是对XData的一种封装，它允许我们对多个XData进行集中操作。我们还提供了一些方法来方便地进行批量管理。 初始化与添加引脚\nport = XPort(\"p\") #创建XPort实例 主要方法\n# 使用Add方法添加引脚 port.Add(\"a\",a) # 添加引脚 port.Add(\"b\",b) # 添加引脚 #使用[]访问引脚 port[\"b\"] # 使用[].value可以访问引脚的值 port[\"b\"].value = 1 # Connect方法对两个Port进行连接如果连接的两个port都是InOut类型的，那么数据流通方向就是Port_2-\u003ePort_1 # 如果一个是In一个是Out，那么数据流向是Out-\u003eIn,连接的命名要求为：xx_A Connect yy_A a = XData(32,XData.In) b = XData(32,XData.Out) port_1 = XPort(\"p\") port_2 = XPort(\"p1\") port_1.Add(\"c\",a) port_2.Add(\"c\",b) port_2.Connect(port_1) #返回引脚个数 port.PortCount() # Flip方法翻转引脚输入输出方式 port.Flip() # AsBiIo方法将引脚方向转换为双向 a.AsBiIO() # 通过DPI刷入所有上升沿引脚的值 port.WriteOnRise() # 通过DPI刷入所有下降沿引脚的值 port.WriteOnFall() # 使用ReadFresh刷新读取引脚的值 port.ReadFresh(XData.In) # 使用SetZero方法将引脚的值设为0 port.SetZero() print(f\"expected 0, actual {port['a'].value}\") # port['a'].value = 0 XClock XClock是电路时钟的封装，用于驱动电路。在传统仿真工具（例如Verilator）中，需要手动为clk赋值，并通过step_eval函数更新状态。但在我们的工具中，我们提供了相应的方法，可以将时钟直接绑定到XClock上。只需使用我们的Step()方法，就可以同时更新clk和电路状态。 初始化与添加引脚\n# 初始化 clk = XClock(lambda a: 1 if print(\"lambda stp: \", a) else 0) #参数stepfunc为DUT后端提供的电路推进方法，例如verilaor的step_eval等 主要方法\n# 使用Add方法添加引脚 clk.Add(XData) # 添加clk引脚 # 在生成的DUT中，我们自动生成了init_clock(self,name:str)函数，调用dut.init_clock(name:str),也可以进行绑定，例如：dut.init_clock(clk) clk.Add(XPort) # 添加Port # 更新状态 clk.Step(1) # 参数为UInt i，表示前进i步 #复位 clk.Reset() # 推动电路执行，不更新波形（仅用于组合逻辑，慎用） clk.eval() # 推动电路执行，更新波形（不建议使用） clk.eval_t() # 添加上升沿回调，参数为回调函数 clk.StepRis(lambda c, x, y: print(\"lambda ris: \", c, x, y), (1, 2)) # 添加下降沿回调，参数为回调函数 clk.StepFal(lambda c, x, y: print(\"lambda fal: \", c, x, y), (3, 4)) 虽然通过上升沿或下降沿的回调可以有效地进行验证，但正如之前所述，传统的回调模式，尤其是在嵌套多层时，会导致代码难以阅读和维护，这通常被称为“回调地狱”（Callback Hell）。因此，我们还提供了异步方法来进行验证，这样可以简化代码结构，提高可读性。\nAsync \u0026 Event 在Python中，异步编程通过asyncio库和async/await语法取代了传统的回调模式。这种方法提供了一种更加直观和简洁的方式来处理异步操作，尤其是在涉及到多个需要按顺序执行的异步操作时。\nasyncio库引入了协程（coroutines），它们是一种通过生成器实现的轻量级线程。协程允许单个Python线程中的并发执行，而不需要多线程或多进程，从而避免了线程切换的开销和进程间通信的复杂性。如果您想更深入的学习asyncio库，可以去参考asyncio库的官方文档。\n使用async/await语法，可以将异步代码写得像同步代码一样直观。你可以用async定义一个函数为协程，然后在函数内部用await挂起等待一个异步操作的完成。这样，当一个协程等待时，事件循环可以继续执行其他协程，直到当前协程可以继续执行。下面我们来简单介绍一下如何使用异步编程来进行验证。\n时钟事件 (Event)\n生成的 Python 模块中提供了基础的异步功能，以方便用户编写异步测试用例。\n具体地，我们在每一个由 Picker 生成的 Python 模块中设置了一个时钟事件（Event），并围绕这一事件提供了异步的接口。该时钟事件可通过实例化对象的 event 属性获取，例如 dut.event。\n同时，该事件也可以从 dut 的每一个接口中获取。这是因为我们将接口定义为了 XPin，其中包含了该接口的 xdata 和全局时钟事件 event，因此可以通过 dut.signal_1.event 这样的方式获取到全局的时钟事件。这有助于我们在仅能访问到一个接口的情况下，获取到该接口对应的全局时钟信号。\n使用异步\n上文介绍的时钟事件是异步功能的核心，在这里我们将介绍如何使用时钟事件来实现异步功能。\n首先我们需要创建一个协程(Coroutine)对象，并将其加入到事件循环(EventLoop)中，以实现全局时钟的驱动，方法如下：\nasyncio.create_task(dut.xclock.RunStep(10)) 这将会使得时钟在“后台”被驱动 10 次，而不会阻塞当前正在执行的代码。但是其他的协程如何得知时钟被驱动了一次呢？这就要用到时钟事件了。在 RunStep 函数中，每驱动一次时钟，都会对时钟事件进行一次触发，其他协程可以通过监听时钟事件来得知时钟被驱动了。例如：\nasync def other_task(): # 循环10次 for _ in range(10): # 等待时钟的一个步进 await dut.xclock.AStep(1) # 每次步进后打印消息 print(f\"Clock has been ticked\") dut.xclock.AStep 中封装了对时钟事件的等待，当时钟事件被触发时，程序才会继续向下执行。我们也可以直接使用 await dut.event.wait() 来等待直接时钟事件的触发。通过这种异步的方式，我们便可以同时创建多个任务，每个任务中都可以等待时钟事件的触发，从而实现多任务的并发执行。\n我们做了相应的工作，以确保在下一次时钟事件到来之前，所有能够执行的任务都将会被执行，并由下一次时钟事件进行阻塞。\n以下是一个完整的示例：\nimport asyncio # 创建设备实例 dut = UT_mydut() # 初始化设备时钟 dut.init_clock(\"clk\") # 定义一个异步函数来模拟其他任务 async def other_task(): for _ in range(10): # 等待时钟步进 await dut.xclock.AStep(1) # 打印时钟已经步进的消息 print(f\"Clock has been ticked\") # 定义一个异步测试函数 async def my_test(): # 创建并启动一个时钟任务 clock_task = asyncio.create_task(dut.xclock.RunStep(10)) # 创建并启动其他任务 asyncio.create_task(other_task()) # 等待时钟任务完成 await clock_task asyncio.run(my_test()) 除了 RunStep 和 AStep 之外，我们还提供了一个实用函数 xclock.ACondition 来实现更复杂的条件等待，例如 await dut.xclock.ACondition(lambda: dut.signal_1.value == 1)。这将会在每次时钟事件触发时检查条件是否满足，如果满足才继续向下执行。\n自定义异步事件\n如果你需要在异步的使用过程中，需要实例化若干 Event 或 Queue 来实现相应的功能，你需要使用 xspcomm 库中提供的 Event 和 Queue 的实现，而不是使用 Python 标准库中的 asyncio.Event 和 asyncio.Queue，这会使自定义事件和时钟触发的先后顺序得不到保证。\n使用 xspcomm 库中的实现可以保证在当前周期所有可被触发的自定义事件都会在下一个周期到来之前被触发。\n更方便的异步使用\npicker 提供的 dut 当中仅提供了最基础的异步功能，如果你需要更加方便的使用异步，可以参考mlvp库的文档，该库提供了更加丰富的异步接口。\n","categories":["教程"],"description":"验证工具的基本使用。","excerpt":"验证工具的基本使用。","ref":"/mlvp/docs/env_usage/picker_usage/","tags":["docs"],"title":"基础使用"},{"body":" 在开始前本页会 简单的介绍什么是验证，以及示例里面用到的概念，如 DUT (Design Under Test) 和 RM (Reference Model) 。\n芯片验证 芯片验证是确保芯片设计正确性和可靠性的重要环节，主要包括功能验证、形式验证和物理验证等形式，本学习材料仅仅包含对功能验证的介绍，且侧重于基于仿真器的芯片功能验证。芯片功能验证的流程和方法与软件测试有比较大的共同点，例如都有单元测试、系统测试、黑盒测试、白盒测试等。在验证指标上也有共同特点，例如功能覆盖率、代码覆盖率等等。从某种形式上说，除了使用的工具和编程语言不一样外，他们的目标和流程几乎相同。因此，在不考虑工具和编程语言的情况下，会软件测试的工程师应当就会芯片验证。 但在实际工作中，软件测试和芯片验证属于两个完全不相交的行业，其主要原因是验证工具和验证语言的不同，导致软件测试工程师很难实现跨界。在芯片验证领域，通常使用硬件描述语言进行验证（例如 Verilog 或者 System Verilog），使用专业商业工具进行电路仿真。硬件描述语言不同于C++/Python等高级软件编程语言，具有独特的“时钟”特性，对于软件领域的工程师不友好，学习成本高。\n为了打通芯片验证与传统软件测试之间的壁垒，让更多的人参与到芯片验证，本项目提供如下内容：\n多语言验证工具（Picker），让用户可以使用自己擅长的编程语言进行芯片验证 验证框架（MLVP），如何在不关心时钟的情况下进行功能验证\n介绍基本电路、验证知识，方便软件背景爱好者更能容易的理解电路特征\n提供基本学习材料，学习基本验证知识\n提供真实高性能芯片验证案例，让爱好者可以远程参与验证工作\n基本术语 DUT： DUT（Design Under Test）指待测试设计，通常指设计好的RTL代码。\nRM： Reference Model （RM）指代待测试单元对应的参考模型，参考模型通常被认为是标准的，没有错误的。\nRTL： 指寄存器传输级（Register Transfer Level），通常指代芯片设计对应的 verilog 或者 vhdl 代码。\n覆盖率： 测试覆盖率是指测试范围与整个需求范围的百分比。在芯片验证领域，通常有代码行覆盖率、函数覆盖率、功能覆盖率等。\nDV： DV中的D通常指设计（Desgin），V指验证（Verification）。何在一起指设计与验证协同工作。\n差分测试（difftest）： 选取两个（或以上）功能相同的被测对象，选取符合被测对象要求的同一测试用例分别提交被测对象进行执行，以观测执行结果是否存在差异的过程。\n工具介绍 本学习材料用到的核心工具为 picker （https://github.com/XS-MLVP/picker），它的作用是将RTL编写的设计模块自动提供高级编程语言接口（Python/C++等）。基于该工具，软件开发（测试）背景的验证人员可以不用去学习 Verilog/VHDL 等硬件描述语言进行芯片验证。\n系统需求 建议操作系统：Ubuntu 22.04 LTS\n在系统结构开发、科研的过程中，Linux 是最为常用的平台，这主要是因为 Linux 拥有丰富的软件、工具资源：由于 Linux 的开源性，各大重要工具软件（如 Verilator）可以很容易地面向 Linux 进行开发。 在本课程的实验中，多语言验证工具Picker、Swig等工具都可以在 Linux 上稳定运行。 ","categories":["示例项目","教程"],"description":"如何使用开放验证平台的环境参与到硬件验证中来。","excerpt":"如何使用开放验证平台的环境参与到硬件验证中来。","ref":"/mlvp/docs/quick-start/","tags":["examples","docs"],"title":"快速开始"},{"body":"原理介绍 基础库 在本章节中，我们将介绍如何使用Picker将RTL代码编译为C++ Class，并编译为动态库。\n首先，Picker工具会解析RTL代码，根据指定的 Top Module ，创建一个新的 Module 封装该模块的输入输出端口，并导出DPI/API以操作输入端口、读取输出端口。\n工具通过指定Top Module所在的文件和 Module Name来确定需要封装的模块。此时可以将 Top 理解为软件编程中的main。\n其次，Picker工具会使用指定的 仿真器 编译RTL代码，并生成一个DPI库文件。该库文件内包含模拟运行RTL代码所需要的逻辑（即为硬件模拟器）。\n对于VCS，该库文件为.so（动态库）文件，对于Verilator，该库文件为.a（静态库）文件。 DPI的含义是 Direct Programming Interface，可以理解为一种API规范。\n接下来，Picker工具会根据配置参数，渲染源代码中定义的基类，生成用于对接仿真器并隐藏仿真器细节的基类（wrapper）。然后链接基类与DPI库文件，生成一个 UT动态库文件。\n此时，该UT库文件使用了Picker工具模板中提供的统一API，相比于DPI库文件中与仿真器强相关的API，UT库文件为仿真器生成的硬件模拟器，提供了统一的API接口。 截至这一步生成UT库文件在不同语言中是通用的！如果没有另行说明，其他高级语言均会通过调用UT动态库以实现对硬件模拟器的操作。 最后，Picker工具会根据配置参数和解析的RTL代码，生成一段 C++ Class 的源码。这段源码即是 RTL 硬件模块在软件中的定义 (.hpp) 及实现 (.cpp) 。实例化该类即相当于创建了一个硬件模块。\n该类继承自基类，并实现了基类中的纯虚函数，以用软件方式实例化硬件。 不将类的实现这一步也封装进动态库的原因有两点：\n由于UT库文件需要在不同语言中通用，而不同语言实现类的方式不同。为了通用性，不将类的实现封装进动态库。 为了便于调试，提升代码可读性，方便用户进行二次封装和修改。 生成可执行文件 在本章节中，我们将介绍如何基于上一章节生成的基础库（包含动态库，类的声明及定义），编写测试用例，生成可执行文件。\n首先，用户需要编写测试用例，即实例化上一章节生成的类，并调用类中的方法，以实现对硬件模块的操作。 详情可以参考随机数生成器验证-配置测试代码中实例化及初始化的过程。\n其次，用户需要根据基础库所应用的不同仿真器，应用不同的链接参数以生成可执行文件。对应的参数在template/cpp/cmake/*.cmake中有定义。\n最终根据配置的链接参数，编译器会链接基础库，生成可执行文件。\n以 加法器验证 为例，picker_out_adder/cpp/cmake/*.cmake即是上述表项2所述模板的拷贝。 vcs.cmake定义了使用VCS仿真器生成的基础库的链接参数，verilator.cmake定义了使用Verilator仿真器生成的基础库的链接参数。\n使用方案 参数 --language cpp 或 -l cpp 用于指定生成C++基础库。 参数 -e 用于生成包含示例项目的可执行文件。 参数 -v 用于保留生成项目时的中间文件。 #include \"UT_Adder.hpp\" int64_t random_int64() { static std::random_device rd; static std::mt19937_64 generator(rd()); static std::uniform_int_distribution\u003cint64_t\u003e distribution(INT64_MIN, INT64_MAX); return distribution(generator); } int main() { #if defined(USE_VCS) UTAdder *dut = new UTAdder(\"libDPIAdder.so\"); #elif defined(USE_VERILATOR) UTAdder *dut = new UTAdder(); #endif // dut-\u003einitClock(dut-\u003eclock); dut-\u003exclk.Step(1); printf(\"Initialized UTAdder\\n\"); struct input_t { uint64_t a; uint64_t b; uint64_t cin; }; struct output_t { uint64_t sum; uint64_t cout; }; for (int c = 0; c \u003c 114514; c++) { input_t i; output_t o_dut, o_ref; i.a = random_int64(); i.b = random_int64(); i.cin = random_int64() \u0026 1; auto dut_cal = [\u0026]() { dut-\u003ea = i.a; dut-\u003eb = i.b; dut-\u003ecin = i.cin; dut-\u003exclk.Step(1); o_dut.sum = (uint64_t)dut-\u003esum; o_dut.cout = (uint64_t)dut-\u003ecout; }; auto ref_cal = [\u0026]() { uint64_t sum = i.a + i.b; bool carry = sum \u003c i.a; sum += i.cin; carry = carry || sum \u003c i.cin; o_ref.sum = sum; o_ref.cout = carry ; }; dut_cal(); ref_cal(); printf(\"[cycle %llu] a=0x%lx, b=0x%lx, cin=0x%lx\\n\", dut-\u003exclk.clk, i.a, i.b, i.cin); printf(\"DUT: sum=0x%lx, cout=0x%lx\\n\", o_dut.sum, o_dut.cout); printf(\"REF: sum=0x%lx, cout=0x%lx\\n\", o_ref.sum, o_ref.cout); Assert(o_dut.sum == o_ref.sum, \"sum mismatch\"); } delete dut; printf(\"Test Passed, destory UTAdder\\n\"); return 0; } 生成波形 在C++中，dut 的析构函数会自动调用 dut.finalize()，因此只需要在测试结束后 delete dut 即可进行后处理工作（写入波形、覆盖率等文件）。\n#include \"UT_Adder.hpp\" int main() { UTAdder *dut = new UTAdder(\"libDPIAdder.so\"); printf(\"Initialized UTAdder\\n\"); for (int c = 0; c \u003c 114514; c++) { auto dut_cal = [\u0026]() { dut-\u003ea = c * 2; dut-\u003eb = c / 2; dut-\u003ecin = i.cin; dut-\u003exclk.Step(1); o_dut.sum = (uint64_t)dut-\u003esum; o_dut.cout = (uint64_t)dut-\u003ecout; }; dut_cal(); printf(\"[cycle %llu] a=0x%lx, b=0x%lx, cin=0x%lx\\n\", dut-\u003exclk.clk, i.a, i.b, i.cin); printf(\"DUT: sum=0x%lx, cout=0x%lx\\n\", o_dut.sum, o_dut.cout); } delete dut; // automatically call dut.finalize() in ~UTAdder() printf(\"Simulation finished\\n\"); return 0; } ","categories":["教程"],"description":"基于C++封装DUT硬件的运行环境，并编译为动态库。","excerpt":"基于C++封装DUT硬件的运行环境，并编译为动态库。","ref":"/mlvp/docs/multi-lang/cpp/","tags":["docs"],"title":"使用 C++"},{"body":"验证报告 https://github.com/yzcccccccccc/XS-MLVP-NutShellCache/blob/master/report/nutshell_cache_report_demo.pdf\n验证环境\u0026用例代码 https://github.com/yzcccccccccc/XS-MLVP-NutShellCache\n","categories":["示例项目","教程"],"description":"利用Python语言对果壳Cache进行验证，","excerpt":"利用Python语言对果壳Cache进行验证，","ref":"/mlvp/docs/advance_case/nutshellcache/","tags":["examples","docs"],"title":"完整果壳 Cache 验证"},{"body":" 本页简单介绍什么是芯片验证，以及示例里面用到的概念，如 DUT (Design Under Test) 和 RM (Reference Model) 。\n芯片验证过程需要和企业、团队的实际情况契合，没有符合所有要求，必须参考的绝对标准。\n什么是芯片验证 芯片从设计到成品的过程主要包括芯片设计、芯片制造、芯片封测试三大阶段。在芯片设计中，又分前端设计和后端设计，前端设计也称之为逻辑设计，目标是让电路逻辑达到预期功能要求。后端设计也称为物理设计，主要工作是优化布局布线，减小芯片面积，降低功耗，提高频率等。芯片验证（Chip Verification）是芯片设计流程中的一个重要环节。它的目标是确保设计的芯片在功能、性能和功耗等方面都满足预定的规格。验证过程通常包括功能验证、时序验证和功耗验证等多个步骤，使用的方法和工具包括仿真、形式验证、硬件加速和原型制作等。针对本文，芯片验证仅包含对芯片前端设计的验证，验证设计的电路逻辑是否满足既定需求（“Does this proposed design do what is intended?\"），通常也称为功能验证（Functional verification），不包含功耗、频率等后端设计。\n对于芯片产品，一旦设计错误被制造出来修改成本将会非常高昂，因为可能需要召回产品，并重新制造芯片，无论是经济成本还是时间成本都十分昂贵。经典由于芯片验证不足导致失败的典型案例如下： Intel Pentium FDIV Bug：在1994年，Intel的Pentium处理器被发现存在一个严重的除法错误，这个错误被称为FDIV bug。这个错误是由于在芯片的浮点单元中，一个查找表中的几个条目错误导致的。这个错误在大多数应用中不会出现，但在一些特定的计算中会导致结果错误。由于这个错误，Intel不得不召回了大量的处理器，造成了巨大的经济损失。\nAriane 5 Rocket Failure：虽然这不是一个芯片的例子，但它展示了硬件验证的重要性。在1996年，欧洲空间局的Ariane 5火箭在发射后不久就爆炸了。原因是火箭的导航系统中的一个64位浮点数被转换为16位整数时溢出，导致系统崩溃。这个错误在设计阶段没有被发现，导致了火箭的失败。\nAMD Barcelona Bug：在2007年，AMD的Barcelona处理器被发现存在一个严重的转译查找缓冲（TLB）错误。这个错误会导致系统崩溃或者重启。AMD不得不通过降低处理器的频率和发布BIOS更新来解决这个问题，这对AMD的声誉和财务状况造成了重大影响。\n这些案例都强调了芯片验证的重要性。如果在设计阶段就能发现并修复这些错误，那么就可以避免这些昂贵的失败。验证不足的案例不仅发生在过去，也发生在现在，例如某新入局 ASIC 芯片市场的互联网企业打造一款 55 纳米芯片，极力追求面积缩减并跳过验证环节，最终导致算法失败，三次流片皆未通过测试，平均每次流片失败导致企业损失约 50 万美元。\n芯片验证流程 芯片设计和验证的耦合关系如上图所示，设计和验证有同样的输入，即规范文档（specification）。参考规范，设计与验证人员双方按照各自的理解，以及各自的需求进行独立编码实现。设计方需要满足的前提是编码的RTL代码“可综合”，需要考虑电路特性，而验证方一般只要考虑功能是否满足要求，编码限制少。双方完成模块开发后，需要进行健全性对比测试（Sanity Test），判定功能是否表现一致，若不一致需要进行协同排查，确定问题所在并进行修复，再进行对比测试，直到所有功能点都满足预期。由于芯片设计和芯片验证耦合度很高，因此有些企业在研发队伍上也进行了直接耦合，为每个子模块的设计团队都配置了对应的验证团队（DV）。上图中的设计与验证的耦合流程为粗粒度的关系，具体到具体芯片（例如Soc、DDR）、具体企业等都有其适合自身的合作模式。\n在上述对比测试中，设计方的产出的模块通常称为DUT（Design Under Test），验证方开发的模型通常称为RM（Reference Model）。针对图中的验证工作，按照流程可以有：编写验证计划、创建验证平台、整理功能点、构建测试用例、运行调试、收集Bug/覆盖率、回归测试、编写测试报告等多个阶段。\n验证计划： 验证计划描述了如何进行验证，以及如何保证验证质量，达到功能验证要求。在文档结构上通常包含验证目标，验证策略、验证环境、验证项、验证过程、风险防范、资源及时间表、结果和报告等部分。验证目标明确需要验证的功能或性能指标，这些目标应该直接从芯片的规范文档中提取。验证策略描述如何进行验证，包括可能使用的验证方法，例如仿真、形式化、FPGA加速等，以及如何组织验证任务。验证环境用于描述具体的测试环境，例如验证工具类型，版本号等。验证项库俄超关羽需要验证的具体项以及预期结果。验证计划可以有总计划，也可以针对具体验证的子任务进行编写。\n平台搭建： 验证平台是具体验证任务的执行环境，同一类验证任务可以使用相同的验证平台。验证平台的搭建是验证流程中的关键步骤、具体包含验证工具选择（例如是采用软件仿真，还是采用形式化验证，或者硬件加速）、环境配置（例如配置服务器环境，FPGA环境）、创建测试环境、基本测试案例等。创建好基本测试平台，跑通基本测试案例，也通常称为“冒烟测试”。后继具体的测试代码，都将基于该测试平台进行，因此测试平台需要具有可重用性。验证平台通过包含测试框架和被测试代码，以及对应的基本信号激励。\n功能点整理： 功能点整理，即需要根据规范手册（spec）列出DUT的基本功能，并对其进行明确的描述，以及如何对该功能点进行测试。功能点整理过程中，需要根据重要性、风险、复杂性等因数对其进行优先级排序。功能点整理还需要对各个功能点进行追踪和状态，如果发现原始功能点有更新需要及时进行对应计划的同步。\n测试用例： 测试用例是指一组条件或变量，用于确定DUT是否满足特定需求并能正确运行。每个测试用例通常包含测试条件，输入数据，预期结果，实际结果和测试结果。通过运行测试用例并比较预期结果和实际结果，可以确定系统或应用是否正确实现了特定的功能或需求。在芯片验证中，测试用例是用来验证芯片设计是否满足规格要求的重要工具。\n编码实现： 编码实现即对测试用例的具体执行过程，包括测试数据生成、测试框架选择、编程语言选择、参考模型编写等。编码实现是对功能点和测试用例充分理解后工作，如果理解不到位，可能导致DUT无法驱动，不能发现潜在bug等问题。\n收集bug/覆盖率： 验证的目标就是提前发现设计中存在的bug，因此需要对发现的bug进行收集和管理。没发现一个新缺陷，需要给定唯一标号，并同设计工程师进行bug定级，然后进行状态追踪。能发现bug最好，但在实际验证中不是每次测试都能发现bug，因此需要另外一个指标评价验证是否到位。该指标通常采用覆盖率，当覆盖率超过一点阈值（例如代码覆盖率大于90%）后方可任务进行了充分验证。\n回归测试： 验证和设计是一个相互迭代的过程，因此当验证出bug后，需要设计进行修正，且需要保证修正后的DUT仍然能正常工作。这种测试的目的是捕获可能由于修改而引入的新错误，或者重新激活旧错误。回归测试可以是全面的，也就是说，它涵盖了所有的功能，或者可以是选择性的，只针对某些特定的功能或系统部分。\n测试报告： 测试报告是对整个验证过程的总结，它提供了关于测试活动的全面视图，包括测试的目标、执行的测试用例、发现的问题和缺陷、测试覆盖率和测试效率等。\n芯片验证层次 按照验证对象的大小，芯片验证通常包含UT、BT、IT、ST四个层次。\n单元测试（Unit Testing， UT）： 这是最低的验证层次，主要针对单个模块或组件进行。目标是验证每个模块或组件的功能是否正确。\n块测试（Block Testing，BT）： 很多时候，单个模块和其他模块存在紧耦合，如果进行单独UT测试，可能存在信号处理复杂，功能验证不准确等问题，这时候可以把多个有耦合关系的模块合并成一个DUT块进行测试。\n集成测试（Integration Testing）： 在单元测试的基础上，将多个模块或组件组合在一起，验证它们能否正确地协同工作，通常用于测试子系统功能是否正常。\n系统测试（System Testing）： ST通常也称为Top验证，在集成测试的基础上，将所有的模块或组件组合在一起，形成一个完整的系统，验证系统的功能是否正确，以及系统的性能是否满足要求。\n理论上，这些层次的验证通常按照从低到高的顺序进行，每个层次的验证都建立在前一个层次的验证的基础上。但实际验证活动中，需要根据企业验证人员的规模、熟练度，功能需求等进行选择，不一定所有层次的验证都需要涉及。在每个层次，都需要编写相应的测试用例，运行测试，收集和分析结果，以确保芯片设计的正确性和质量。\n芯片验证指标 芯片验证的指标，通常包含功能正确性、测试覆盖率、缺陷密度、验证效率、验证成本等多个方面。功能正确性是最基本的验证指标，即芯片是否能够正确地执行其设计的功能。这通常通过运行一系列的功能测试用例来验证，包括正常情况下的功能测试，以及异常情况下的鲁棒性测试。测试覆盖率是指测试用例覆盖了多少设计的功能点，以及覆盖的程度如何。高的测试覆盖率通常意味着更高的验证质量。测试覆盖率可以进一步细分为代码覆盖率、功能覆盖率、条件覆盖率等。缺陷密度是指在一定的设计规模或代码量中，发现的缺陷的数量。低的缺陷密度通常意味着更高的设计质量。验证效率是指在一定的时间和资源下，能够完成的验证工作量。高的验证效率通常意味着更高的验证生产力。验证成本是指进行验证所需要的总体资源，包括人力、设备、时间等。低的验证成本通常意味着更高的验证经济性。\n功能正确性是验证的绝对指标，但在实践中，很多时候无法确定测试方案是否完备，所有测试空间是否全部测试到位，因此需要一个可量化的指标来指导验证是否足够充分，是否可以结束验证。该指标通常采用“测试覆盖率”。测试覆盖率通常有代码覆盖率（行，函数，分支）、功能覆盖率。\n代码行覆盖率： 即在测试过程中，DUT的设计代码中有多少行被执行；\n函数覆盖率： 即在测试过程中，DUT的设计代码中有多少函数被执行；\n分支覆盖率： 即在测试过程中，DUT的设计代码中有多少分支被执行（if else）；\n功能覆盖率： 即在测试过程中，有多少预定义功能被触发。\n高的代码覆盖率可以提高验证的质量和可靠性，但并不能保证验证的完全正确性，因为它不能覆盖所有的输入和状态组合。因此，除了追求高的代码覆盖率，还需要结合其他测试方法和指标，如功能测试、性能测试、缺陷密度等。\n芯片验证管理 芯片验证管理是一个涵盖了芯片验证过程中所有活动的管理过程，包括之前提到的验证策略的制定、验证环境的搭建、测试用例的编写和执行、结果的收集和分析、以及问题和缺陷的跟踪和修复等。芯片验证管理的目标是确保芯片设计满足所有的功能和性能要求，以及规格和标准。\n在芯片验证管理中，首先需要制定一个详细的验证策略，包括验证的目标、范围、方法、时间表等。然后，需要搭建一个适合的验证环境，包括硬件设备、软件工具、测试数据等。接下来，需要编写一系列的测试用例，覆盖所有的功能和性能点，然后执行这些测试用例，收集和分析结果，找出问题和缺陷。最后，需要跟踪和修复这些问题和缺陷，直到所有的测试用例都能通过。\n芯片验证管理是一个复杂的过程，需要多种技能和知识，包括芯片设计、测试方法、项目管理等。它需要与芯片设计、生产、销售等其他活动紧密协作，以确保芯片的质量和性能。芯片验证管理的效果直接影响到芯片的成功和公司的竞争力。因此，芯片验证管理是芯片开发过程中的一个重要环节。\n芯片验证管理过程可以基于“项目管理平台”和“bug管理平台”进行，基于平台的管理效率通常情况下明显高于基于人工的管理模式。\n芯片验证现状 当前，芯片验证通常是在芯片设计公司内部完成的，这一过程不仅技术上复杂，而且具有巨大的成本。从验收与设计的紧密关系来看，芯片验证不可避免地涉及芯片设计的源代码。然而，芯片设计公司通常将芯片设计源代码视为商业机密，这使得必须由公司内部人员来执行芯片验证，难以将验证工作外包。\n芯片验证的重要性在于确保设计的芯片在各种条件下能够可靠运行。验证工作不仅仅是为了满足技术规格，还需要应对不断增长的复杂性和新兴技术的要求。随着半导体行业的发展，芯片验证的工作量不断增加，尤其是对于复杂的芯片而言，验证工作已经超过了设计工作，占比超过70%。这使得在工程师人员配比上，验证工程师人数通常是设计工程师人数的2倍或以上（例如zeku的三千人规模团队中，大约有一千人的设计工程师，两千人的验证工程师。其他大型芯片设计公司的验证人员占比类似或更高）。\n由于验证工作的特殊性，需要对芯片设计源代码进行访问，这在很大程度上限制了芯片验证的外包可能性。芯片设计源代码被视为公司的核心商业机密，涉及到技术细节和创新，因此在安全和法律层面上不太可能与外部方共享。这也导致了公司内部人员必须承担验证工作的重任，增加了公司内部的工作负担和成本。\n在当前情况下，芯片验证工程师的需求持续增加。他们需要具备深厚的技术背景，熟悉各种验证工具和方法，并且对新兴技术有敏锐的洞察力。由于验证工作的复杂性，验证团队通常需要庞大的规模，这与设计团队规模形成鲜明对比。\n为了应对这一挑战，行业可能需要不断探索创新的验证方法和工具，以提高验证效率，降低成本。\n小结：复杂芯片验证成本昂贵，表现在如下几个方面 验证工作量大： 对于复杂芯片，验证工作在整个芯片设计工作中，占比超过 70%。\n人力成本高： 验证工程师人数是设计工程师人数的2倍，对于复杂业务，工程师数量在千人以上。\n内部验证： 芯片设计公司为了保证商业秘密（芯片设计代码）不被泄露，只能选择招聘大量验证工程师，在公司内部进行验证工作。\n芯片验证众包 相比与硬件，软件领域为了减少软件测试成本，测试外包（分包）已经成为常态，该领域的分包业务非常成熟，市场规模已经是千亿人民币级别，并朝万亿级别规模进发。从工作内容上看，软件测试和硬件验证，有非常大的共同特征（系统的目的不同的对象），如果以软件的方式对硬件验证进行分包是否可行？\n把芯片验证工作进行外包（分包）面临诸多挑战，例如： 从业人员基数少： 相比软件领域，硬件开发者数量少了几个数量级。例如在github的统计上（https://madnight.github.io/githut/#/pull_requests/2023/2），传统软件编程语言占（Python、Java、C++，Go）比接近 50%， 而硬件描述语言，verilog占比仅 0.076%，这能从侧面反应出各自领域的开发者数量。\n验证工具商业化： 企业中使用的验证工具（仿真器、形式化、数据分析）几乎都是商业工具，这类工具对于普通人来说几乎不可见，自学难度高。\n开放学习资料少： 芯片验证涉及到访问芯片设计的源代码，而这些源代码通常被视为公司的商业机密和专有技术。芯片设计公司可能不愿意公开详细的验证过程和技术，限制了学习材料的可用性。\n可行性分析 虽然芯片验证领域一直以来相对封闭，但从技术角度而言，采用分包的方式进行验证是一种可行的选择。这主要得益于以下几个因素：\n首先，随着开源芯片项目的逐渐增多，验证过程中所涉及的源代码已经变得更加开放和透明。这些开源项目在设计和验证过程中没有商业机密的顾虑，为学习和研究提供了更多的可能性。即使某些项目涉及商业机密，也可以通过采用加密等方式来隐藏设计代码，从而在一定程度上解决了商业机密的问题，使验证更容易实现。\n其次，芯片验证领域已经涌现出大量的基础验证工具，如verilator和systemc等。这些工具为验证工程师提供了强大的支持，帮助他们更高效地进行验证工作。通过这些工具，验证过程的复杂性和难度得到了一定程度的缓解，为采用分包的验证方法提供了更为可行的技术基础。\n在开源软件领域，已经有一些成功的案例可供参考。例如，Linux内核的验证过程采用了分包的方式，不同的开发者和团队分别负责不同的模块验证，最终形成一个整体完备的系统。类似地，机器学习领域的ImageNet项目也采用了分包标注的策略，通过众包的方式完成大规模的图像标注任务。这些案例为芯片验证领域提供了成功的经验，证明了分包验证在提高效率、降低成本方面的潜力。\n因此，尽管芯片验证领域相对于其他技术领域而言仍显得封闭，但技术的进步和开源项目的增多为采用分包验证提供了新的可能性。通过借鉴其他领域的成功经验和利用现有的验证工具，我们有望在芯片验证中推动更加开放、高效的验证方法的应用，进一步促进行业的发展。这种技术的开放性和灵活性将为验证工程师提供更多的选择，推动芯片验证领域迎来更为创新和多样化的发展。\n技术路线 为了克服挑战，让更多的人参与到芯片验证，本项目从如下几个技术方向进行持续尝试\n提供多语言验证工具： 传统芯片验证是基于System Verilog编程语言进行，但是该语言用户基数少，为了让其他软件开发/测试的技术人员参与到芯片验证，本项目提供多语言验证转换工具Picker，它可以让验证者使用自己熟悉的编程语言（例如C++/Python/Java/Go）基于开源验证工具参与验证工作。\n提供验证学习材料： 芯片验证学习材料少，主要原因由于商业公司几乎不可能公开其内部资料，为此本项目会持续更新学习材料，让验证人员可在线，免费学习所需要的技能。\n提供真实芯片验证案例： 为了让学习材料更具使用性，本项目以“香山昆明湖（工业级高性能risc-v处理器）IP核”作为基础，从中摘取模块持续更新验证案例。\n组织芯片设计分包验证： 学以致用是每个人学习的期望目标，为此本项目定期组织芯片设计的验证分包，让所有人（无论你是大学生、验证专家、软件开发测试者、还是中学生）都可以参与到真实芯片的设计工作中去。\n本项目的目标是达到如下愿景，“打开传统验证模式的黑盒，让所有感兴趣的人可以随时随地的，用自己擅长的编程语言参与芯片验证”。\n","categories":"","description":"关于芯片验证的基本概念\n","excerpt":"关于芯片验证的基本概念\n","ref":"/mlvp/docs/basic/ic_verify/","tags":"","title":"芯片验证"},{"body":"Asynchronous Programming Overview Why Introduce Asynchronous Programming? In the previous section, we learned how to use callback functions. However, when using callback functions, we may encounter callback hell. This means that if callbacks are nested too deeply, the code can become very complex and difficult to manage. Therefore, we can avoid this situation by using asynchronous (async/await) methods. Using asynchronous methods can make the code structure clearer. By using the await keyword, asynchronous operations can be executed sequentially without the need for managing the execution order through callback functions.\nImplementation Principle In Python’s asyncio, asynchronous programming is based on the following three core concepts, which will be explained in more detail in the next section.\nCallback Functions (Callback) Callback functions that are pre-registered are the basis of asynchronous programming. When a task is completed, the system calls the callback function to process the result of the task. Through callback functions, the program can continue to execute other tasks while waiting for the task to be completed, improving program concurrency. Event Loop The event loop is one of the core mechanisms of asynchronous programming. It is responsible for listening to various events (such as user input, I/O operations, etc.). When an event occurs, it triggers the corresponding callback function for processing. The event loop implements non-blocking task processing by continuously polling the event queue. Coroutine Coroutines are tasks defined by users. Common Asynchronous Programming Frameworks and Tools To facilitate developers in asynchronous programming, there are many excellent frameworks and tools to choose from. Here are some common asynchronous programming frameworks and tools:\nAsyncio Asyncio is a powerful asynchronous programming framework in Python that provides efficient coroutine support. It can be used to write network applications, web crawlers, etc., with excellent concurrency performance. Node.js Node.js is a JavaScript runtime environment built on the Chrome V8 engine, which inherently supports non-blocking I/O operations. It is widely used in web development and excels in handling high-concurrency real-time applications. RxJava RxJava is an asynchronous programming library based on the observer pattern and iterator pattern. It provides Java developers with rich operators and combination methods, simplifying the complexity of asynchronous programming. In Python, to use asynchronous programming, you need to use the async and await keywords.\nasync: Used to define asynchronous functions. In asynchronous functions, asynchronous operations are typically included. await: Used to wait for asynchronous operations to complete in asynchronous functions. Here is a simple Python code to demonstrate the usage of async and await keywords:\nasync def my_async_function(): print(\"Start async_function and wait some funcion \") await some_other_async_function() print(\"End of my_async_function\") In Python, asyncio module is commonly used for asynchronous operations. In the following example, we define a greet function that prints “Hello, \" + name and “Goodbye, \" + name, with a 2-second interval between the two prints. We use asyncio.create_task to create two asynchronous tasks and collect the execution results.\nasyncio.create_task(): Used to create a coroutine task and schedule it for immediate execution. asyncio.gather(): Waits for all coroutine tasks to complete and can collect the execution results. asyncio.sleep(): Waits for a period in asynchronous operations. import asyncio # Define an asynchronous function async def greet(name): print(\"Hello, \" + name) await asyncio.sleep(2) # Use asynchronous sleep function print(\"Goodbye, \" + name) # Execute the asynchronous function async def main(): # Create and execute tasks concurrently task1 = asyncio.create_task(greet(\"verify chip\")) task2 = asyncio.create_task(greet(\"picker\")) # Wait for all tasks to complete await asyncio.gather(task1, task2) # Run the main function if __name__ == \"__main__\": asyncio.run(main()) The greet(“verify chip”) is executed first, printing “Hello, verify chip”. When encountering await, it switches to execute greet(“picker”), printing “Hello, picker”. After the awaited operations are completed, both tasks output “Goodbye, verify chip” and “Goodbye, picker”. Advantages of Asynchronous Programming Asynchronous programming has several significant advantages:\nImproved Response Speed Through asynchronous programming, programs can continue to execute other tasks while waiting for a task to complete, avoiding the delay caused by task blocking. This can greatly improve the program’s response speed and enhance user experience. Enhanced Concurrency Performance Asynchronous programming allows programs to handle multiple tasks simultaneously, making full use of computing resources and improving system concurrency. Especially in handling a large number of I/O-intensive tasks, asynchronous programming can better leverage its advantages and reduce resource consumption. Simplified Programming Logic Asynchronous programming can avoid writing complex multithreaded code, reducing the complexity of the program and the probability of errors. By simplifying the programming logic, developers can focus more on implementing business logic. Therefore, asynchronous programming is widely used in the following areas:\nWeb Development In web development, asynchronous programming is commonly used to handle tasks such as network requests and database operations. By processing these tasks asynchronously, the main thread is not blocked, ensuring the concurrent performance of the web server. Parallel Computing Asynchronous programming can help achieve parallel computing by splitting a large task into multiple smaller tasks and executing them concurrently, improving computing efficiency. This is very common in scientific computing and data processing. Message Queues Message queues are one of the classic applications of asynchronous programming. Asynchronous message queues can achieve decoupling and asynchronous communication between different systems, improving system scalability and stability. Asynchronous Usage in Picker For example, in Picker, we can control the flow of code execution through cycles using the following methods:\nawait clk.AStep(3): Wait for clock clk to advance 3 clock cycles. The await keyword makes the program pause execution here until the clock has advanced the specified number of clock cycles before continuing execution. await clk.ACondition(lambda: clk.clk == 20): It waits for the condition clk.clk == 20 to be true. Similarly, the program pauses execution here until the condition is true before continuing execution. async def test_async(): clk = XClock(lambda a: 0) clk.StepRis(lambda c : print(\"lambda ris: \", c)) task = create_task(clk.RunStep(30)) print(\"test AStep:\", clk.clk) await clk.AStep(3) print(\"test ACondition:\", clk.clk) await clk.ACondition(lambda: clk.clk == 20) print(\"test cpm:\", clk.clk) await task Using Asynchronous to Verify the Adder Here we continue to use the rising edge triggered adder as an example, and we have made some minor changes to the previous code, replacing the generation and waiting for clock signals with asynchronous methods provided by picker:\nThe Step(i) method of XClock will advance the clock signal by i clock cycles, with two main functions:\nGenerate the clock signal for i clock cycles. Wait for the clock to pass through i cycles. In asynchronous programming, these two functions correspond to two asynchronous methods provided by XClock:\nRunStep(i)：Generates the clock signal for i clock cycles. You need to create a task with asyncio.create_task and use await at the end of the test code to wait for its completion. AStep(i)：Waits for the clock to pass through i cycles. If the RunStep(i) method completes before AStep(i), the entire program will be blocked at AStep(i).\nTest Code Using Asynchronous from UT_RisAdder import * import random import asyncio # Control font colors FONT_GREEN = \"\\033[0;32m\" # Green FONT_RED = \"\\033[0;31m\" # Red FONT_COLOR_RESET = \"\\033[0m\" # Reset color class SimpleRisAdder: \"\"\" The SimpleRisAdder class is a reference adder class, it simulates the expected behavior of our RisAdder \"\"\" def __init__(self, width) -\u003e None: self.WIDTH = width # Bit width of the adder # Port definition self.a = 0 # Input port a self.b = 0 # Input port b self.cin = 0 # Input port cin self.cout = 0 # Output port cout self.sum = 0 # Output port sum def step(self, a, b, cin): \"\"\" Simulate rising edge update output: first update the output with the input of the previous cycle, and then update the input \"\"\" sum = self.a + self.b + self.cin self.cout = sum \u003e\u003e self.WIDTH # Calculate carry self.sum = sum \u0026 ((1 \u003c\u003c self.WIDTH) - 1) # Calculate sum self.a = a # Update input a self.b = b # Update input b self.cin = cin # Update input cin # Test function to verify the output of the adder def test_adder(clk: int, dut: DUTRisAdder, ref: SimpleRisAdder) -\u003e None: # Get the input and output of the adder a = dut.a.value b = dut.b.value cin = dut.cin.value cout = dut.cout.value sum = dut.sum.value # Check if the output of the adder matches the expected isEqual = (cout, sum) == (ref.cout, ref.sum) # Output test result print(f\"Cycle: {clk}, Input(a, b, cin) = ({a:x}, {b:x}, {cin:x})\") print( FONT_GREEN + \"Pass.\" # Output green \"Pass.\" if the test passes if isEqual else FONT_RED + f\"MisMatch! Expect cout: {ref.cout:x}, sum: {ref.sum:x}.\" + FONT_COLOR_RESET + f\"Get cout: {cout:x}, sum: {sum:x}.\" ) assert isEqual # Trigger an assertion exception if the test fails # Asynchronous function for running tests async def run_test(): WIDTH = 32 # Set the bit width of the adder ref = SimpleRisAdder(WIDTH) # Create a reference adder dut = DUTRisAdder() # Create the adder under test # Bind the clock signal dut.init_clock(\"clk\") # Set the dut input signal to 0 dut.a.value = 0 dut.b.value = 0 dut.cin.value = 0 task = asyncio.create_task( dut.runstep(114514 + 1) # Create an asynchronous task to simulate the clock signal continuously for (114514+1) cycles ) await dut.astep(1) # Wait for the clock to enter the next cycle dut.StepRis(test_adder, (dut, ref)) # Register the function triggered on the rising edge of the clock # Start testing for _ in range(114514): # Generate random inputs a = random.randint(0, (1 \u003c\u003c WIDTH) - 1) b = random.randint(0, (1 \u003c\u003c WIDTH) - 1) cin = random.randint(0, 1) ref.step(a, b, cin) # Update the status of the reference adder dut.a.value = a # Set the input a of the adder under test dut.b.value = b # Set the input b of the adder under test dut.cin.value = cin # Set the input cin of the adder under test await dut.astep(1) # Wait for the clock to enter the next cycle await task # Wait for the clock to finish dut.finalize() if __name__ == \"__main__\": asyncio.run(run_test()) # Run the test pass ","categories":["Example Projects","Tutorials"],"description":"Simplifying callbacks using asynchronous mode","excerpt":"Simplifying callbacks using asynchronous mode","ref":"/mlvp/en/docs/advance_func/async/","tags":["examples","docs"],"title":"Asynchronous Programming"},{"body":" This page introduces the basics of digital circuits. Digital circuits use digital signals and are the foundation of most modern computers.\nWhat Are Digital Circuits Digital circuits are electronic circuits that use two discrete voltage levels to represent information. Typically, digital circuits use two power supply voltages to indicate high (H) and low (L) levels, representing the digits 1 and 0 respectively. This representation uses binary signals to transmit and process information.\nMost digital circuits are built using field-effect transistors, with MOSFETs (Metal-Oxide-Semiconductor Field-Effect Transistors) being the most common. MOSFETs are semiconductor devices that control current flow using an electric field, enabling digital signal processing.\nIn digital circuits, MOSFETs are combined to form various logic gates like AND, OR, and NOT gates. These logic gates are combined in different ways to create the various functions and operations in digital circuits. Here are some key features of digital circuits:\n(1) Voltage Representation： Digital circuits use two voltage levels, high and low, to represent digital information. Typically, a high level represents the digit 1, and a low level represents the digit 0.\n(2) MOSFET Implementation： MOSFETs are one of the most commonly used components in digital circuits. By controlling the on and off states of MOSFETs, digital signal processing and logic operations can be achieved.\n(3) Logic Gate Combinations： Logic gates, composed of MOSFETs, are the basic building blocks of digital circuits. By combining different logic gates, complex digital circuits can be built to perform various logical functions.\n(4) Binary Representation： Information in digital circuits is typically represented using the binary system. Each digit can be made up of a series of binary bits, which can be processed and operated on within digital circuits.\n(5) Signal Processing： Digital circuits convert and process signals through changes in voltage and logic operations. This discrete processing method makes digital circuits well-suited for computing and information processing tasks.\nWhy Learn Digital Circuits Learning digital circuits is fundamental and necessary for the chip verification process, primarily for the following reasons:\n(1) Understanding Design Principles： Digital circuits are the foundation of chip design. Knowing the basic principles and design methods of digital circuits is crucial for understanding the structure and function of chips. The goal of chip verification is to ensure that the designed digital circuits work according to specifications in actual hardware, and understanding digital circuits is key to comprehending the design.\n(2) Design Standards： Chip verification typically involves checking whether the design meets specific standards and functional requirements. Learning digital circuits helps in understanding these standards, thus building better test cases and verification processes to ensure thorough and accurate verification.\n(3) Timing and Clocks： Timing issues are common challenges in digital circuit design and verification. Learning digital circuits helps in understanding concepts of timing and clocks, ensuring that timing issues are correctly handled during verification, avoiding timing delays and conflicts in the circuit.\n(4) Logical Analysis： Chip verification often involves logical analysis to ensure circuit correctness. Learning digital circuits fosters a deep understanding of logic, aiding in logical analysis and troubleshooting.\n(5) Writing Test Cases： In chip verification, various test cases need to be written to ensure design correctness. Understanding digital circuits helps in designing comprehensive and targeted test cases, covering all aspects of the circuit.\n(6) Signal Integrity： Learning digital circuits helps in understanding signal propagation and integrity issues within circuits. Ensuring proper signal transmission under different conditions is crucial, especially in high-speed designs.\nOverall, learning digital circuits provides foundational knowledge and tools for chip verification, enabling verification engineers to better understand designs, write effective test cases, analyze verification results, and troubleshoot issues. Theoretical and practical experience with digital circuits is indispensable for chip verification engineers.\nDigital Circuits Basics You can learn digital circuits through the following online resources：\nTsinghua University’s Digital Circuits Basics USTC Digital Circuit Lab Digital Design and Computer Architecture MIT Analysis and Design of Digital Integrated Circuits Hardware Description Language Chisel Traditional Description Languages Hardware Description Languages (HDL) are languages used to describe digital circuits, systems, and hardware. They allow engineers to describe hardware structure, function, and behavior through text files, enabling abstraction and modeling of hardware designs.\nHDL is commonly used for designing and simulating digital circuits such as processors, memory, controllers, etc. It provides a formal method to describe the behavior and structure of hardware circuits, making it easier for design engineers to perform hardware design, verification, and simulation.\nCommon hardware description languages include:\nVerilog：One of the most used HDLs, Verilog is an event-driven language widely used for digital circuit design, verification, and simulation. VHDL：Another common HDL, VHDL is an object-oriented language offering richer abstraction and modular design methods. SystemVerilog：An extension of Verilog, SystemVerilog introduces advanced features like object-oriented programming and randomized testing, making Verilog more suitable for complex system design and verification. Chisel Chisel is a modern, advanced hardware description language that differs from traditional Verilog and VHDL. It’s a hardware construction language based on Scala. Chisel offers a more modern and flexible way to describe hardware, leveraging Scala’s features to easily implement parameterization, abstraction, and reuse while maintaining hardware-level efficiency and performance.\nChisel’s features include:\nModern Syntax: Chisel’s syntax is more similar to software programming languages like Scala, making hardware description more intuitive and concise. Parameterization and Abstraction: Chisel supports parameterization and abstraction, allowing for the creation of configurable and reusable hardware modules. Type Safety: Based on Scala, Chisel has type safety features, enabling many errors to be detected at compile-time. Generating Performance-Optimized Hardware: Chisel code can be converted to Verilog and then synthesized, placed, routed, and simulated by standard EDA toolchains to generate performance-optimized hardware. Strong Simulation Support: Chisel provides simulation support integrated with ScalaTest and Firrtl, making hardware simulation and verification more convenient and flexible. Chisel Example of a Full Adder The circuit design is shown below:\nComplete Chisel code:\npackage examples import chisel3._ class FullAdder extends Module { // Define IO ports val io = IO(new Bundle { val a = Input(UInt(1.W)) // Input port 'a' of width 1 bit val b = Input(UInt(1.W)) // Input port 'b' of width 1 bit val cin = Input(UInt(1.W)) // Input port 'cin' (carry-in) of width 1 bit val sum = Output(UInt(1.W)) // Output port 'sum' of width 1 bit val cout = Output(UInt(1.W))// Output port 'cout' (carry-out) of width 1 bit }) // Calculate sum bit (sum of a, b, and cin) val s1 = io.a ^ io.b // XOR operation between 'a' and 'b' io.sum := s1 ^ io.cin // XOR operation between 's1' and 'cin', result assigned to 'sum' // Calculate carry-out bit val s3 = io.a \u0026 io.b // AND operation between 'a' and 'b', result assigned to 's3' val s2 = s1 \u0026 io.cin // AND operation between 's1' and 'cin', result assigned to 's2' io.cout := s2 | s3 // OR operation between 's2' and 's3', result assigned to 'cout' } You can refer to Chisel learning materials from the official documentation: https://www.chisel-lang.org/docs\n","categories":"","description":"Basic concepts of digital circuits\n","excerpt":"Basic concepts of digital circuits\n","ref":"/mlvp/en/docs/basic/ic_base/","tags":"","title":"Digital Circuits"},{"body":" This page will briefly introduce what verification is and concepts used in the examples, such as DUT (Design Under Test) and RM (Reference Model).\n","categories":["Sample Projects","Tutorials"],"description":"Detailed usage instructions for the Open Verification Platform environment.","excerpt":"Detailed usage instructions for the Open Verification Platform …","ref":"/mlvp/en/docs/env_usage/","tags":["examples","docs"],"title":"Environment Usage"},{"body":"","categories":["Example Projects","Tutorials"],"description":"Using TileLink Protocol for L2 Cache Driven by C++","excerpt":"Using TileLink Protocol for L2 Cache Driven by C++","ref":"/mlvp/en/docs/advance_case/tilelink/","tags":["examples","docs"],"title":"TileLink Protocol"},{"body":"","categories":["示例项目","教程"],"description":"基于C++驱动使用 TillLink 协议的 L2 Cache","excerpt":"基于C++驱动使用 TillLink 协议的 L2 Cache","ref":"/mlvp/docs/advance_case/tilelink/","tags":["examples","docs"],"title":"TileLink 协议"},{"body":" Introduction to chip verification using the Guoke Cache as an example, covering the basic verification process and report writing.\n","categories":["Sample Projects","Tutorials"],"description":"Introduction to the basic knowledge required for working with the open verification platform.","excerpt":"Introduction to the basic knowledge required for working with the open …","ref":"/mlvp/en/docs/basic/","tags":["examples","docs"],"title":"Verification Basics"},{"body":"Usage When using the Picker tool to encapsulate the DUT, use the -w [wave_file] option to specify the waveform file to be saved. Different waveform file types are supported for different backend simulators, as follows:\nVerilator .vcd format waveform file. .fst format waveform file, a more efficient compressed file. VCS .fsdb format waveform file, a more efficient compressed file. Note that if you choose to generate the libDPI_____.so file yourself, the waveform file format is not restricted by the above constraints. The waveform file format is determined when the simulator constructs libDPI.so, so if you generate it yourself, you need to specify the waveform file format using the corresponding simulator’s configuration.\nPython Example Normally, the DUT needs to be explicitly declared complete to notify the simulator to perform post-processing tasks (writing waveform, coverage files, etc.). In Python, after completing all tests, call the .finalize() method of the DUT to notify the simulator that the task is complete, and then flush the files to disk.\nUsing the Adder Example, the test program is as follows:\nfrom UT_Adder import * if __name__ == \"__main__\": dut = DUTAdder() for i in range(10): dut.a.value = i * 2 dut.b.value = int(i / 4) dut.Step(1) print(dut.sum.value, dut.cout.value) dut.finalize() # flush the wave file to disk After the run is completed, the waveform file with the specified name will be generated.\nViewing Results GTKWave Use GTKWave to open fst or vcd waveform files to view the waveform.\nVerdi Use Verdi to open fsdb or vcd waveform files to view the waveform.\n","categories":["Sample Projects","Tutorials"],"description":"Generate circuit waveforms.","excerpt":"Generate circuit waveforms.","ref":"/mlvp/en/docs/env_usage/wave/","tags":["examples","docs"],"title":"Waveform Generation"},{"body":"使用方法 在使用 Picker 工具封装 DUT 时，使用选项-w [wave_file]指定需要保存的波形文件。 针对不同的后端仿真器，支持不同的波形文件类型，具体如下：\nVerilator .vcd格式的波形文件。 .fst格式的波形文件，更高效的压缩文件。 VCS .fsdb格式的波形文件，更高效的压缩文件。 需要注意的是，如果你选择自行生成 libDPI_____.so 文件，那么波形文件格式不受上述约束的限制。因为波形文件是在仿真器构建 libDPI.so 时决定的，如果你自行生成，那么波形文件格式也需要自行用对应仿真器的配置指定。\nPython 示例 正常情况下，dut需要被显式地声明完成任务，以通知进行模拟器的后处理工作（写入波形、覆盖率等文件）。 在Python中，需要在完成所有测试后，调用dut的.finalize()方法以通知模拟器任务已完成，进而将文件flush到磁盘。\n以加法器为例，以下为测试程序：\nfrom UT_Adder import * if __name__ == \"__main__\": dut = DUTAdder() for i in range(10): dut.a.value = i * 2 dut.b.value = int(i / 4) dut.Step(1) print(dut.sum.value, dut.cout.value) dut.finalize() # flush the wave file to disk 运行结束后即可生成指定文件名的波形文件。\n查看结果 GTKWave 使用 GTKWave 打开 fst 或 vcd 波形文件，即可查看波形图。\nVerdi 使用 Verdi 打开 fsdb 或 vcd 波形文件，即可查看波形图。\n","categories":["示例项目","教程"],"description":"生成电路波形","excerpt":"生成电路波形","ref":"/mlvp/docs/env_usage/wave/","tags":["examples","docs"],"title":"波形生成"},{"body":" 在开始前本页会 简单的介绍什么是验证，以及示例里面用到的概念，如 DUT (Design Under Test) 和 RM (Reference Model) 。\n","categories":["示例项目","教程"],"description":"开放验证平台的环境的详细使用方法。","excerpt":"开放验证平台的环境的详细使用方法。","ref":"/mlvp/docs/env_usage/","tags":["examples","docs"],"title":"环境使用"},{"body":" 本页将介绍数字电路的基础知识。数字电路是利用数字信号的电子电路。近年来，绝大多数的计算机都是基于数字电路实现的。\n什么是数字电路 数字电路是一种利用两种不连续的电位来表示信息的电子电路。在数字电路中，通常使用两个电源电压，分别表示高电平（H）和低电平（L），分别代表数字1和0。这样的表示方式通过离散的电信号，以二进制形式传递和处理信息。\n大多数数字电路的实现基于场效应管，其中最常用的是 MOSFET（Metal-Oxide-Semiconductor Field-Effect Transistor，金属氧化物半导体场效应管）。MOSFET 是一种半导体器件，可以在电场的控制下调控电流流动，从而实现数字信号的处理。\n在数字电路中，MOSFET 被组合成各种逻辑电路，如与门、或门、非门等。这些逻辑门通过不同的组合方式，构建了数字电路中的各种功能和操作。以下是一些数字电路的基本特征：\n(1) 电位表示信息： 数字电路使用两种电位，即高电平和低电平，来表示数字信息。通常，高电平代表数字1，低电平代表数字0。\n(2) MOSFET 实现： MOSFET 是数字电路中最常用的元件之一。通过控制 MOSFET 的导通和截止状态，可以实现数字信号的处理和逻辑运算。\n(3) 逻辑门的组合： 逻辑门是数字电路的基本构建块，由 MOSFET 组成。通过组合不同的逻辑门，可以构建复杂的数字电路，实现各种逻辑功能。\n(4) 二进制表达： 数字电路中的信息通常使用二进制系统进行表示。每个数字都可以由一串二进制位组成，这些位可以在数字电路中被处理和操作。\n(5) 电平转换和信号处理： 数字电路通过电平的变化和逻辑操作，实现信号的转换和处理。这种离散的处理方式使得数字电路非常适用于计算和信息处理任务。\n为什么要学习数字电路 学习数字电路是芯片验证过程中的基础和必要前提，主要体现在以下多个方面：\n(1) 理解设计原理： 数字电路是芯片设计的基础，了解数字电路的基本原理和设计方法是理解芯片结构和功能的关键。芯片验证的目的是确保设计的数字电路在实际硬件中按照规格正常工作，而理解数字电路原理是理解设计的关键。\n(2) 设计规范： 芯片验证通常涉及验证设计是否符合特定的规范和功能要求。学习数字电路可以帮助理解这些规范，从而更好地构建测试用例和验证流程，确保验证的全面性和准确性。\n(3) 时序和时钟： 时序问题是数字电路设计和验证中的常见挑战。学习数字电路可以帮助理解时序和时钟的概念，以确保验证过程中能够正确处理时序问题，避免电路中的时序迟滞和冲突。\n(4) 逻辑分析： 芯片验证通常涉及对逻辑的分析，确保电路的逻辑正确性。学习数字电路可以培养对逻辑的深刻理解，从而更好地进行逻辑分析和故障排查。\n(5) 测试用例编写： 在芯片验证中，需要编写各种测试用例来确保设计的正确性。对数字电路的理解可以帮助设计更全面、有针对性的测试用例，涵盖电路的各个方面。\n(6) 信号完整性： 学习数字电路有助于理解信号在电路中的传播和完整性问题。在芯片验证中，确保信号在不同条件下的正常传递是至关重要的，特别是在高速设计中。\n整体而言，学习数字电路为芯片验证提供了基础知识和工具，使验证工程师能够更好地理解设计，编写有效的测试用例，分析验证结果，并解决可能出现的问题。数字电路的理论和实践经验对于芯片验证工程师来说都是不可或缺的。\n数字电路基础知识 可以通过以下在线资源进行数字电路学习：\n清华大学数字电路基础 中科大数字电路实验 数字设计和计算机体系结构 MIT 数字集成电路分析与设计 硬件描述语言Chisel 传统描述语言 硬件描述语言（Hardware Description Language，简称 HDL）是一种用于描述数字电路、系统和硬件的语言。它允许工程师通过编写文本文件来描述硬件的结构、功能和行为，从而实现对硬件设计的抽象和建模。\nHDL 通常被用于设计和仿真数字电路，如处理器、存储器、控制器等。它提供了一种形式化的方法来描述硬件电路的行为和结构，使得设计工程师可以更方便地进行硬件设计、验证和仿真。\n常见的硬件描述语言包括：\nVerilog：Verilog 是最常用的 HDL 之一，它是一种基于事件驱动的硬件描述语言，广泛应用于数字电路设计、验证和仿真。 VHDL：VHDL 是另一种常用的 HDL，它是一种面向对象的硬件描述语言，提供了更丰富的抽象和模块化的设计方法。 SystemVerilog：SystemVerilog 是 Verilog 的扩展，它引入了一些高级特性，如对象导向编程、随机化测试等，使得 Verilog 更适用于复杂系统的设计和验证。 Chisel Chisel 是一种现代化高级的硬件描述语言，与传统的 Verilog 和 VHDL 不同，它是基于 Scala 编程语言的硬件构建语言。Chisel 提供了一种更加现代化和灵活的方法来描述硬件，通过利用 Scala 的特性，可以轻松地实现参数化、抽象化和复用，同时保持硬件级别的效率和性能。\nChisel 的特点包括：\n现代化的语法：Chisel 的语法更加接近软件编程语言，如 Scala，使得硬件描述更加直观和简洁。 参数化和抽象化：Chisel 支持参数化和抽象化，可以轻松地创建可配置和可重用的硬件模块。 类型安全：Chisel 是基于 Scala 的，因此具有类型安全的特性，可以在编译时检测到许多错误。 生成性能优化的硬件：Chisel 代码可以被转换成 Verilog，然后由标准的 EDA 工具链进行综合、布局布线和仿真，生成性能优化的硬件。 强大的仿真支持：Chisel 提供了与 ScalaTest 和 Firrtl 集成的仿真支持，使得对硬件进行仿真和验证更加方便和灵活。 Chisel版的全加法器实例 电路设计如下图所示：\n完整的Chisel代码如下：\npackage examples import chisel3._ class FullAdder extends Module { // Define IO ports val io = IO(new Bundle { val a = Input(UInt(1.W)) // Input port 'a' of width 1 bit val b = Input(UInt(1.W)) // Input port 'b' of width 1 bit val cin = Input(UInt(1.W)) // Input port 'cin' (carry-in) of width 1 bit val sum = Output(UInt(1.W)) // Output port 'sum' of width 1 bit val cout = Output(UInt(1.W))// Output port 'cout' (carry-out) of width 1 bit }) // Calculate sum bit (sum of a, b, and cin) val s1 = io.a ^ io.b // XOR operation between 'a' and 'b' io.sum := s1 ^ io.cin // XOR operation between 's1' and 'cin', result assigned to 'sum' // Calculate carry-out bit val s3 = io.a \u0026 io.b // AND operation between 'a' and 'b', result assigned to 's3' val s2 = s1 \u0026 io.cin // AND operation between 's1' and 'cin', result assigned to 's2' io.cout := s2 | s3 // OR operation between 's2' and 's3', result assigned to 'cout' } Chisel 学习材料可以参考官方文档：https://www.chisel-lang.org/docs\n","categories":"","description":"关于数字电路的基本概念\n","excerpt":"关于数字电路的基本概念\n","ref":"/mlvp/docs/basic/ic_base/","tags":"","title":"数字电路"},{"body":" 介绍芯片验证，以果壳 Cache 为例，介绍基本的验证流程、报告撰写。\n","categories":["示例项目","教程"],"description":"介绍开放验证平台工作所需要的基础知识。","excerpt":"介绍开放验证平台工作所需要的基础知识。","ref":"/mlvp/docs/basic/","tags":["examples","docs"],"title":"验证基础"},{"body":"异步编程 概述 为什么要引入异步编程？ 上一节中我们学习了如何使用回调函数，但是在使用回调函数时可能会遇到回调地狱，即如果回调嵌套过多会导致代码会变得非常复杂，并且难以，因此我们可以通过异步(async,await)的方式来避免这种情况，使用异步，可以使代码结构变得清晰，过await关键字，可以使得异步操作按顺序执行，而不需要通过回调函数来管理执行顺序。\n实现原理 在python的asyncio中异步编程的实现基于以下三个核心概念，我们会在下一小节进行更详细的介绍\n回调函数（Callback） 回调函数预先注册的回是异步编程的基础。当一个任务完成时，系统会调用调函数来处理任务的结果。通过回调函数的方式，程序可以在等待任务完成的同时继续执行其他任务，提高了程序的并发性。 事件循环（Event Loop） 事件循环是异步编程的核心机制之一。它负责监听各种事件（如用户输入、I/O 操作等），当事件发生时，触发相应的回调函数进行处理。事件循环通过不断地轮询事件队列，实现了非阻塞式的任务处理。 协程 其中协程就是用户自己定义的任务 常见的异步编程框架和工具 为了方便开发者进行异步编程，有许多优秀的框架和工具可供选择。以下是一些常见的异步编程框架和工具：\nAsyncio Asyncio 是 Python 的一个强大的异步编程框架，提供了高效的协程（Coroutine）支持。它可以用于编写并发性能优秀的网络应用、爬虫程序等。 Node. Js Node. Js 是基于 Chrome V 8 引擎构建的 JavaScript 运行时环境，天生支持非阻塞 I/O 操作。它在 Web 开发领域广泛应用，尤其擅长处理高并发的实时应用。 RxJava RxJava 是一个基于观察者模式和迭代器模式的异步编程库。它为 Java 开发者提供了丰富的操作符和组合方式，简化了异步编程的复杂性。 在python中使用异步，需要使用async和await两个关键字\nasync：用于定义异步函数，在异步函数中，通常需要包含异步操作 await：用于在异步函数中等待异步操作的完成 下面是一个简单的python代码，来演示async和await关键字的用法\nasync def my_async_function(): print(\"Start async_function and wait some funcion \") await some_other_async_function() print(\"End of my_async_function\") 在python中要想实现异步，通常使用asyncio模块，在下面的例子中，我们定义了一个greet函数，分别打印Hello+name和Goodbye+name,两次打印中间间隔2s.使用asyncio.create创建两个异步任务，并收集执行结果\nasyncio.create_task()：用于创建一个协程任务，并安排其立即执行 asyncio.gather()：等待多个协程任务的全部完成，并且可以收集执行结果 asyncio.sleep()：在异步操作中等待一段实际 import asyncio # 定义一个异步函数 async def greet(name): print(\"Hello, \" + name) await asyncio.sleep(2) # 使用异步的sleep函数 print(\"Goodbye, \" + name) # 执行异步函数 async def main(): # 创建任务并发执行 task1 = asyncio.create_task(greet(\"verify chip\")) task2 = asyncio.create_task(greet(\"picker\")) # 等待所有任务完成 await asyncio.gather(task1, task2) # 运行主函数 if __name__ == \"__main__\": asyncio.run(main()) 首先执行greet(“verify chip”)，打印Hello,verify chip 当遇到await时，转去执行greet(“picker”), 打印Hello,picker 当要等待的操作执行完以后两个task分别输出Goodbye,verify chip，Goodbye,picker 异步编程的优势 异步编程具有以下几个显著的优势：\n提高响应速度 通过异步编程，程序能够在等待某个任务完成时继续执行其他任务，避免了任务阻塞带来的延迟。这样能够大幅度提高程序的响应速度，提升用户体验。 提升并发性能 异步编程允许程序同时处理多个任务，充分利用计算资源，提升了系统的并发能力。特别是在处理大量 I/O 密集型任务时，异步编程能够更好地发挥优势，降低资源消耗。 简化编程逻辑 异步编程可以避免编写复杂的多线程代码，降低了程序的复杂性和出错的概率。通过简化编程逻辑，开发者能够更专注于业务逻辑的实现。 因此异步编程广泛应用于以下几个领域：\nWeb 开发 在 Web 开发中，异步编程常用于处理网络请求、数据库操作等耗时任务。通过异步方式处理这些任务，可以避免阻塞主线程，保证 Web 服务器的并发性能。 并行计算 异步编程可以帮助实现并行计算，将一个大任务拆分成多个小任务并发执行，提高计算效率。这在科学计算、数据处理等领域非常常见。 消息队列 消息队列是异步编程的经典应用之一。异步消息队列可以实现不同系统之间的解耦和异步通信，提高系统的可扩展性和稳定性。 picker中异步的用法 例如在picker中，我们可以通过如下方法通过周期来控制代码执行的流程\nawait clk.AStep(3)：等待时钟 clk 走 3 个时钟周期。await 关键字使得程序在这里暂停执行，直到时钟走完指定的时钟周期后才继续执行下一行代码。 await clk.ACondition(lambda: clk.clk == 20)：它等待条件 clk.clk == 20 成立。类似地，程序在这里暂停执行，直到条件成立后才继续执行下一行代码。 async def test_async(): clk = XClock(lambda a: 0) clk.StepRis(lambda c : print(\"lambda ris: \", c)) task = create_task(clk.RunStep(30)) print(\"test AStep:\", clk.clk) await clk.AStep(3) print(\"test ACondition:\", clk.clk) await clk.ACondition(lambda: clk.clk == 20) print(\"test cpm:\", clk.clk) await task 验证加法器时使用异步 这里继续用在上升沿触发的加法器作为例子，我们对之前的代码做了一些微小的变动，把时钟信号的产生和等待时钟周期换成了picker提供的异步方法:\nXClock的Step(i)方法会推进i个时钟周期，具有两个主要功能：\n生成i个时钟周期的时钟信号。 等待时钟经过i个周期。 在异步编程中，这两个功能对应着 XClock 提供的两种异步方法：\nRunStep(i)：生成i个时钟周期的时钟信号。需要通过asyncio.create_task创建任务，并在测试代码的最后使用 await 等待其完成。 AStep(i)：等待时钟经过i个周期。 如果RunStep(i)方法在AStep(i)之前完成，整个程序将在AStep(i)处被阻塞。\n使用异步的测试代码 from UT_RisAdder import * import random import asyncio # 控制字体颜色 FONT_GREEN = \"\\033[0;32m\" # 绿色 FONT_RED = \"\\033[0;31m\" # 红色 FONT_COLOR_RESET = \"\\033[0m\" # 重置颜色 class SimpleRisAdder: \"\"\" SimpleRisAdder 类是一个作为参考的加法器类， 它模拟了我们预期的RisAdder的行为 \"\"\" def __init__(self, width) -\u003e None: self.WIDTH = width # 加法器的位宽 # 端口定义 self.a = 0 # 输入端口a self.b = 0 # 输入端口b self.cin = 0 # 输入端口cin self.cout = 0 # 输出端口cout self.sum = 0 # 输出端口sum def step(self, a, b, cin): \"\"\" 模拟上升沿更新输出: 先用上个周期的输入更新输出，之后再更新输入 \"\"\" sum = self.a + self.b + self.cin self.cout = sum \u003e\u003e self.WIDTH # 计算进位 self.sum = sum \u0026 ((1 \u003c\u003c self.WIDTH) - 1) # 计算和 self.a = a # 更新输入a self.b = b # 更新输入b self.cin = cin # 更新输入cin # 测试函数，验证加法器的输出是否正确 def test_adder(clk: int, dut: DUTRisAdder, ref: SimpleRisAdder) -\u003e None: # 获取加法器的输入和输出 a = dut.a.value b = dut.b.value cin = dut.cin.value cout = dut.cout.value sum = dut.sum.value # 检查加法器的输出是否与预期一致 isEqual = (cout, sum) == (ref.cout, ref.sum) # 输出测试结果 print(f\"Cycle: {clk}, Input(a, b, cin) = ({a:x}, {b:x}, {cin:x})\") print( FONT_GREEN + \"Pass.\" # 输出绿色的“Pass.”，如果测试通过 if isEqual else FONT_RED + f\"MisMatch! Expect cout: {ref.cout:x}, sum: {ref.sum:x}.\" + FONT_COLOR_RESET + f\"Get cout: {cout:x}, sum: {sum:x}.\" ) assert isEqual # 如果测试失败，触发断言异常 # 异步函数，用于运行测试 async def run_test(): WIDTH = 32 # 设置加法器的位宽 ref = SimpleRisAdder(WIDTH) # 创建一个参考加法器 dut = DUTRisAdder() # 创建被测试的加法器 # 绑定时钟信号 dut.init_clock(\"clk\") # dut输入信号置0 dut.a.value = 0 dut.b.value = 0 dut.cin.value = 0 task = asyncio.create_task( dut.runstep(114514 + 1) # 创建一个异步任务，用于模拟时钟信号持续(114514+1)个周期 ) await dut.astep(1) # 等待时钟进入下个周期 dut.StepRis(test_adder, (dut, ref)) # 注册在时钟上升沿触发的函数 # 启动测试 for _ in range(114514): # 随机生成输入 a = random.randint(0, (1 \u003c\u003c WIDTH) - 1) b = random.randint(0, (1 \u003c\u003c WIDTH) - 1) cin = random.randint(0, 1) ref.step(a, b, cin) # 更新参考加法器的状态 dut.a.value = a # 设置被测试加法器的输入a dut.b.value = b # 设置被测试加法器的输入b dut.cin.value = cin # 设置被测试加法器的输入cin await dut.astep(1) # 等待时钟进入下个周期 await task # 等待时钟结束 dut.finalize() if __name__ == \"__main__\": asyncio.run(run_test()) # 运行测试 pass ","categories":["示例项目","教程"],"description":"利用异步模式简化回调","excerpt":"利用异步模式简化回调","ref":"/mlvp/docs/advance_func/async/","tags":["examples","docs"],"title":"异步编程"},{"body":"RTL Source Code In this case, we drive a 64-bit adder. The source code is as follows:\n// A verilog 64-bit full adder with carry in and carry out module Adder #( parameter WIDTH = 64 ) ( input [WIDTH-1:0] a, input [WIDTH-1:0] b, input cin, output [WIDTH-1:0] sum, output cout ); assign {cout, sum} = a + b + cin; endmodule This adder consists of a 64-bit adder. The inputs are two 64-bit numbers and a carry-in signal, and the outputs are a 64-bit sum and a carry-out signal.\nTesting Process During the testing process, we will create a folder named Adder, containing an Adder.v file. The content of this file is the RTL source code mentioned above.\nBuilding the RTL into a Python Module Generating Intermediate Files Enter the Adder folder and execute the following command:\npicker --autobuild=false Adder.v -w Adder.fst -S Adder -t picker_out_adder -l python -e --sim verilator The meaning of this command is:\nUse Adder.v as the top file and Adder as the top module. Generate a dynamic library using the Verilator simulator, with the target language being Python. Enable waveform output with the target waveform file as Adder.fst. Include files to drive the example project (-e) and do not auto-compile after code generation (-autobuild=false). The final file output path is picker_out_adder. Some command-line parameters are not used in this command; these will be introduced in subsequent sections.\nThe output directory structure is as follows. Note that these are all intermediate files and cannot be used directly:\npicker_out_adder |-- Adder.v # Original RTL source code |-- Adder_top.sv # Generated Adder_top top-level wrapper, using DPI to drive Adder module inputs and outputs |-- Adder_top.v # Generated Adder_top top-level wrapper, a Verilog version because Verdi does not support importing SV source code |-- CMakeLists.txt # Used to call the simulator to compile basic cpp class and package it into a binary dynamic library with bare DPI functions (libDPIAdder.so) |-- Makefile # Generated Makefile, used to call CMakeLists.txt, allowing users to compile libAdder.so via the make command and manually adjust Makefile configuration parameters. Or compile the example project |-- cmake # Generated cmake folder, used to call different simulators to compile RTL code | |-- vcs.cmake | `-- verilator.cmake |-- cpp # CPP example directory, containing example code | |-- CMakeLists.txt # Used to encapsulate libDPIAdder.so into a directly operable class (libUTAdder.so) with basic data types, rather than bare DPI functions. | |-- Makefile | |-- cmake | | |-- vcs.cmake | | `-- verilator.cmake | |-- dut.cpp # Generated cpp UT encapsulation, containing the call to libDPIAdder.so and the declaration and implementation of the UTAdder class | |-- dut.hpp # Header file | `-- example.cpp # Example code calling the UTAdder class |-- dut_base.cpp # Base class used to call and drive different simulator compilation results, encapsulated into a unified class to hide all simulator-related code details. |-- dut_base.hpp |-- filelist.f # Other file lists used for multi-file projects, see the introduction of the -f parameter. Empty in this case |-- mk | |-- cpp.mk # Used to control the Makefile when the target language is cpp, including the logic to compile example projects (-e, example) | `-- python.mk # Same as above, target language is python `-- python |-- CMakeLists.txt |-- Makefile |-- cmake | |-- vcs.cmake | `-- verilator.cmake |-- dut.i # SWIG configuration file, used to export the base class and function declarations of libDPIAdder.so to Python, providing Python calling capability `-- dut.py # Generated python UT encapsulation, containing the call to libDPIAdder.so and the declaration and implementation of the UTAdder class, equivalent to libUTAdder.so Building Intermediate Files Enter the picker_out_adder directory and execute the make command to generate the final files.\nThe automatic compilation process flow defined by Makefile is as follows:\nCall the simulator through cmake/*.cmake defined scripts to compile Adder_top.sv and related files into the dynamic library libDPIAdder.so. Use the compilation scripts defined in CMakelists.txt to encapsulate libDPIAdder.so into the dynamic library libUTAdder.so through dut_base.cpp. The results of steps 1 and 2 are copied to the UT_Adder directory. Use header files such as dut_base.hpp and dut.hpp to generate the encapsulation layer through the SWIG tool, and finally build a Python Module in the UT_Adder directory. If there is a -e parameter, the predefined example.py will be placed in the parent directory of the UT_Adder directory as an example of how to call this Python Module. The final directory structure is:\n. |-- Adder.fst # Test waveform file |-- UT_Adder | |-- Adder.fst.hier | |-- _UT_Adder.so # Wrapper dynamic library generated by Swig | |-- __init__.py # Initialization file of the Python Module, also the library definition file | |-- libDPIAdder.a # Library file generated by the simulator | |-- libUTAdder.so # Encapsulation of the libDPI dynamic library generated based on dut_base | `-- libUT_Adder.py # Python Module generated by Swig | `-- xspcomm # Fixed folder, no need to pay attention `-- example.py # Example code Configuring Test Code Note that the content in example.py needs to be replaced to ensure the example project runs as expected.\nfrom UT_Adder import * import random class input_t: def __init__(self, a, b, cin): self.a = a self.b = b self.cin = cin class output_t: def __init__(self): self.sum = 0 self.cout = 0 def random_int(): # Data needs to be passed into dut as an unsigned number return random.randint(-(2**63), 2**63 - 1) \u0026 ((1 \u003c\u003c 63) - 1) def as_uint(x, nbits): # Convert data to unsigned number return x \u0026 ((1 \u003c\u003c nbits) - 1) def main(): dut = DUTAdder() # Assuming USE_VERILATOR print(\"Initialized UTAdder\") for c in range(114514): i = input_t(random_int(), random_int(), random_int() \u0026 1) o_dut, o_ref = output_t(), output_t() def dut_cal(): # Assign values to DUT inputs, must use .value dut.a.value, dut.b.value, dut.cin.value = i.a, i.b, i.cin # Drive the circuit for one cycle dut.Step(1) o_dut.sum = dut.sum.value o_dut.cout = dut.cout.value def ref_cal(): sum = as_uint( i.a + i.b, 64 ) carry = sum \u003c i.a sum += i.cin carry = carry or sum \u003c i.cin o_ref.sum, o_ref.cout = sum, carry dut_cal() ref_cal() print(f\"[cycle {dut.xclock.clk}] a=0x{i.a:x}, b=0x{i.b:x}, cin=0x{i.cin:x} \") print(f\"DUT: sum=0x{o_dut.sum:x}, cout=0x{o_dut.cout:x}\") print(f\"REF: sum=0x{o_ref.sum:x}, cout=0x{o_ref.cout:x}\") assert o_dut.sum == o_ref.sum, \"sum mismatch\" dut.finalize() # Must explicitly call finalize method to prevent memory leaks and generate waveforms and coverage print(\"Test Passed, destroy UTAdder\") if __name__ == \"__main__\": main() Running the Test Execute the python example.py command in the picker_out_adder directory to run the test. After the test is completed, we can see the output of the example project. The waveform file will be saved in Adder.fst.\n[...] [cycle 114513] a=0x6defb0918b94495d, b=0x72348b453ae6a7a8, cin=0x0 DUT: sum=0xe0243bd6c67af105, cout=0x0 REF: sum=0xe0243bd6c67af105, cout=0x0 [cycle 114514] a=0x767fa8cbfd6bbfdc, b=0x4486aa3a9b29719a, cin=0x1 DUT: sum=0xbb06530698953177, cout=0x0 REF: sum=0xbb06530698953177, cout=0x0 Test Passed, destroy UTAdder ","categories":["Example Projects","Tutorials"],"description":"Demonstrates the principles and usage of the tool based on a simple adder verification. This adder is implemented using simple combinational logic.","excerpt":"Demonstrates the principles and usage of the tool based on a simple …","ref":"/mlvp/en/docs/quick-start/eg-adder/","tags":["examples","docs"],"title":"Case: 1 Adder"},{"body":"RTL源码 在本案例中，我们驱动一个 64 位的加法器，其源码如下：\n// A verilog 64-bit full adder with carry in and carry out module Adder #( parameter WIDTH = 64 ) ( input [WIDTH-1:0] a, input [WIDTH-1:0] b, input cin, output [WIDTH-1:0] sum, output cout ); assign {cout, sum} = a + b + cin; endmodule 该加法器包含一个 64 位的加法器，其输入为两个 64 位的数和一个进位信号，输出为一个 64 位的和和一个进位信号。\n测试过程 在测试过程中，我们将创建一个名为 Adder 的文件夹，其中包含一个 Adder.v 文件。该文件内容即为上述的 RTL 源码。\n将RTL构建为 Python Module 生成中间文件 进入 Adder 文件夹，执行如下命令：\npicker --autobuild=false Adder.v -w Adder.fst -S Adder -t picker_out_adder -l python -e --sim verilator 该命令的含义是：\n将 Adder.v 作为 Top 文件，并将 Adder 作为 Top Module，基于 verilator 仿真器生成动态库，生成目标语言为 Python。 启用波形输出，目标波形文件为Adder.fst。 包含用于驱动示例项目的文件(-e)，同时codegen完成后不自动编译(-autobuild=false)。 最终的文件输出路径是 picker_out_adder 在使用该命令时，还有部分命令行参数没有使用，这些命令将在后续的章节中介绍。\n输出的目录结构如下，请注意这部分均为中间文件，不能直接使用：\npicker_out_adder |-- Adder.v # 原始的RTL源码 |-- Adder_top.sv # 生成的Adder_top顶层封装，使用DPI驱动Adder模块的inputs和outputs |-- Adder_top.v # 生成的Adder_top顶层封装，因为Verdi不支持导入SV源码使用，因此需要生成一个Verilog版本 |-- CMakeLists.txt # 用于调用仿真器编译基本的cpp class并将其打包成有裸DPI函数二进制动态库(libDPIAdder.so) |-- Makefile # 生成的Makefile，用于调用CMakeLists.txt，并让用户可以通过make命令编译出libAdder.so，并手动调整Makefile的配置参数。或者编译示例项目 |-- cmake # 生成的cmake文件夹，用于调用不同仿真器编译RTL代码 | |-- vcs.cmake | `-- verilator.cmake |-- cpp # CPP example目录，包含示例代码 | |-- CMakeLists.txt # 用于将libDPIAdder.so使用基础数据类型封装为一个可直接操作的类（libUTAdder.so），而非裸DPI函数。 | |-- Makefile | |-- cmake | | |-- vcs.cmake | | `-- verilator.cmake | |-- dut.cpp # 生成的cpp UT封装，包含了对libDPIAdder.so的调用，及UTAdder类的声明及实现 | |-- dut.hpp # 头文件 | `-- example.cpp # 调用UTAdder类的示例代码 |-- dut_base.cpp # 用于调用与驱动不同仿真器编译结果的基类，通过继承封装为统一的类，用于隐藏所有仿真器相关的代码细节。 |-- dut_base.hpp |-- filelist.f # 多文件项目使用的其他文件列表，请查看 -f 参数的介绍。本案例中为空 |-- mk | |-- cpp.mk # 用于控制以cpp为目标语言时的Makefile，包含控制编译示例项目（-e，example）的逻辑 | `-- python.mk # 同上，目标语言是python `-- python |-- CMakeLists.txt |-- Makefile |-- cmake | |-- vcs.cmake | `-- verilator.cmake |-- dut.i # SWIG配置文件，用于将libDPIAdder.so的基类与函数声明，依据规则用swig导出到python，提供python调用的能力 `-- dut.py # 生成的python UT封装，包含了对libDPIAdder.so的调用，及UTAdder类的声明及实现，等价于 libUTAdder.so 构建中间文件 进入 picker_out_adder 目录并执行 make 命令，即可生成最终的文件。\n由 Makefile 定义的自动编译过程流如下：\n通过 cmake/*.cmake 定义的仿真器调用脚本，编译 Adder_top.sv 及相关文件为 libDPIAdder.so 动态库。 通过 CMakelists.txt 定义的编译脚本，将 libDPIAdder.so 通过 dut_base.cpp 封装为 libUTAdder.so 动态库。并将1、2步产物拷贝到 UT_Adder 目录下。 通过 dut_base.hpp 及 dut.hpp 等头文件，利用 SWIG 工具生成封装层，并最终在 UT_Adder 这一目录中构建一个 Python Module。 如果有 -e 参数，则将预先定义好的 example.py 置于 UT_Adder 目录的上级目录，作为如何调用该 Python Module 的示例代码。 最终目录结果为：\n. |-- Adder.fst # 测试的波形文件 |-- UT_Adder | |-- Adder.fst.hier | |-- _UT_Adder.so # Swig生成的wrapper动态库 | |-- __init__.py # Python Module的初始化文件，也是库的定义文件 | |-- libDPIAdder.a # 仿真器生成的库文件 | |-- libUTAdder.so # 基于dut_base生成的libDPI动态库封装 | `-- libUT_Adder.py # Swig生成的Python Module | `-- xspcomm # xspcomm基础库，固定文件夹，不需要关注 `-- example.py # 示例代码 配置测试代码 注意需要替换 example.py 中的内容，才能保证 example 示例项目按预期运行。\nfrom UT_Adder import * import random class input_t: def __init__(self, a, b, cin): self.a = a self.b = b self.cin = cin class output_t: def __init__(self): self.sum = 0 self.cout = 0 def random_int(): # 需要将数据以无符号数的形式传入dut return random.randint(-(2**63), 2**63 - 1) \u0026 ((1 \u003c\u003c 63) - 1) def as_uint(x, nbits): # 将数据转换为无符号数 return x \u0026 ((1 \u003c\u003c nbits) - 1) def main(): dut = DUTAdder() # Assuming USE_VERILATOR print(\"Initialized UTAdder\") for c in range(114514): i = input_t(random_int(), random_int(), random_int() \u0026 1) o_dut, o_ref = output_t(), output_t() def dut_cal(): # 针对 DUT 的输入赋值，必须使用 .value dut.a.value, dut.b.value, dut.cin.value = i.a, i.b, i.cin # 驱动电路运行一个周期 dut.Step(1) o_dut.sum = dut.sum.value o_dut.cout = dut.cout.value def ref_cal(): sum = as_uint( i.a + i.b, 64 ) carry = sum \u003c i.a sum += i.cin carry = carry or sum \u003c i.cin o_ref.sum, o_ref.cout = sum, carry dut_cal() ref_cal() print(f\"[cycle {dut.xclock.clk}] a=0x{i.a:x}, b=0x{i.b:x}, cin=0x{i.cin:x} \") print(f\"DUT: sum=0x{o_dut.sum:x}, cout=0x{o_dut.cout:x}\") print(f\"REF: sum=0x{o_ref.sum:x}, cout=0x{o_ref.cout:x}\") assert o_dut.sum == o_ref.sum, \"sum mismatch\" dut.finalize() # 必须显式调用finalize方法，否则会导致内存泄漏，并无法生成波形和覆盖率 print(\"Test Passed, destroy UTAdder\") if __name__ == \"__main__\": main() 运行测试 在 picker_out_adder 目录下执行 python example.py 命令，即可运行测试。在测试完成后我们即可看到 example 示例项目的输出。波形文件会被保存在 Adder.fst 中。\n[...] [cycle 114513] a=0x6defb0918b94495d, b=0x72348b453ae6a7a8, cin=0x0 DUT: sum=0xe0243bd6c67af105, cout=0x0 REF: sum=0xe0243bd6c67af105, cout=0x0 [cycle 114514] a=0x767fa8cbfd6bbfdc, b=0x4486aa3a9b29719a, cin=0x1 DUT: sum=0xbb06530698953177, cout=0x0 REF: sum=0xbb06530698953177, cout=0x0 Test Passed, destroy UTAdder ","categories":["示例项目","教程"],"description":"基于一个简单的加法器验证展示工具的原理和使用方法，这个加法器内部是简单的组合逻辑。","excerpt":"基于一个简单的加法器验证展示工具的原理和使用方法，这个加法器内部是简单的组合逻辑。","ref":"/mlvp/docs/quick-start/eg-adder/","tags":["examples","docs"],"title":"案例一：加法器"},{"body":"Picker now supports simulation using VCS. Relevant documentation is still being improved.\n","categories":["Example Projects","Tutorials"],"description":"Tutorial on the advanced features of the Open Verification Platform toolchain.","excerpt":"Tutorial on the advanced features of the Open Verification Platform …","ref":"/mlvp/en/docs/advance_func/","tags":["examples","docs"],"title":"Advanced Tutorial"},{"body":" Using Guoke Cache as an example, this document introduces how to create a DUT based on Chisel.\nIn this document, a DUT (Design Under Test) refers to the circuit or system being verified during the chip verification process. The DUT is the primary subject of verification. When creating a DUT based on the picker tool, it is essential to consider the functionality, performance requirements, and verification goals of the subject under test. These goals may include the need for faster execution speed or more detailed test information. Generally, the DUT, written in RTL, is combined with its surrounding environment to form the verification environment (test_env), where test cases are written. In this project, the DUT is the Python module that needs to be tested and converted through RTL. Traditional RTL languages include Verilog, System Verilog, VHDL, etc. However, as an emerging RTL design language, （https://www.chisel-lang.org/） is playing an increasingly important role in RTL design due to its object-oriented features and ease of use. This chapter introduces how to create a DUT using the conversion of the cache source code from the Guoke Processor-NutShell to a Python module as an example.\nChisel and Guoke Chisel is a high-level hardware construction language (HCL) based on the Scala language. Traditional HDLs describe circuits, while HCLs generate circuits, making them more abstract and advanced. The Stage package provided in Chisel can convert HCL designs into traditional HDL languages such as Verilog and System Verilog. With tools like Mill and Sbt, automation in development can be achieved.\nGuoke is a sequential single-issue processor implementation based on the RISC-V RV64 open instruction set, modularly designed using the Chisel language. For a more detailed introduction to Guoke, please refer to the link: https://oscpu.github.io/NutShell-doc/.\nGuoke cache The Guoke Cache (Nutshell Cache) is the cache module used in the Guoke processor. It features a three-stage pipeline design. When the third stage pipeline detects that the current request is MMIO or a refill occurs, it will block the pipeline. The Guoke Cache also uses a customizable modular design that can generate different-sized L1 Caches or L2 Caches by changing parameters. Additionally, the Guoke Cache has a coherence interface to handle coherence-related requests.\nChisel to Verilog The stage library in Chisel helps generate traditional HDL code such as Verilog and System Verilog from Chisel code. Below is a brief introduction on how to convert a cache implementation based on Chisel into the corresponding Verilog circuit description.\nInitializing the Guoke Environment First, download the entire Guoke source code from the source repository and initialize it:\nmkdir cache-ut cd cache-ut git clone https://github.com/OSCPU/NutShell.git cd NutShell \u0026\u0026 git checkout 97a025d make init Creating Scala Compilation Configuration Then, create build.sc in the cache-ut directory with the following content:\nimport $file.NutShell.build import mill._, scalalib._ import coursier.maven.MavenRepository import mill.scalalib.TestModule._ // Specify Nutshell dependencies object difftest extends NutShell.build.CommonNS { override def millSourcePath = os.pwd / \"NutShell\" / \"difftest\" } // Nutshell configuration object NtShell extends NutShell.build.CommonNS with NutShell.build.HasChiselTests { override def millSourcePath = os.pwd / \"NutShell\" override def moduleDeps = super.moduleDeps ++ Seq( difftest, ) } // UT environment configuration object ut extends NutShell.build.CommonNS with ScalaTest{ override def millSourcePath = os.pwd override def moduleDeps = super.moduleDeps ++ Seq( NtShell ) } Instantiating cache After creating the configuration information, create the src/main/scala source code directory according to the Scala specification. Then, in the source code directory, create nut_cache.scala and use the following code to instantiate the Cache and convert it into Verilog code:\npackage ut_nutshell import chisel3._ import chisel3.util._ import nutcore._ import top._ import chisel3.stage._ object CacheMain extends App { (new ChiselStage).execute(args, Seq( ChiselGeneratorAnnotation(() =\u003e new Cache()(CacheConfig(ro = false, name = \"tcache\", userBits = 16))) )) } Generating RTL After creating all the files (build.sc, src/main/scala/nut_cache.scala), execute the following command in the cache-ut directory:\nmkdir build mill --no-server -d ut.runMain ut_nutshell.CacheMain --target-dir build --output-file Cache Note: For the Mill environment configuration, please refer to https://mill-build.com/mill/Intro_to_Mill.html.\nAfter successfully executing the above command, a Verilog file Cache.v will be generated in the build directory. Then, the picker tool can be used to convert Cache.v into a Python module. Besides Chisel, almost all other HCL languages can generate corresponding RTL codes, so the basic process above also applies to other HCLs.\nDUT Compilation Generally, if you need the DUT to generate waveforms, coverage, etc., it will slow down the DUT’s execution speed. Therefore, when generating a Python module through the picker tool, it will be generated according to various configurations: (1) Turn off all debug information; (2) Enable waveforms; (3) Enable code line coverage. The first configuration aims to quickly build the environment for regression testing, etc.; the second is used to analyze specific errors, timing, etc.; the third is used to improve coverage.\n","categories":["Sample Projects","Learning Materials"],"description":"Using Guoke Cache as an example, this document introduces how to create a DUT based on Chisel.","excerpt":"Using Guoke Cache as an example, this document introduces how to …","ref":"/mlvp/en/docs/basic/create_dut/","tags":["examples","docs"],"title":"Creating DUT"},{"body":"Overview Message-driven programming is a programming paradigm that relies on asynchronous message passing to facilitate communication and collaboration between components. In this paradigm, components of a system communicate by sending and receiving messages instead of directly invoking each other’s functions or methods. For example, in the Picker environment, we can use a message-driven approach to decouple the behavior of the circuit from the excitation of the software, thereby avoiding the constraints of hardware circuit timing. In hardware circuit testing, hardware timing refers to the sequence and timing of operations of components in the circuit, which is crucial for the correct operation of the circuit. Software excitation refers to a series of actions or signals generated by software to simulate the impact of external events on the circuit for testing its response. Decoupling hardware timing from software excitation is necessary because it makes the testing process more flexible and efficient. This decoupling also helps reuse software excitation in different environments, improving the utilization of testing resources. In conclusion, using message-driven programming to decouple hardware timing and software excitation can improve the quality and maintainability of testing, while reducing complexity.\nMessage-driven programming typically involves the following concepts and components:\nMessage： A message is a unit of data exchanged between components. Messages can be simple data structures, event objects, or even commands. The sender sends a message to a target, and the receiver receives the message from the target. Message Queue： A message queue is an intermediary for message passing. It is responsible for storing and managing messages sent to it and delivering messages to receivers. Message queues can be based on memory or disk, and can be unicast (one-to-one), multicast (one-to-many), or broadcast (one-to-all). Publish-Subscribe Pattern：The publish-subscribe pattern is a common implementation of message-driven programming. In this pattern, publishers publish messages to one or more topics, and subscribers subscribe to topics of interest and receive corresponding messages. Message Broker：A message broker is a middleware component that handles message delivery. It is responsible for receiving and distributing messages, managing message queues, ensuring the reliable delivery of messages, and providing other message-related functions such as message routing, message filtering, message persistence, etc. Implementing Message-Driven with Pub/Sub Pattern The publish/subscribe pattern is a common messaging communication paradigm in software architecture. In this pattern, publishers do not directly send messages to specific recipients, but publish (send) them to an intermediary, known as a message broker. Subscribers express interest in specific message types or topics, indicating which messages they wish to receive. The responsibility of the message broker is to ensure that all clients subscribed to a particular topic receive the corresponding messages. A key feature of this pattern is the decoupling between publishers and subscribers. They do not need to be aware of each other’s existence or communicate directly. This enhances the flexibility and scalability of the system, as publishers and subscribers can be added or removed independently without affecting other parts of the system.\nBasic Publish/Subscribe Model Implemented with Python’s Built-in Queue Module: The Publisher class has a message queue and a list of subscribers. When a message is published using the publish method, it is added to the queue and then passed to all subscribed clients by calling their receive methods. The Subscriber class has a receive method that simply prints the received message. import queue # Publisher class class Publisher: def __init__(self): # Initialize message queue and list of subscribers self.message_queue = queue.Queue() self.subscribers = [] def subscribe(self, subscriber): # Add a new subscriber to the list of subscribers self.subscribers.append(subscriber) def publish(self, message): # Put the message into the queue and notify all subscribers self.message_queue.put(message) for subscriber in self.subscribers: # Call the subscriber's receive method subscriber.receive(message) # Subscriber class class Subscriber: def __init__(self, name): # Initialize the subscriber's name self.name = name def receive(self, message): # Print the received message print(f\"{self.name} received message: {message}\") # Create an instance of the Publisher publisher = Publisher() # Create two instances of the Subscriber subscriber_1 = Subscriber(\"Subscriber 1\") subscriber_2 = Subscriber(\"Subscriber 2\") # Add the subscribers to the Publisher's list of subscribers publisher.subscribe(subscriber_1) publisher.subscribe(subscriber_2) # Publish a message publisher.publish(\"Hello World\") Publish/Subscribe Model Implemented with Python’s Threading Module: In this example, the Publisher class has a subscriber dictionary, where keys are topics and values are lists of subscribers. The subscribe method adds a subscriber to the list of subscribers for a specified topic. The publish method checks if there are any subscribers for the specified topic, sets an event, and stores the message for each subscriber. import threading # Publisher class class Publisher: def __init__(self): # Initialize the subscriber dictionary, organized by topic self.subscribers = {} def subscribe(self, subscriber, topic): # Subscribe method, adds the subscriber to the specified topic if topic not in self.subscribers: self.subscribers[topic] = [] self.subscribers[topic].append(subscriber) def publish(self, message, topic): # Publish method, sends the message to all subscribers of the specified topic if topic in self.subscribers: for subscriber in self.subscribers[topic]: # Set the event flag to notify subscribers of new message subscriber.event.set() # Store the message for each subscriber subscriber.message = message # Subscriber class class Subscriber: def __init__(self, name): # Initialize the subscriber's name and event flag self.name = name self.event = threading.Event() self.message = None def receive(self): # Receive method, waits for the event flag to be set self.event.wait() # Print the received message print(f\"{self.name} received message: {self.message}\") # Clear the event flag to prepare for the next message self.event.clear() # Create an instance of the Publisher publisher = Publisher() # Create three instances of the Subscriber subscriber_1 = Subscriber(\"Subscriber 1\") subscriber_2 = Subscriber(\"Subscriber 2\") subscriber_3 = Subscriber(\"Subscriber 3\") # Subscribe the subscribers to the publisher based on topics publisher.subscribe(subscriber_1, \"sports\") publisher.subscribe(subscriber_2, \"entertainment\") publisher.subscribe(subscriber_3, \"sports\") # Publish a message belonging to the 'sports' topic publisher.publish(\"Soccer match result\", \"sports\") # Subscriber 1 receives and processes the message subscriber_1.receive() Subscriber 1 receives and processes the message Here we take the verification process of NutShell cache as an example to introduce the use of message-driven in verification. For the full code, please refer to the GitHub repository.\nfrom util.simplebus import SimpleBusWrapper from tools.colorprint import Color as cl import xspcomm as xsp import queue # Request message class, used to encapsulate details of communication requests class ReqMsg: def __init__(self, addr, cmd, user=0x123, size=7, mask=0, data=0): self.user = user self.size = size self.addr = addr self.cmd = cmd self.mask = mask self.data = data def display(self): print(f\"[REQ MSG] user {self.user:x}, size {self.size}, addr 0x{self.addr:x} \" f\"cmd 0x{self.cmd:x}, mask {self.mask:b}, data {self.data:x}\") # Cache Wrapper Class, used to simulate cache behavior and communicate with the external bus class CacheWrapper: def __init__(self, io_bus: SimpleBusWrapper, clk: xsp.XClock, cache_port: xsp.XPort): self.xclk = clk # Simple Bus Wrapper for external communication self.io_bus = io_bus # Cache port for potential interaction with external components self.cache_port = cache_port # Initialize request queue to store incoming request messages self.req_que = queue.Queue() # Initialize response queue to store processed response messages self.resp_que = queue.Queue() # Register callback method on the rising edge of the hardware clock for request and response handling self.xclk.StepRis(self.__callback) # Initiate a read request def trigger_read_req(self, addr): # Put the read request message into the request queue without waiting for queue lock self.req_que.put_nowait(ReqMsg(addr=addr, cmd=self.io_bus.cmd_read)) # Initiate a write request def trigger_write_req(self, addr, data, mask): # Put the write request message into the request queue without waiting for queue lock self.req_que.put_nowait(ReqMsg(addr=addr, cmd=self.io_bus.cmd_write, mask=mask, data=data)) # Receive a response def recv(self): # Wait for the response queue to be non-empty, then retrieve the response while self.resp_que.empty(): self.xclk.Step(1) return self.resp_que.get() # Read data def read(self, addr): # Initiate a read request and then wait for and return the response self.trigger_read_req(addr) return self.recv() # Write data def write(self, addr, data, mask): # Initiate a write request and then wait for and return the response self.trigger_write_req(addr, data, mask) return self.recv() # Reset the cache def reset(self): # Set the reset signal, wait for a certain number of clock cycles, then clear the reset signal self.cache_port[\"reset\"].value = 1 self.xclk.Step(100) self.cache_port[\"reset\"].value = 0 self.cache_port[\"io_flush\"].value = 0 # Wait for the request ready signal while not self.io_bus.IsReqReady(): self.xclk.Step(1) # Callback method on the rising edge of the hardware clock def __callback(self, *a, **b): # Handle requests if self.io_bus.IsReqSend(): # If a request is sent, retrieve one from the request queue self.req_que.get() # Check if the request queue is empty if self.req_que.empty(): # If the request queue is empty, send an invalid request signal to io_bus self.io_bus.ReqUnValid() else: # If the request queue is not empty, send a valid request signal to io_bus self.io_bus.ReqSetValid() # Retrieve the first request message from the queue msg: ReqMsg = self.req_que.queue[0] # Execute read or write operation based on the request command type if msg.cmd == self.io_bus.cmd_read: self.io_bus.ReqReadData(msg.addr) if msg.cmd == self.io_bus.cmd_write: self.io_bus.ReqWriteData(msg.addr, msg.data, msg.mask) # Handle reception self.io_bus.port[\"resp_ready\"].value = 1 # If the response is valid, retrieve the response data from io_bus and put it into the response queue if self.io_bus.IsRespValid(): res = self.io_bus.get_resp_rdata() self.resp_que.put_nowait(res) In the code above, the message-driven flow proceeds as follows:\nEncapsulating Software Stimuli: Software stimuli are first encapsulated into ReqMsg objects, which contain all necessary information such as address, command, data, etc. This example uses the Guoke cache verification as an example. Storing Requests with Message Queues: Encapsulated requests are placed into the req_que of the CacheWrapper class. This queue acts as a buffer for software stimuli, allowing software to send requests at any time without waiting for an immediate hardware response. Decoupled Callback Mechanism: The __callback method of the CacheWrapper class is triggered on the rising edge of the hardware clock. This method checks whether there are pending requests in the request queue and decides whether to process them based on the current hardware state. This is a key step in the decoupling process, as it separates the sending of software stimuli from hardware timing. Simulating Hardware Response: Encapsulated requests are placed into the req_que of the CacheWrapper class. This queue acts as a buffer for software stimuli, allowing software to send requests at any time without waiting for an immediate hardware response. Software Receiving Responses: Software can retrieve responses from the response queue via the recv method of the CacheWrapper class. This process is synchronous but allows software to check the response queue at any time rather than at specific hardware timing points. Through this process, software requests (stimuli) and hardware responses (timing) are effectively decoupled. Software can freely send requests, while hardware processes these requests at appropriate timings and generates responses. This separation ensures that software development and testing can be independent of specific hardware behavior, greatly enhancing development efficiency and system scalability. To avoid manually writing code every time, we provide a framework called MLVP, which includes a series of ready-made message-driven methods.\n","categories":["Example Projects","Tutorials"],"description":"Decoupling Circuit and Software Excitation Using Messages","excerpt":"Decoupling Circuit and Software Excitation Using Messages","ref":"/mlvp/en/docs/advance_func/message/","tags":["examples","docs"],"title":"Message-Driven"},{"body":"Multi-File Input and Output In many cases, a module in one file may instantiate modules in other files. In such cases, you can use the picker tool’s -f option to process multiple Verilog source files. For example, suppose you have three source files: Cache.sv, CacheStage.sv, and CacheMeta.sv:\nFile List Cache.sv // In module Cache( ... ); CacheStage s1( ... ); CacheStage s2( ... ); CacheStage s3( ... ); CacheMeta cachemeta( ... ); endmodule CacheStage.sv // In CacheStage.sv module CacheStage( ... ); ... endmodule CacheMeta.sv // In CacheMeta.sv module CacheMeta( ... ); ... endmodule Usage In this case, the module under test is Cache, which is in Cache.sv. You can generate the DUT using the following command:\nCommand Line Specification picker Cache.sv -f CacheStage.sv,CacheMeta.sv -S Cache Specification through a File List File You can also use a .txt file to specify multiple input files:\npicker Cache.sv -f src.txt -S Cache Where the contents of src.txt are:\nCacheStage.sv CacheMeta.sv Notes It is important to note that even when using multiple file inputs, you still need to specify the file containing the top-level module under test, as shown in the example above with Cache.sv. When using multiple file inputs, Picker will pass all files to the simulator, which will compile them simultaneously. Therefore, it is necessary to ensure that the module names in all files are unique. ","categories":["Sample Projects","Tutorials"],"description":"Handling multiple Verilog source files","excerpt":"Handling multiple Verilog source files","ref":"/mlvp/en/docs/env_usage/multifile/","tags":["examples","docs"],"title":"Multi-File Input"},{"body":"Currently, Picker supports C++/Python. Other languages such as Java, Golang, Javascript, Scala, etc., will be supported after the Python interface is stabilized.\n","categories":["Tutorials"],"description":"Encapsulate the DUT hardware runtime environment with Java and package it as a jar file.","excerpt":"Encapsulate the DUT hardware runtime environment with Java and package …","ref":"/mlvp/en/docs/multi-lang/java/","tags":["docs"],"title":"Using Java ..."},{"body":" 以果壳cache为例，介绍如何创建基于Chisel的DUT\n在本文档中，DUT（Design Under Test）是指在芯片验证过程中，被验证的对象电路或系统。DUT是验证的主体，在基于picker工具创建DUT时，需要考虑被测对象的功能、性能要求和验证目标，例如是需要更快的执行速度，还是需要更详细的测试信息。通常情况下DUT，即RTL编写的源码，与外围环境一起构成验证环境（test_env），然后基于该验证环境编写测试用例。在本项目中，DUT是需要测试的Python模块，需要通过RTL进行转换。传统的RTL语言包括Verilog、System Verilog、VHDL等，然而作为新兴的RTL设计语言，Chisel（https://www.chisel-lang.org/）也以其面向对象的特征和便捷性，逐渐在RTL设计中扮演越来越重要的角色。本章以果壳处理器-NutShell中的cache源代码到Python模块的转换为例进行介绍如何创建DUT。\nChisel与果壳 准确来说，Chisel是基于Scala语言的高级硬件构造（HCL）语言。传统HDL是描述电路，而HCL则是生成电路，更加抽象和高级。同时Chisel中提供的Stage包则可以将HCL设计转化成Verilog、System Verilog等传统的HDL语言设计。配合上Mill、Sbt等Scala工具则可以实现自动化的开发。\n果壳是使用 Chisel 语言模块化设计的、基于 RISC-V RV64 开放指令集的顺序单发射处理器实现。果壳更详细的介绍请参考链接：https://oscpu.github.io/NutShell-doc/\n果壳 cache 果壳cache（Nutshell Cache）是果壳处理器中使用的缓存模块。其采用三级流水设计，当第三级流水检出当前请求为MMIO或者发生重填（refill）时，会阻塞流水线。同时，果壳cache采用可定制的模块化设计，通过改变参数可以生成存储空间大小不同的一级cache（L1 Cache）或者二级cache（L2 Cache）。此外，果壳cache留有一致性（coherence）接口，可以处理一致性相关的请求。\nChisel 转 Verilog Chisel中的stage库可以帮助由Chisel代码生成Verilog、System Verilog等传统的HDL代码。以下将简单介绍如何由基于Chisel的cache实现转换成对应的Verilog电路描述。\n初始化果壳环境 首先从源仓库下载整个果壳源代码，并进行初始化：\nmkdir cache-ut cd cache-ut git clone https://github.com/OSCPU/NutShell.git cd NutShell \u0026\u0026 git checkout 97a025d make init 创建scala编译配置 在cache-ut目录下创建build.sc，其中内容如下：\nimport $file.NutShell.build import mill._, scalalib._ import coursier.maven.MavenRepository import mill.scalalib.TestModule._ // 指定Nutshell的依赖 object difftest extends NutShell.build.CommonNS { override def millSourcePath = os.pwd / \"NutShell\" / \"difftest\" } // Nutshell 配置 object NtShell extends NutShell.build.CommonNS with NutShell.build.HasChiselTests { override def millSourcePath = os.pwd / \"NutShell\" override def moduleDeps = super.moduleDeps ++ Seq( difftest, ) } // UT环境配置 object ut extends NutShell.build.CommonNS with ScalaTest{ override def millSourcePath = os.pwd override def moduleDeps = super.moduleDeps ++ Seq( NtShell ) } 实例化 cache 创建好配置信息后，按照scala规范，创建src/main/scala源代码目录。之后，就可以在源码目录中创建nut_cache.scala，利用如下代码实例化Cache并转换成Verilog代码：\npackage ut_nutshell import chisel3._ import chisel3.util._ import nutcore._ import top._ import chisel3.stage._ object CacheMain extends App { (new ChiselStage).execute(args, Seq( ChiselGeneratorAnnotation(() =\u003e new Cache()(CacheConfig(ro = false, name = \"tcache\", userBits = 16))) )) } 生成RTL 完成上述所有文件的创建后（build.sc，src/main/scala/nut_cache.scala），在cache-ut目录下执行如下命令：\nmkdir build mill --no-server -d ut.runMain ut_nutshell.CacheMain --target-dir build --output-file Cache 注：mill环境的配置请参考 https://mill-build.com/mill/Intro_to_Mill.html\n上述命令成功执行完成后，会在build目录下生成verilog文件：Cache.v。之后就可以通过picker工具进行Cache.v到 Python模块的转换。除去chisel外，其他HCL语言几乎都能生成对应的 RTL代码，因此上述基本流程也适用于其他HCL。\nDUT编译 一般情况下，如果需要DUT生成波形、覆盖率等会导致DUT的执行速度变慢，因此在通过picker工具生成python模块时会根据多种配置进行生成：（1）关闭所有debug信息；（2）开启波形；（3）开启代码行覆盖率。其中第一种配置的目标是快速构建环境，进行回归测试等；第二种配置用于分析具体错误，时序等；第三种用于提升覆盖率。\n","categories":["示例项目","学习材料"],"description":"以果壳cache为例，介绍如何创建基于chisel的DUT","excerpt":"以果壳cache为例，介绍如何创建基于chisel的DUT","ref":"/mlvp/docs/basic/create_dut/","tags":["examples","docs"],"title":"创建DUT"},{"body":"多文件输入输出 在许多情况中，某文件下的某个模块会例化其他文件下的模块，在这种情况下您可以使用Picker工具的-f选项处理多个verilog源文件。例如，假设您有Cache.sv, CacheStage.sv以及CacheMeta.sv三个源文件：\n文件列表 Cache.sv // In module Cache( ... ); CacheStage s1( ... ); CacheStage s2( ... ); CacheStage s3( ... ); CacheMeta cachemeta( ... ); endmodule CacheStage.sv // In CacheStage.sv module CacheStage( ... ); ... endmodule CacheMeta.sv // In CacheMeta.sv module CacheMeta( ... ); ... endmodule 应用方式 其中，待测模块为Cache，位于Cache.sv中，则您可以通过以下命令生成DUT：\n命令行指定 picker Cache.sv -f CacheStage.sv,CacheMeta.sv -S Cache 通过文件列表文件指定 您也可以通过传入.txt文件的方式来实现多文件输入：\npicker Cache.sv -f src.txt -S Cache 其中src.txt的内容为:\nCacheStage.sv CacheMeta.sv 注意事项 需要注意的是，使用多文件输入时仍需要指定待测顶层模块所在的文件，例如上文中所示的Cache.sv。 在使用多文件输入时，Picker会将所有文件都交给仿真器，仿真器同时进行编译，因此需要保证所有文件中的模块名不重复。 ","categories":["示例项目","教程"],"description":"处理多个Verilog源文件","excerpt":"处理多个Verilog源文件","ref":"/mlvp/docs/env_usage/multifile/","tags":["examples","docs"],"title":"多文件输入"},{"body":"picker目前已经支持使用vcs进行仿真，相关文档还在完善中\n","categories":["示例项目","教程"],"description":"开放验证平台工具链的高级特性教程。","excerpt":"开放验证平台工具链的高级特性教程。","ref":"/mlvp/docs/advance_func/","tags":["examples","docs"],"title":"高级教程"},{"body":"目前picker支持C++/Python，其他语言例如 Java、Golang、Javascript，Scala 等在 python 接口稳定后跟进。\n","categories":["教程"],"description":"基于Java封装DUT硬件的运行环境，并打为jar包","excerpt":"基于Java封装DUT硬件的运行环境，并打为jar包","ref":"/mlvp/docs/multi-lang/java/","tags":["docs"],"title":"使用 Java ..."},{"body":"概述 消息驱动编程是一种编程范式，它依赖于异步消息传递以促进组件间的通信和协作。在这种模式下，系统的各个组件不是通过直接调用对方的函数或方法，而是通过发送和接收消息来交流。例如，在picker环境中，我们可以利用消息驱动的方法将电路的行为和软件的激励相解耦，这样就可以避免受到硬件电路时序限制的束缚。 在硬件电路测试中，硬件时序指的是电路中各个元件操作的顺序和时间间隔，这对于电路的正确运行至关重要。软件激励则是指用软件生成的一系列动作或信号，用以模拟外部事件对电路的影响，以测试电路的反应。将硬件时序与软件激励解耦是必要的，因为这样可以使得测试过程更加灵活和高效。这种解耦还有助于在不同的环境中重用软件激励，提高测试资源的利用率。总之，使用消息驱动来解耦硬件时序和软件激励可以提升测试的质量和可维护性，同时降低复杂性。\n消息驱动编程通常涉及以下几个概念和组件：\n消息： 消息是在组件之间传递的数据单元。消息可以是简单的数据结构、事件对象，甚至是命令。发送方将消息发送到一个目标，接收方则从目标接收消息。 消息队列： 消息队列是消息传递的中介。它负责存储和管理发送到它的消息，并将消息传递给接收方。消息队列可以基于内存或磁盘，可以是单播（一对一）、多播（一对多）或广播（一对所有）。 发布-订阅模式： 发布-订阅模式是消息驱动编程的一种常见实现方式。在这种模式中，发布者发布消息到一个或多个主题（topic），订阅者订阅感兴趣的主题，并接收相应的消息。 消息代理： 消息代理是处理消息传递的中间件组件。它负责接收和分发消息，管理消息队列，确保消息的可靠传递，以及提供其他消息相关的功能，如消息路由、消息过滤、消息持久化等 使用Pub/Sub模式来实现消息驱动 发布/订阅模式是一种在软件架构中常见的消息通信方式。在这个模式中，发布者不直接将消息发送给特定的接收者，而是发布（发送）到一个中间层，即消息代理。订阅者通过订阅感兴趣的消息类型或主题，来表明他们希望接收哪些消息。消息代理的职责是确保所有订阅了特定主题的客户端都能收到相应的消息。 这种模式的一个关键特点是发布者和订阅者之间的解耦。他们不需要知道对方的存在，也不需要直接通信。这提高了系统的灵活性和可扩展性，因为可以独立地添加或移除发布者和订阅者，而不会影响系统的其他部分。\n使用 Python 的内置队列模块实现的基本发布/订阅模型： 此处 Publisher 类具有消息队列和订阅者列表。使用发布方法发布消息时，会将其添加到队列中，并通过调用其接收方法传递到所有订阅的客户端。Subscriber 类具有一个 receive 方法，该方法仅打印收到的消息。 import queue # 发布者类 class Publisher: def __init__(self): # 初始化消息队列和订阅者列表 self.message_queue = queue.Queue() self.subscribers = [] def subscribe(self, subscriber): # 添加一个新的订阅者到订阅者列表 self.subscribers.append(subscriber) def publish(self, message): # 将消息放入队列并通知所有订阅者 self.message_queue.put(message) for subscriber in self.subscribers: # 调用订阅者的接收方法 subscriber.receive(message) # 订阅者类 class Subscriber: def __init__(self, name): # 初始化订阅者的名称 self.name = name def receive(self, message): # 打印接收到的消息 print(f\"{self.name} received message: {message}\") # 创建一个发布者实例 publisher = Publisher() # 创建两个订阅者实例 subscriber_1 = Subscriber(\"Subscriber 1\") subscriber_2 = Subscriber(\"Subscriber 2\") # 将订阅者添加到发布者的订阅者列表中 publisher.subscribe(subscriber_1) publisher.subscribe(subscriber_2) # 发布者发布一条消息 publisher.publish(\"Hello World\") 使用 Python 的线程模块实现的发布/订阅模型： 在此示例中，Publisher 类有一个订阅者字典，其中键是主题，值是订阅者列表。subscribe 方法将订阅服务器添加到指定主题的列表中。publish 方法检查指定主题是否有任何订阅者，如果有，则设置事件并存储每个订阅者的消息。Subscriber 类和 receive 方法与前面的示例相同。 import threading # 发布者类 class Publisher: def __init__(self): # 初始化订阅者字典，按主题组织 self.subscribers = {} def subscribe(self, subscriber, topic): # 订阅方法，将订阅者添加到特定主题 if topic not in self.subscribers: self.subscribers[topic] = [] self.subscribers[topic].append(subscriber) def publish(self, message, topic): # 发布方法，向特定主题的所有订阅者发送消息 if topic in self.subscribers: for subscriber in self.subscribers[topic]: # 设置事件标志，通知订阅者有新消息 subscriber.event.set() # 将消息传递给订阅者 subscriber.message = message # 订阅者类 class Subscriber: def __init__(self, name): # 初始化订阅者名称和事件标志 self.name = name self.event = threading.Event() self.message = None def receive(self): # 接收方法，等待事件标志被设置 self.event.wait() # 打印接收到的消息 print(f\"{self.name} received message: {self.message}\") # 清除事件标志，准备接收下一个消息 self.event.clear() # 创建发布者实例 publisher = Publisher() # 创建三个订阅者实例 subscriber_1 = Subscriber(\"Subscriber 1\") subscriber_2 = Subscriber(\"Subscriber 2\") subscriber_3 = Subscriber(\"Subscriber 3\") # 将订阅者根据主题订阅到发布者 publisher.subscribe(subscriber_1, \"sports\") publisher.subscribe(subscriber_2, \"entertainment\") publisher.subscribe(subscriber_3, \"sports\") # 发布者发布一条属于'sports'主题的消息 publisher.publish(\"Soccer match result\", \"sports\") # 订阅者1接收并处理消息 subscriber_1.receive() 使用消息驱动进行验证 下面我们将以果壳cache的验证过程为例，来介绍消息驱动在验证中的使用。 完整代码参见。\nfrom util.simplebus import SimpleBusWrapper from tools.colorprint import Color as cl import xspcomm as xsp import queue # 请求消息类，用于封装通信请求的详细信息 class ReqMsg: def __init__(self, addr, cmd, user=0x123, size=7, mask=0, data=0): self.user = user self.size = size self.addr = addr self.cmd = cmd self.mask = mask self.data = data def display(self): print(f\"[REQ MSG] user {self.user:x}, size {self.size}, addr 0x{self.addr:x} \" f\"cmd 0x{self.cmd:x}, mask {self.mask:b}, data {self.data:x}\") # 缓存包装器类，模拟缓存的行为并与外部总线通信 class CacheWrapper: def __init__(self, io_bus: SimpleBusWrapper, clk: xsp.XClock, cache_port: xsp.XPort): self.xclk = clk # 简单总线包装器，用于与外部通信 self.io_bus = io_bus # 缓存端口，可能用于与外部组件交互 self.cache_port = cache_port # 初始化请求队列，用于存储即将处理的请求消息 self.req_que = queue.Queue() # 初始化响应队列，用于存储处理完的响应消息 self.resp_que = queue.Queue() # 注册硬件时钟上升沿的回调方法，用于处理请求和响应 self.xclk.StepRis(self.__callback) # 发起一个读请求 def trigger_read_req(self, addr): # 将读请求消息放入请求队列，不等待队列锁定 self.req_que.put_nowait(ReqMsg(addr=addr, cmd=self.io_bus.cmd_read)) # 发起一个写请求 def trigger_write_req(self, addr, data, mask): # 将写请求消息放入请求队列，不等待队列锁定 self.req_que.put_nowait(ReqMsg(addr=addr, cmd=self.io_bus.cmd_write, mask=mask, data=data)) # 接收响应 def recv(self): # 等待响应队列非空，然后取出响应 while self.resp_que.empty(): self.xclk.Step(1) return self.resp_que.get() # 读取数据 def read(self, addr): # 发起读请求，然后等待并返回响应 self.trigger_read_req(addr) return self.recv() # 写入数据 def write(self, addr, data, mask): # 发起写请求，然后等待并返回响应 self.trigger_write_req(addr, data, mask) return self.recv() # 重置缓存 def reset(self): # 设置复位信号，等待一定时钟周期，然后清除复位信号 self.cache_port[\"reset\"].value = 1 self.xclk.Step(100) self.cache_port[\"reset\"].value = 0 self.cache_port[\"io_flush\"].value = 0 # 等待请求准备就绪信号 while not self.io_bus.IsReqReady(): self.xclk.Step(1) # 硬件时钟上升沿的回调方法 def __callback(self, *a, **b): # 处理请求 if self.io_bus.IsReqSend(): # 如果有请求发送，从请求队列取出一个请求 self.req_que.get() # 检查请求队列是否为空 if self.req_que.empty(): # 如果请求队列为空，向io_bus发送无效请求信号 self.io_bus.ReqUnValid() else: # 如果请求队列不为空，向io_bus发送有效请求信号 self.io_bus.ReqSetValid() # 取出队首的请求消息 msg: ReqMsg = self.req_que.queue[0] # 根据请求命令类型，执行读或写操作 if msg.cmd == self.io_bus.cmd_read: self.io_bus.ReqReadData(msg.addr) if msg.cmd == self.io_bus.cmd_write: self.io_bus.ReqWriteData(msg.addr, msg.data, msg.mask) # 处理接收 self.io_bus.port[\"resp_ready\"].value = 1 # 如果响应有效，从io_bus获取响应数据，并放入响应队列 if self.io_bus.IsRespValid(): res = self.io_bus.get_resp_rdata() self.resp_que.put_nowait(res) 在上述代码中，进行消息驱动的流程如下：\n封装软件激励： 软件激励首先被封装进ReqMsg对象中，这个对象包含了所有必要的信息，如地址、命令、数据等。此处以果壳cache的验证为例。 使用消息队列存储请求： 封装后的请求被放入CacheWrapper类的请求队列req_que中。这个队列作为软件激励的缓冲区，允许软件在任何时刻发送请求，而不必等待硬件的即时响应。 解耦的回调机制： 在硬件时钟上升沿，CacheWrapper类的__callback方法被触发。这个方法检查请求队列中是否有待处理的请求，并根据当前的硬件状态决定是否处理这些请求。这是解耦过程中的关键步骤，因为它将软件激励的发送与硬件时序的处理分离开来。 模拟硬件响应： 封装后的请求被放入CacheWrapper类的请求队列req_que中。这个队列作为软件激励的缓冲区，允许软件在任何时刻发送请求，而不必等待硬件的即时响应。 软件接收响应： 软件可以通过CacheWrapper类的recv方法从响应队列中取出响应。这个过程是同步的，但它允许软件在任何时刻检查响应队列，而不是必须在特定的硬件时序点上。 通过上述过程，软件的请求（激励）和硬件的响应（时序）被有效地解耦。软件可以自由地发送请求，而硬件则在适当的时序下处理这些请求，生成响应。这样的分离确保了软件的开发和测试可以与硬件的具体行为相独立，极大提升了开发效率和系统的可扩展性。为了避免每次都手动编写代码，我们提供了一个名为MLVP的框架，它包含了一系列现成的消息驱动方法。\n","categories":["示例项目","教程"],"description":"利用消息对电路和软件激励进行解耦","excerpt":"利用消息对电路和软件激励进行解耦","ref":"/mlvp/docs/advance_func/message/","tags":["examples","docs"],"title":"消息驱动"},{"body":"","categories":["Example Projects","Tutorials"],"description":"Complex case studies completed using the open verification platform.","excerpt":"Complex case studies completed using the open verification platform.","ref":"/mlvp/en/docs/advance_case/","tags":["examples","docs"],"title":"Advanced Case Studies"},{"body":"RTL Source Code In this case, we drive a random number generator with the following source code:\nmodule RandomGenerator ( input wire clk, input wire reset, input [15:0] seed, output [15:0] random_number ); reg [15:0] lfsr; always @(posedge clk or posedge reset) begin if (reset) begin lfsr \u003c= seed; end else begin lfsr \u003c= {lfsr[14:0], lfsr[15] ^ lfsr[14]}; end end assign random_number = lfsr; endmodule This random number generator consists of a 16-bit LFSR. It takes a 16-bit seed as input and produces a 16-bit random number as output. The LFSR update rule is as follows:\nXOR the most significant bit and the second most significant bit of the current LFSR value to get a new bit. Shift the original LFSR value to the left by one bit, and place the new bit at the least significant position. Discard the most significant bit. Testing Process During testing, we will create a folder named RandomGenerator containing a file RandomGenerator.v with the RTL source code provided above.\nBuilding RTL into a Python Module Generating Intermediate Files Navigate to the RandomGenerator folder and execute the following command:\npicker --autobuild=false RandomGenerator.v -w RandomGenerator.fst -S RandomGenerator -t picker_out_rmg -l python -e --sim verilator This command performs the following actions:\nUses RandomGenerator.v as the top file and RandomGenerator as the top module, generates a dynamic library based on the Verilator simulator, and targets the Python language. Enables waveform output, targeting the RandomGenerator.fst waveform file. Includes the files needed to drive the example project (-e) and does not automatically compile after code generation (-autobuild=false). Outputs the files to the picker_out_rmg directory. The output directory structure is similar to [Adder Verification - Generating Intermediate Files](/docs/quick-start/eg-adder/#Generating Intermediate Files)，and will not be further elaborated here.\nBuilding Intermediate Files Navigate to the picker_out_rmg directory and execute the make command to generate the final files.\nNote: The compilation process is similar to [Adder Verification - Compilation Process](/docs/quick-start/eg-adder/#Generating Intermediate Files), and will not be further elaborated here.\nThe final directory structure is:\npicker_out_rmg |-- RandomGenerator.fst # Waveform file from the test |-- UT_RandomGenerator | |-- RandomGenerator.fst.hier | |-- _UT_RandomGenerator.so # SWIG-generated wrapper dynamic library | |-- __init__.py # Python module initialization file and library definition file | |-- libDPIRandomGenerator.a # Library file generated by the simulator | |-- libUTRandomGenerator.so # Dynamic library wrapper based on dut_base | |-- libUT_RandomGenerator.py # Python module generated by SWIG | |-- xspcomm # xspcomm base library, fixed folder, no need to focus on it `-- example.py # Example code Configuring the Test Code Note: You need to replace the content in example.py to ensure the example project runs as expected.\nfrom UT_RandomGenerator import * import random class LFSR_16: def __init__(self, seed): self.state = seed \u0026 ((1 \u003c\u003c 16) - 1) def step(self): new_bit = (self.state \u003e\u003e 15) ^ (self.state \u003e\u003e 14) \u0026 1 self.state = ((self.state \u003c\u003c 1) | new_bit ) \u0026 ((1 \u003c\u003c 16) - 1) if __name__ == \"__main__\": dut = DUTRandomGenerator() dut.init_clock(\"clk\") seed = random.randint(0, 2**16 - 1) dut.seed.value = seed ref = LFSR_16(seed) # reset dut.reset.value = 1 dut.Step(1) # This step performs the initialization assignment dut.reset.value = 0 # Remember to reset the signal after setting! dut.Step(1) for i in range(65536): print(f\"Cycle {i}, DUT: {dut.random_number.value:x}, REF: {ref.state:x}\") assert dut.random_number.value == ref.state, \"Mismatch\" dut.Step(1) ref.step() print(\"Test Passed, destroy UT_RandomGenerator\") dut.finalize() Running the Test Program Execute python example.py in the picker_out_rmg directory to run the test program. If the output is Test Passed, destroy UT_RandomGenerator, the test has passed.\nExample output:\n··· Cycle 65529, DUT: d9ea, REF: d9ea Cycle 65530, DUT: b3d4, REF: b3d4 Cycle 65531, DUT: 67a9, REF: 67a9 Cycle 65532, DUT: cf53, REF: cf53 Cycle 65533, DUT: 9ea6, REF: 9ea6 Cycle 65534, DUT: 3d4d, REF: 3d4d Cycle 65535, DUT: 7a9a, REF: 7a9a Test Passed, destroy UT_RandomGenerator ","categories":["Example Projects","Tutorials"],"description":"Demonstrating the tool usage with a 16-bit LFSR random number generator, which includes a clock signal, sequential logic, and registers.","excerpt":"Demonstrating the tool usage with a 16-bit LFSR random number …","ref":"/mlvp/en/docs/quick-start/eg-rmg/","tags":["examples","docs"],"title":"Case 2: Random Number Generator"},{"body":" The Picker tool supports generating code line coverage reports, and the MLVP（https://github.com/XS-MLVP/mlvp）project supports generating functional coverage reports.\nCode Line Coverage Currently, the Picker tool supports generating code line coverage reports based on the Verilator simulator.\nVerilator The Verilator simulator provides coverage support.\nThe implementation is as follows:\nUse the verilator_coverage tool to process or merge coverage databases, ultimately generating a coverage.info file for multiple DUTs. Use the genhtml command of the lcov tool based on coverage.info and RTL code source files to generate a complete code coverage report. The process is as follows:\nEnable the COVERAGE feature when generating the DUT with Picker (add the -c option). After the simulator runs, a coverage database file V{DUT_NAME}.dat will be generated after dut.finalize() is called. Use the write-info function of verilator_coverage to convert it to a .info file. Use the genhtml function of lcov to generate an HTML report using the .info file and the RTL source files specified in the file. Note: The RTL source files specified in the file refer to the source file paths used when generating the DUT, and these paths need to be valid in the current environment. In simple terms, all .sv/.v files used for compilation need to exist in the current environment, and the directory remains unchanged.\nverilator_coverage The verilator_coverage tool is used to process coverage data generated by the DUT after running .dat files. The tool can process and merge multiple .dat files and has two main functions:\nGenerate a .info file based on the .dat file for subsequent generation of a web page report.\n-annotate \u003coutput_dir\u003e：Present the coverage situation in the source file in annotated form, and save the result to output_dir. The format is as follows:\n100000 input logic a; // Begins with whitespace, because // number of hits (100000) is above the limit. %000000 input logic b; // Begins with %, because // number of hits (0) is below the limit. -annotate-min \u003ccount\u003e：Specify the limit as count for the above.\nCombine the .dat file with the source code file, and write the coverage data in annotated form into the specified directory.\n-write \u003cmerged-datafile\u003e -read \u003cdatafiles\u003e：Merge several .dat (datafiles) files into one .dat file. -write-info \u003cmerged-info\u003e -read \u003cdatafiles\u003e：Merge several .dat (datafiles) files into one .info file. genhtml The genhtml provided by the lcov package can export a more readable HTML report from the .info file. The command format is: genhtml [OPTIONS] \u003cinfofiles\u003e. It is recommended to use the -o \u003coutputdir\u003e option to output the results to a specified directory.\nFor example, in theAddr project. Usage Example If you enable the -c option when using Picker, after the simulation ends, a V{DUT_NAME}.dat file will be generated. And there will be a Makefile in the top-level directory, which contains the command to generate the coverage report.\nThe command is as follows:\ncoverage: ... verilator_coverage -write-info coverage.info ./${TARGET}/V${PROJECT}_coverage.dat genhtml coverage.info --output-directory coverage ... Enter make coverage in the shell, which will generate coverage.info based on the generated .dat file and then use genhtml to generate an html report in the coverage directory.\nVCS Documentation for VCS is currently being finalized.\n","categories":["Sample Projects","Tutorials"],"description":"Coverage tools","excerpt":"Coverage tools","ref":"/mlvp/en/docs/env_usage/coverage/","tags":["examples","docs"],"title":"Coverage Statistics"},{"body":"RTL源码 在本案例中，我们驱动一个随机数生成器，其源码如下：\nmodule RandomGenerator ( input wire clk, input wire reset, input [15:0] seed, output [15:0] random_number ); reg [15:0] lfsr; always @(posedge clk or posedge reset) begin if (reset) begin lfsr \u003c= seed; end else begin lfsr \u003c= {lfsr[14:0], lfsr[15] ^ lfsr[14]}; end end assign random_number = lfsr; endmodule 该随机数生成器包含一个 16 位的 LFSR，其输入为一个 16 位的种子数，输出为一个 16 位的随机数。LFSR 的更新规则为：\n将当前的 LFSR 的最高位与次高位异或，称为new_bit。 将原来的 LFSR 向左平移一位，将 new_bit 放在最低位。 丢弃最高位。 测试过程 在测试过程中，我们将创建一个名为 RandomGenerator 的文件夹，其中包含一个 RandomGenerator.v 文件。该文件内容即为上述的 RTL 源码。\n将RTL构建为 Python Module 生成中间文件 进入 RandomGenerator 文件夹，执行如下命令：\npicker --autobuild=false RandomGenerator.v -w RandomGenerator.fst -S RandomGenerator -t picker_out_rmg -l python -e --sim verilator 该命令的含义是：\n将RandomGenerator.v作为 Top 文件，并将RandomGenerator作为 Top Module，基于 verilator 仿真器生成动态库，生成目标语言为 Python。 启用波形输出，目标波形文件为RandomGenerator.fst 包含用于驱动示例项目的文件(-e)，同时codegen完成后不自动编译(-autobuild=false)。 最终的文件输出路径是 picker_out_rmg 输出的目录类似加法器验证-生成中间文件，这里不再赘述。\n构建中间文件 进入 picker_out_rmg 目录并执行 make 命令，即可生成最终的文件。\n备注：其编译过程类似于 加法器验证-编译流程，这里不再赘述。\n最终目录结果为：\npicker_out_rmg |-- RandomGenerator.fst # 测试的波形文件 |-- UT_RandomGenerator | |-- RandomGenerator.fst.hier | |-- _UT_RandomGenerator.so # Swig生成的wrapper动态库 | |-- __init__.py # Python Module的初始化文件，也是库的定义文件 | |-- libDPIRandomGenerator.a # 仿真器生成的库文件 | |-- libUTRandomGenerator.so # 基于dut_base生成的libDPI动态库封装 | `-- libUT_RandomGenerator.py # Swig生成的Python Module | `-- xspcomm # xspcomm基础库，固定文件夹，不需要关注 `-- example.py # 示例代码 配置测试代码 注意需要替换 example.py 中的内容，才能保证 example 示例项目按预期运行。\nfrom UT_RandomGenerator import * import random class LFSR_16: def __init__(self, seed): self.state = seed \u0026 ((1 \u003c\u003c 16) - 1) def step(self): new_bit = (self.state \u003e\u003e 15) ^ (self.state \u003e\u003e 14) \u0026 1 self.state = ((self.state \u003c\u003c 1) | new_bit ) \u0026 ((1 \u003c\u003c 16) - 1) if __name__ == \"__main__\": dut = DUTRandomGenerator() dut.init_clock(\"clk\") seed = random.randint(0, 2**16 - 1) dut.seed.value = seed ref = LFSR_16(seed) # reset dut.reset.value = 1 dut.Step(1) # 该步进行了初始化赋值操作 dut.reset.value = 0 # 设置完成后需要记得复位原信号！ dut.Step(1) for i in range(65536): print(f\"Cycle {i}, DUT: {dut.random_number.value:x}, REF: {ref.state:x}\") assert dut.random_number.value == ref.state, \"Mismatch\" dut.Step(1) ref.step() print(\"Test Passed, destroy UT_RandomGenerator\") dut.finalize() 运行测试程序 在 picker_out_rmg 目录下执行 python example.py 即可运行测试程序。在运行完成后，若输出 Test Passed, destroy UT_RandomGenerator，则表示测试通过。\n输出示例：\n··· Cycle 65529, DUT: d9ea, REF: d9ea Cycle 65530, DUT: b3d4, REF: b3d4 Cycle 65531, DUT: 67a9, REF: 67a9 Cycle 65532, DUT: cf53, REF: cf53 Cycle 65533, DUT: 9ea6, REF: 9ea6 Cycle 65534, DUT: 3d4d, REF: 3d4d Cycle 65535, DUT: 7a9a, REF: 7a9a Test Passed, destroy UT_RandomGenerator ","categories":["示例项目","教程"],"description":"基于一个16bit的LFSR随机数生成器展示工具的用法，该随机数生成器内部存在时钟信号、时序逻辑与寄存器。","excerpt":"基于一个16bit的LFSR随机数生成器展示工具的用法，该随机数生成器内部存在时钟信号、时序逻辑与寄存器。","ref":"/mlvp/docs/quick-start/eg-rmg/","tags":["examples","docs"],"title":"案例二：随机数生成器"},{"body":" Picker 工具支持生成代码行覆盖率报告，MLVP（https://github.com/XS-MLVP/mlvp） 项目支持生成功能覆盖率报告。\n代码行覆盖率 目前 Picker 工具支持基于 Verilator 仿真器生成的代码行覆盖率报告。\nVerilator Verilator 仿真器提供了覆盖率支持功能。\n该功能的实现方式是：\n利用 verilator_coverage 工具处理或合并覆盖率数据库，最终针对多个DUT生成一个 coverage.info 文件。 利用 lcov 工具的 genhtml 命令基于coverage.info和RTL代码源文件，生成完整的代码覆盖率报告。 使用时的流程如下：\n使用 Picker 生成 dut 时，使能 COVERAGE 功能 （添加-c选项）。 仿真器运行完成后，dut.finalize() 之后会生成覆盖率数据库文件 V{DUT_NAME}.dat。 基于 verilator_coverage 的 write-info 功能将其转换成 .info文件。 基于 lcov 的 genhtml 功能，使用.info文件和文件中指定的rtl源文件，生成html报告。 注意： 文件中指定的rtl源文件是指在生成的DUT时使用的源文件路径，需要保证这些路径在当前环境下是有效的。简单来说，需要编译时用到的所有.sv/.v文件都需要在当前环境下存在，并且目录不变。\nverilator_coverage verilator_coverage 工具用于处理 DUT 运行后生成的 .dat 的覆盖率数据。该工具可以处理并合并多个 .dat 文件，同时具有两类功能：\n基于 .dat 文件生成 .info 文件，用于后续生成网页报告。\n-annotate \u003coutput_dir\u003e：以标注的形式在源文件中呈现覆盖率情况，结果保存到output_dir中。形式如下：\n100000 input logic a; // Begins with whitespace, because // number of hits (100000) is above the limit. %000000 input logic b; // Begins with %, because // number of hits (0) is below the limit. -annotate-min \u003ccount\u003e：指定上述的limit为count\n可以将 .dat 文件，结合源代码文件，将覆盖率数据以标注的形式与源代码结合在一起，并写入到指定目录。\n-write \u003cmerged-datafile\u003e -read \u003cdatafiles\u003e：将若干个.dat(datafiles)文件合并为一个.dat文件 -write-info \u003cmerged-info\u003e -read \u003cdatafiles\u003e：将若干个.dat(datafiles)文件合并为一个.info文件 genhtml 由 locv 包提供的 genhtml 可以由上述的.info文件导出可读性更好的html报告。命令格式为：genhtml [OPTIONS] \u003cinfofiles\u003e。 建议使用-o \u003coutputdir\u003e选项将结果输出到指定目录。\n以加法器为例。\n使用示例 如果您使用Picker时打开了-c选项，那么在仿真结束后，会生成一个V{DUT_NAME}.dat文件。并且顶层目录会有一个Makefile文件，其中包含了生成覆盖率报告的命令。\n命令内容如下：\ncoverage: ... verilator_coverage -write-info coverage.info ./${TARGET}/V${PROJECT}_coverage.dat genhtml coverage.info --output-directory coverage ... 在shell中输入make coverage,其会根据生成的.dat文件生成coverage.info，再使用genhtml再coverage目录下生成html报告。\nVCS VCS对应的文档正在完善当中。\n","categories":["示例项目","教程"],"description":"覆盖率工具","excerpt":"覆盖率工具","ref":"/mlvp/docs/env_usage/coverage/","tags":["examples","docs"],"title":"覆盖率统计"},{"body":"","categories":["示例项目","教程"],"description":"基于开放验证平台完成验证的复杂案例。","excerpt":"基于开放验证平台完成验证的复杂案例。","ref":"/mlvp/docs/advance_case/","tags":["examples","docs"],"title":"高级案例"},{"body":" This section introduces the general process of verifying a DUT based on Picker.\nThe goal of the open verification platform is functional verification, which generally involves the following steps:\n1. Determine the verification object and goals Typically, the design documentation of the DUT is also delivered to the verification engineer. At this point, you need to read the documentation or source code to understand the basic functions, main structure, and expected functionalities of the verification object.\n2. Build the basic verification environment After fully understanding the design, you need to build the basic verification environment. For example, in addition to the DUT generated by Picker, you may also need to set up a reference model for comparison and a signal monitoring platform for evaluating subsequent functional points.\n3. Decompose functional points and test points Before officially starting the verification, you need to extract the functional points and further decompose them into test points. You can refer to: CSDN: Chip Verification Series - Decomposition of Testpoints\n4. Construct test cases With the test points, you need to construct test cases to cover the corresponding test points. A test case may cover multiple test points.\n5. Collect test results After running all the test cases, you need to summarize all the test results. Generally, this includes line coverage and functional coverage. The former can be obtained through the coverage function provided by the Picker tool, while the latter requires you to judge whether a function is covered by the test cases through monitoring the behavior of the DUT.\n6. Evaluate the test results Finally, you need to evaluate the obtained results, such as whether there are design errors, whether a function cannot be triggered, whether the design documentation description is consistent with the DUT behavior, and whether the design documentation is clearly described.\nNext, we will introduce the general verification process usingMMIO read and write of Nutshell Cache as an example:\n1 Determine the verification object and goals:：\nThe MMIO read and write function of the Nutshell Cache. MMIO is a special type of IO mapping that supports accessing IO device registers by accessing memory addresses. Since the register state of IO devices can change at any time, it is not suitable to cache it. When receiving an MMIO request, the Nutshell cache will directly access the MMIO memory area to read or write data instead of querying hit/miss in the ordinary cache line.\n2 Build the basic verification environment:：\nWe can roughly divide the verification environment into five parts: 1. Testcase Driver：Responsible for generating corresponding signals driven by test cases 2. Monitor：Monitors signals to determine whether functions are covered and correct 3. Ref Cache：A simple reference model 4. Memory/MMIO Ram：Simulates peripheral devices to simulate corresponding cache requests 5. Nutshell Cache Dut：DUT generated by Picker\nIn addition, you may need to further encapsulate the DUT interface to achieve more convenient read and write request operations. For details, refer to Nutshll cachewrapper.\n3 Decompose functional points and test points：\nNutshell cache can respond to MMIO requests, further decomposing into the following test points:\nTest Point 1：MMIO requests will be forwarded to the MMIO port Test Point 2：The cache will not issue burst transfer requests when responding to MMIO requests Test Point 3：The cache will block the pipeline when responding to MMIO requests\n4 Construct test cases： The construction of test cases is simple. Knowing that the MMIO address range of the Nutshell cache obtained through Creating DUTis 0x30000000~0x7fffffff, we only need to access this memory range to obtain the expected MMIO results. Note that to trigger the test point of blocking the pipeline, you may need to initiate requests continuously.\nHere is a simple test case:\n# import CacheWrapper here def mmio_test(cache: CacheWrapper): mmio_lb\t= 0x30000000 mmio_rb\t= 0x30001000 print(\"\\n[MMIO Test]: Start MMIO Serial Test\") for addr in range(mmio_lb, mmio_rb, 16): addr \u0026= ~(0xf) addr1 = addr addr2 = addr + 4 addr3 = addr + 8 cache.trigger_read_req(addr1) cache.trigger_read_req(addr2) cache.trigger_read_req(addr3) cache.recv() cache.recv() cache.recv() print(\"[MMIO Test]: Finish MMIO Serial Test\") 5 Collect test results：\n''' In tb_cache.py ''' # import packages here class TestCache(): def setup_class(self): color.print_blue(\"\\nCache Test Start\") self.dut = DUTCache(\"libDPICache.so\") self.dut.init_clock(\"clock\") # Init here # ... self.testlist = [\"mmio_serial\"] def teardown_class(self): self.dut.finalize() color.print_blue(\"\\nCache Test End\") def __reset(self): # Reset cache and devices # MMIO Test def test_mmio(self): if (\"mmio_serial\" in self.testlist): # Run test from ..test.test_mmio import mmio_test mmio_test(self.cache, self.ref_cache) else: print(\"\\nmmio test is not included\") def run(self): self.setup_class() # test self.test_mmio() self.teardown_class() pass if __name__ == \"__main__\": tb = TestCache() tb.run() Run：\npython3 tb_cache.py The above is only a rough execution process, for details refer to：Nutshell Cache Verify。\n6 Evaluate the running results\nAfter the run is complete, the following data can be obtained: Line coverage: Functional coverage: It can be seen that the preset MMIO functions are all covered and correctly triggered.\n","categories":["Example Projects","Learning Materials"],"description":"Overview of the general verification process","excerpt":"Overview of the general verification process","ref":"/mlvp/en/docs/basic/test_dut/","tags":["examples","docs"],"title":"DUT Verification"},{"body":" 本节介绍基于Picker验证DUT的一般流程\n开放验证平台的目标是功能性验证，其一般有以下步骤：\n1. 确定验证对象和目标 通常来说，同时交付给验证工程师的还有DUT的设计文档。此时您需要阅读文档或者源代码，了解验证对象的基本功能、主体结构以及预期功能。\n2. 构建基本验证环境 充分了解设计之后，您需要构建验证的基本环境。例如，除了由Picker生成的DUT外，您可能还需要搭建用于比对的参考模型，也可能需要为后续功能点的评测搭建信号的监听平台。\n3. 功能点与测试点分解 在正式开始验证之前，您还需要提取功能点，并将其进一步分解成测试点。提取和分解方法可以参考：CSDN:芯片验证系列——Testpoints分解\n4. 构造测试用例 有了测试点之后，您需要构造测试用例来覆盖相应的测试点。一个用例可能覆盖多个测试点。\n5. 收集测试结果 运行完所有的测试用例之后，您需要汇总所有的测试结果。一般来说包括代码行覆盖率以及功能覆盖率。前者可以通过Picker工具提供的覆盖率功能获得，后者则需要您通过监听DUT的行为判断某功能是否被用例覆盖到。\n6. 评估测试结果 最后您需要评估得到的结果，如是否存在错误的设计、某功能是否无法被触发、设计文档表述是否与DUT行为一致、设计文档是否表述清晰等。\n接下来我们以果壳Cache的MMIO读写为例，介绍一般验证流程：\n1 确定验证对象和目标：\n果壳Cache的MMIO读写功能。MMIO是一类特殊的IO映射，其支持通过访问内存地址的方式访问IO设备寄存器。由于IO设备的寄存器状态是随时可能改变的，因此不适合将其缓存在cache中。当收到MMIO请求时，果壳cache不会在普通的cache行中查询命中/缺失情况，而是会直接访问MMIO的内存区域来读取或者写入数据。\n2 构建基本验证环境：\n我们可以将验证环境大致分为五个部分：\n1. Testcase Driver：负责由用例产生相应的信号驱动\n2. Monitor：监听信号，判断功能是否被覆盖以及功能是否正确\n3. Ref Cache：一个简单的参考模型\n4. Memory/MMIO Ram：外围设备的模拟，用于模拟相应cache的请求\n5. Nutshell Cache Dut：由Picker生成的DUT\n此外，您可能还需要对DUT的接口做进一步封装以实现更方便的读写请求操作，具体可以参考Nutshll cachewrapper。\n3 功能点与测试点分解：\n果壳cache可以响应MMIO请求，进一步分解可以得到一下测试点：\n测试点1：MMIO请求会被转发到MMIO端口上\n测试点2：cache响应MMIO请求时，不会发出突发传输（Burst Transfer）的请求\n测试点3：cache响应MMIO请求时，会阻塞流水线\n4 构造测试用例： 测试用例的构造是简单的，已知通过创建DUT得到的Nutshell cache的MMIO地址范围是0x30000000~0x7fffffff，则我们只需访问这段内存区间，应当就能获得MMIO的预期结果。需要注意的是，为了触发阻塞流水线的测试点，您可能需要连续地发起请求。\n以下是一个简单的测试用例：\n# import CacheWrapper here def mmio_test(cache: CacheWrapper): mmio_lb\t= 0x30000000 mmio_rb\t= 0x30001000 print(\"\\n[MMIO Test]: Start MMIO Serial Test\") for addr in range(mmio_lb, mmio_rb, 16): addr \u0026= ~(0xf) addr1 = addr addr2 = addr + 4 addr3 = addr + 8 cache.trigger_read_req(addr1) cache.trigger_read_req(addr2) cache.trigger_read_req(addr3) cache.recv() cache.recv() cache.recv() print(\"[MMIO Test]: Finish MMIO Serial Test\") 5 收集测试结果：\n''' In tb_cache.py ''' # import packages here class TestCache(): def setup_class(self): color.print_blue(\"\\nCache Test Start\") self.dut = DUTCache(\"libDPICache.so\") self.dut.init_clock(\"clock\") # Init here # ... self.testlist = [\"mmio_serial\"] def teardown_class(self): self.dut.finalize() color.print_blue(\"\\nCache Test End\") def __reset(self): # Reset cache and devices # MMIO Test def test_mmio(self): if (\"mmio_serial\" in self.testlist): # Run test from ..test.test_mmio import mmio_test mmio_test(self.cache, self.ref_cache) else: print(\"\\nmmio test is not included\") def run(self): self.setup_class() # test self.test_mmio() self.teardown_class() pass if __name__ == \"__main__\": tb = TestCache() tb.run() 运行：\npython3 tb_cache.py 以上仅为大致的运行流程，具体可以参考：Nutshell Cache Verify。\n6 评估运行结果\n运行结束之后可以得到以下数据：\n行覆盖率：\n功能覆盖率：\n可以看到预设的MMIO功能均被覆盖且被正确触发。\n","categories":["示例项目","学习材料"],"description":"介绍验证的一般流程","excerpt":"介绍验证的一般流程","ref":"/mlvp/docs/basic/test_dut/","tags":["examples","docs"],"title":"DUT验证"},{"body":" In traditional chip verification practices, frameworks like UVM are widely adopted. Although they provide a comprehensive set of verification methodologies, they are typically confined to specific hardware description languages and simulation environments. Our tool breaks these limitations by converting simulation code into C++ or Python, allowing us to leverage software verification tools for more comprehensive testing. Given Python’s robust ecosystem, this project primarily uses Python as an example, briefly introducing two classic software testing frameworks: Pytest and Hypothesis. Pytest handles various testing needs with its simple syntax and rich features. Meanwhile, Hypothesis enhances the thoroughness and depth of testing by generating test cases that uncover unexpected edge cases. Our project is designed from the outset to be compatible with various modern software testing frameworks. We encourage you to explore the potential of these tools and apply them to your testing processes. Through hands-on practice, you will gain a deeper understanding of how these tools can enhance code quality and reliability. Let’s work together to improve the quality of chip development.\n","categories":["Sample Projects","Tutorials"],"description":"Available Software Testing Frameworks","excerpt":"Available Software Testing Frameworks","ref":"/mlvp/en/docs/env_usage/frameworks/","tags":["examples","docs"],"title":"Integrated Testing Framework"},{"body":"The Python DUT generated by the Picker tool allows us to perform simple verification within the Python environment, including DUT instantiation, signal assignment, clock driving, and other operations. However, in practical verification work, we typically require more advanced verification features, such as coroutine support, coverage collection, and report generation. For this purpose, we provide the MLVP (Multi-language Verification Platform) verification framework to offer these advanced verification features.\nCurrently, the MLVP verification framework supports the following features:\nCoroutine Support：The MLVP verification framework provides coroutine support, allowing users to easily write asynchronous verification code. Coverage Collection and Report Generation：The MLVP verification framework offers coverage collection and report generation functions, enabling users to conveniently collect coverage data and generate coverage reports. Logging：The MLVP verification framework provides logging functionality, allowing users to easily record information during the verification process. Interfaces ：The MLVP verification framework allows for the creation of interfaces, enabling users to define a set of interfaces for specific functions. This also decouples the software module implementation from the specific DUT implementation. Verification Utility Modules： The MLVP verification framework provides several verification utility modules to facilitate writing software modules. Currently included are modules like the “Two-bit Saturation Counter” and the “Pseudo LRU Algorithm”. For detailed instructions on using the MLVP verification framework, please refer to MLVP。\n","categories":["Example Projects","Tutorials"],"description":"MLVP Verification Framework.","excerpt":"MLVP Verification Framework.","ref":"/mlvp/en/docs/advance_func/mlvp/","tags":["examples","docs"],"title":"Verification Framework"},{"body":" 在芯片验证的传统实践中，UVM等框架被广泛采用。尽管它们提供了一整套验证方法，但通常只适用于特定的硬件描述语言和仿真环境。本工具突破了这些限制，能够将仿真代码转换成C++或Python，使得我们可以利用软件验证工具来进行更全面的测试。\n因为Python具有强大的生态系统，所以本项目主要以Python作为示例，简单介绍Pytest和Hypothesis两个经典软件测试框架。Pytest以其简洁的语法和丰富的功能，轻松应对各种测试需求。而Hypothesis则通过生成测试用例，揭示出意料之外的边缘情况，提高了测试的全面性和深度。\n我们的项目从一开始就设计为与多种现代软件测试框架兼容。我们鼓励您探索这些工具的潜力，并将其应用于您的测试流程中。通过亲身实践，您将更深刻地理解这些工具如何提升代码的质量和可靠性。让我们一起努力，提高芯片开发的质量。\n","categories":["示例项目","教程"],"description":"可用软件测试框架","excerpt":"可用软件测试框架","ref":"/mlvp/docs/env_usage/frameworks/","tags":["examples","docs"],"title":"集成测试框架"},{"body":"通过 Picker 工具生成的 Python DUT，已经可以使我们在 Python 环境中进行简单的验证，包括对 DUT 的实例化、信号赋值、时钟驱动等操作。但是在实际的验证工作中，我们通常需要更为高级的验证特性，例如协程支持、覆盖率收集与报告生成等功能。为此，我们提供了 MLVP(Multi-language Verification Platform) 验证框架，用于提供这些高级验证特性。\n目前，MLVP 验证框架支持的功能包括：\n协程支持：MLVP 验证框架提供了协程支持，使用户可以方便地编写异步验证代码。 覆盖率收集与报告生成：MLVP 验证框架提供了覆盖率收集与报告生成功能，使用户可以方便地收集覆盖率数据，并生成覆盖率报告。 日志记录：MLVP 验证框架提供了日志记录功能，使用户可以方便地记录验证过程中的信息。 接口 ：MLVP 验证框架提供了接口的创建，方便用户定义一组用于完成某个特定功能的接口集合，同时也使得软件模块的编写与 DUT 的具体实现解耦。 验证实用模块： MLVP 验证框架提供了一些验证实用模块，方便用户编写软件模块，目前包含 “两比特饱和计数器”， “伪 LRU 算法” 等。 有关 MLVP 验证框架的详细使用方法，请参见 MLVP。\n","categories":["示例项目","教程"],"description":"MLVP 验证框架。","excerpt":"MLVP 验证框架。","ref":"/mlvp/docs/advance_func/mlvp/","tags":["examples","docs"],"title":"验证框架"},{"body":" After we complete the DUT verification, writing a verification report is a crucial step. This section will provide an overview of the structure of the verification report and the content that needs to be covered.\nThe verification report is a review of the entire verification process and an important supporting document for determining the reasonableness of the verification. Generally, the verification report should include the following content:\nBasic document information (author, log, version, etc.) Verification object (verification target) Introduction to functional points Verification plan Breakdown of test points Test cases Test environment Result analysis Defect analysis Verification conclusion The following content provides further explanation of the list, with specific examples available innutshell_cache_report_demo.pdf\n1. Basic Information Including author, log, version, date, etc.\n2. Verification object (verification target) A necessary introduction to your verification object, which may include its structure, basic functions, interface information, etc.\n3. Introduction to functional points By reading the design documents or source code, you need to summarize the target functions of the DUT and break them down into various functional points.\n4. Verification plan Including your planned verification process and verification framework. Additionally, you should explain how each part of your framework works together.\n5. Breakdown of test points Proposed testing methods for the functional points. Specifically, it can include what signal output should be observed under certain signal inputs.\n6. Test cases The specific implementation of the test points. A test case can include multiple test points.\n7. Test environment Including hardware information, software version information, etc.\n8. Result analysis Result analysis generally refers to coverage analysis. Typically, two types of coverage should be considered: 1. Line Coverage： How many RTL lines of code are executed in the test cases. Generally, we require line coverage to be above 98%.\n2. Functional Coverage：Determine whether the extracted functional points are covered and correctly triggered based on the relevant signals. We generally require test cases to cover each functional point.\n9. Defect analysis Analyze the defects present in the DUT. This can include the specification and detail of the design documents, the correctness of the DUT functions (whether there are bugs), and whether the DUT functions can be triggered.\n10. Verification conclusion The final conclusion drawn after completing the chip verification process, summarizing the above content.\n","categories":["Example Projects","Learning Materials"],"description":"An overview of the structure and content of the verification report.","excerpt":"An overview of the structure and content of the verification report.","ref":"/mlvp/en/docs/basic/report/","tags":["examples","docs"],"title":"Verification Report"},{"body":" 在我们完成DUT验证后，编写验证报告是至关重要的一环。本节将从整体角度概述验证报告的结构以及报告所需覆盖的内容。\n验证报告是对整个验证过程的回顾，是验证合理与否的重要支持文件。一般情况下，验证报告需要包含以下内容：\n文档基本信息（作者、日志、版本等） 验证对象（验证目标） 功能点介绍 验证方案 测试点分解 测试用例 测试环境 结果分析 缺陷分析 测试结论 以下内容对列表进行进一步解释，具体示例可以参考nutshell_cache_report_demo.pdf\n1. 基本信息 应当包括作者、日志、版本、日期等。\n2. 验证对象（验证目标） 需要对您的验证对象做必要的介绍，可以包括其结构、基本功能、接口信息等。\n3. 功能点介绍 通过阅读设计文档或者源码，您需要总结DUT的目标功能，并将其细化为各功能点。\n4. 验证方案 应当包括您计划的验证流程以及验证框架。同时，您也应当接受您的框架各部分是如何协同工作的。\n5. 测试点分解 针对功能点提出的测试方法。具体可以包括在怎样的信号输入下应当观测到怎样的信号输出。\n6. 测试用例 测试点的具体实现。一个测试用例可以包括多个测试点。\n7. 测试环境 包括硬件信息、软件版本信息等。\n8. 结果分析 结果分析一般指覆盖率分析。通常来说应当考虑两类覆盖率：\n1. 行覆盖率： 在测试用例中有多少RTL行代码被执行。一般来说我们要求行覆盖率在98%以上。\n2. 功能覆盖率：根据相应的信号判断您提取的功能点是否被覆盖且被正确触发。一般我们要求测试用例覆盖每个功能点。\n9. 缺陷分析 对DUT存在的缺陷进行分析。可以包括设计文档的规范性和详细性、DUT功能的正确性（是否存在bug）、DUT功能是否能被触发等方面。\n10. 验证结论 验证结论是在完成芯片验证过程后得出的最终结论，是对以上内容的总结。\n","categories":["示例项目","学习材料"],"description":"概述验证报告的结构与内容。","excerpt":"概述验证报告的结构与内容。","ref":"/mlvp/docs/basic/report/","tags":["examples","docs"],"title":"验证报告"},{"body":"","categories":["Sample Projects","Tutorials"],"description":"The Open Verification Platform supports multiple languages.","excerpt":"The Open Verification Platform supports multiple languages.","ref":"/mlvp/en/docs/multi-lang/","tags":["examples","docs"],"title":"Multi-language Support"},{"body":"","categories":["示例项目","教程"],"description":"开放验证平台支持多种语言","excerpt":"开放验证平台支持多种语言","ref":"/mlvp/docs/multi-lang/","tags":["examples","docs"],"title":"多语言支持"},{"body":" This learning resource introduces the basic concepts and techniques related to verification, as well as how to use the open-source tools provided by this project for chip verification.\nBefore studying this material, it is assumed that you already have basic knowledge of Linux, Python, etc.\nRelevant learning materials:\n《Linux 101》Online Lecture Notes Python Official Python Tutorial Official Python Tutorial If you plan to participate in the “Open Source Verification Projects” published on this platform, it is recommended to complete the study of this material in advance.\n","categories":"","description":"","excerpt":" This learning resource introduces the basic concepts and techniques …","ref":"/mlvp/en/docs/","tags":"","title":"Learning Resources"},{"body":" 本学习资源介绍验证相关的基本概念、技术，以及如何使用本项目提供的开源工具进行芯片验证\n学习本材料前，假定您已经拥有linux、python等相关基础知识。\n相关学习材料：\n《Linux 101》在线讲义 Python官方教程 Javatpoint上的Git基础 若计划参与本平台上发布的“开源开放验证项目”，建议提前完本材料的学习。\n","categories":"","description":"","excerpt":" 本学习资源介绍验证相关的基本概念、技术，以及如何使用本项目提供的开源工具进行芯片验证\n学习本材料前，假定您已经拥有linux、python …","ref":"/mlvp/docs/","tags":"","title":"学习资源"},{"body":"Software Testing Before we start with pytest, let’s understand software testing. Software testing generally involves the following four aspects:\nUnit Testing: Also known as module testing, it involves checking the correctness of program modules, which are the smallest units in software design. Integration Testing: Also known as assembly testing, it usually builds on unit testing by sequentially and incrementally testing all program modules, focusing on the interface parts of different modules. System Testing: It treats the entire software system as a whole for testing, including testing the functionality, performance, and the software’s running environment. Acceptance Testing: Refers to testing the entire system according to the project task book, contract, and acceptance criteria agreed upon by both the supply and demand sides, to determine whether to accept or reject the system. pytest was initially designed as a unit testing framework, but it also provides many features that allow it to be used for a wider range of testing, including integration testing and system testing. It is a very mature full-featured Python testing framework. It simplifies test writing and execution by collecting test functions and modules and providing a rich assertion library. It is a very mature and powerful Python testing framework with the following key features:\nSimple and Flexible: Pytest is easy to get started with and is flexible. Supports Parameterization: You can easily provide different parameters for test cases. Full-featured: Pytest not only supports simple unit testing but can also handle complex functional testing. You can even use it for automation testing, such as Selenium or Appium testing, as well as interface automation testing (combining Pytest with the Requests library). Rich Plugin Ecosystem: Pytest has many third-party plugins, and you can also customize extensions. Some commonly used plugins include: pytest-selenium: Integrates Selenium. pytest-html: Generates HTML test reports. pytest-rerunfailures: Repeats test cases in case of failure. pytest-xdist: Supports multi-CPU distribution. Well Integrated with Jenkins. Supports Allure Report Framework. This article will briefly introduce the usage of pytest based on testing requirements. The complete manual is available here for students to study in depth.\nInstalling Pytest # Install pytest: pip install pytest # Upgrade pytest pip install -U pytest # Check pytest version pytest --version # Check installed package list pip list # Check pytest help documentation pytest -h # Install third-party plugins pip install pytest-sugar pip install pytest-rerunfailures pip install pytest-xdist pip install pytest-assume pip install pytest-html Using Pytest Naming Convention # When using pytest, our module names are usually prefixed with test or end with test. You can also modify the configuration file to customize the naming convention. # test_*.py or *_test.py test_demo1 demo2_test # The class name in the module must start with Test and cannot have an init method. class TestDemo1: class TestLogin: # The test methods defined in the class must start with test_ test_demo1(self) test_demo2(self) # Test Case class test_one: def test_demo1(self): print(\"Test Case 1\") def test_demo2(self): print(\"Test Case 2\") Pytest Parameters pytest supports many parameters, which can be viewed using the help command.\npytest -help Here are some commonly used ones:\n-m: Specify multiple tag names with an expression. pytest provides a decorator @pytest.mark.xxx for marking tests and grouping them (xxx is the group name you defined), so you can quickly select and run them, with different groups separated by and or or.\n-v: Outputs more detailed information during runtime. Without -v, the runtime does not display the specific test case names being run; with -v, it prints out the specific test cases in the console.\n-q: Similar to the verbosity in unittest, used to simplify the runtime output. When running tests with -q, only simple runtime information is displayed, for example:\n.s.. [100%] 3 passed, 1 skipped in 9.60s -k: You can run specified test cases using an expression. It is a fuzzy match, with and or or separating keywords, and the matching range includes file names, class names, and function names.\n-x: Exit the test if one test case fails. This is very useful for debugging. When a test fails, stop running the subsequent tests.\n-s: Display print content. When running test scripts, we often add some print content for debugging or printing some content. However, when running pytest, this content is not displayed. If you add -s, it will be displayed.\npytest test_se.py -s Selecting Test Cases to Execute with Pytest In Pytest, you can select and execute test cases based on different dimensions such as test folders, test files, test classes, and test methods.\nExecute by test folder # Execute all test cases in the current folder and subfolders pytest . # Execute all test cases in the tests folder and its subfolders, which are at the same level as the current folder pytest ../tests # Execute by test file # Run all test cases in test_se.py pytest test_se.py # Execute by test class, must be in the following format: pytest file_name.py::TestClass, where \"::\" is the separator used to separate the test module and test class. # Run all test cases under the class named TestSE in the test_se.py file pytest test_se.py::TestSE # Execute by test method, must be in the following format: pytest file_name.py::TestClass::TestMethod, where \"::\" is the separator used to separate the test module, test class, and test method. # Run the test case named test_get_new_message under the class named TestSE in the test_se.py file pytest test_se.py::TestSE::test_get_new_message # The above methods of selecting test cases are all on the **command line**. If you want to execute directly in the test program, you can directly call pytest.main(), the format is: pytest.main([module.py::class::method]) In addition, Pytest also supports multiple ways to control the execution of test cases, such as filtering execution, running in multiple processes, retrying execution, etc.\nWriting Validation with Pytest During testing, we use the previously validated adder. Go to the Adder folder, create a new test_adder.py file in the picker_out_adder directory, with the following content: # Import test modules and required libraries from UT_Adder import * import pytest import ctypes import random # Use pytest fixture to initialize and clean up resources @pytest.fixture def adder(): # Create an instance of DUTAdder, load the dynamic link library dut = DUTAdder() # Execute one clock step to prepare the DUT dut.Step(1) # The code after the yield statement will be executed after the test ends, used to clean up resources yield dut # Clean up DUT resources and generate test coverage reports and waveforms dut.finalize() class TestFullAdder: # Define full_adder as a static method, as it does not depend on class instances @staticmethod def full_adder(a, b, cin): cin = cin \u0026 0b1 Sum = ctypes.c_uint64(a).value Sum += ctypes.c_uint64(b).value + cin Cout = (Sum \u003e\u003e 64) \u0026 0b1 Sum \u0026= 0xffffffffffffffff return Sum, Cout # Use the pytest.mark.usefixtures decorator to specify the fixture to use @pytest.mark.usefixtures(\"adder\") # Define the test method, where adder is injected by pytest through the fixture def test_adder(self, adder): # Perform multiple random tests for _ in range(114514): # Generate random 64-bit a, b, and 1-bit cin a = random.getrandbits(64) b = random.getrandbits(64) cin = random.getrandbits(1) # Set the input of the DUT adder.a.value = a adder.b.value = b adder.cin.value = cin # Execute one clock step adder.Step(1) # Calculate the expected result using a static method sum, cout = self.full_adder(a, b, cin) # Assert that the output of the DUT is the same as the expected result assert sum == adder.sum.value assert cout == adder.cout.value if __name__ == \"__main__\": pytest.main(['-v', 'test_adder.py::TestFullAdder']) After running the test, the output is as follows: collected 1 item test_adder.py ✓ 100% ██████████ Results (4.33s): The successful test indicates that after 114514 loops, our device has not found any bugs for now. However, using randomly generated test cases with multiple loops consumes a considerable amount of resources, and these randomly generated test cases may not effectively cover all boundary conditions. In the next section, we will introduce a more efficient method for generating test cases.\n","categories":["Sample Projects","Tutorials"],"description":"Used for managing tests and generating test reports.","excerpt":"Used for managing tests and generating test reports.","ref":"/mlvp/en/docs/env_usage/frameworks/pytest/","tags":["examples","docs"],"title":"PyTest"},{"body":"软件测试 在正式开始pytest 之间我们先了解一下软件的测试，软件测试一般分为如下四个方面\n单元测试：称模块测试，针对软件设计中的最小单位——程序模块，进行正确性检查的测试工作 集成测试：称组装测试，通常在单元测试的基础上，将所有程序模块进行有序的、递增测试，重点测试不同模块的接口部分 系统测试：将整个软件系统看成一个整体进行测试，包括对功能、性能以及软件所运行的软硬件环境进行测试 验收测试：指按照项目任务书或合同、供需双方约定的验收依据文档进行的对整个系统的测试与评审，决定是否接收或拒收系统 pytest最初是作为一个单元测试框架而设计的，但它也提供了许多功能，使其能够进行更广泛的测试，包括集成测试，系统测试，他是一个非常成熟的全功能的python 测试框架。 它通过收集测试函数和模块，并提供丰富的断言库来简化测试的编写和运行，是一个非常成熟且功能强大的 Python 测试框架，具有以下几个特点：\n简单灵活：Pytest 容易上手，且具有灵活性。 支持参数化：您可以轻松地为测试用例提供不同的参数。 全功能：Pytest 不仅支持简单的单元测试，还可以处理复杂的功能测试。您甚至可以使用它来进行自动化测试，如 Selenium 或 Appium 测试，以及接口自动化测试（结合 Pytest 和 Requests 库）。 丰富的插件生态：Pytest 有许多第三方插件，您还可以自定义扩展。一些常用的插件包括： pytest-selenium：集成 Selenium。 pytest-html：生成HTML测试报告。 pytest-rerunfailures：在失败的情况下重复执行测试用例。 pytest-xdist：支持多 CPU 分发。 与 Jenkins 集成良好。 支持 Allure 报告框架。 本文将基于测试需求简单介绍pytest的用法，其完整手册在这里，供同学们进行深入学习。\nPytest安装 # 安装pytest： pip install pytest # 升级pytest pip install -U pytest # 查看pytest版本 pytest --version # 查看已安装包列表 pip list # 查看pytest帮助文档 pytest -h # 安装第三方插件 pip install pytest-sugar pip install pytest-rerunfailures pip install pytest-xdist pip install pytest-assume pip install pytest-html Pytest使用 命名规则 # 首先在使用pytest 时我们的模块名通常是以test开头或者test结尾，也可以修改配置文件，自定义命名规则 # test_*.py 或 *_test.py test_demo1 demo2_test # 模块中的类名要以Test 开始且不能有init 方法 class TestDemo1: class TestLogin: # 类中定义的测试方法名要以test_开头 test_demo1(self) test_demo2(self) # 测试用例 class test_one: def test_demo1(self): print(\"测试用例1\") def test_demo2(self): print(\"测试用例2\") Pytest 参数 pytest支持很多参数，可以通过help命令查看\npytest -help 我们在这里列出来常用的几个：\n-m: 用表达式指定多个标记名。 pytest 提供了一个装饰器 @pytest.mark.xxx，用于标记测试并分组（xxx是你定义的分组名），以便你快速选中并运行，各个分组直接用 and、or 来分割。\n-v: 运行时输出更详细的用例执行信息 不使用-v参数，运行时不会显示运行的具体测试用例名称；使用-v参数，会在 console 里打印出具体哪条测试用例被运行。\n-q: 类似 unittest 里的 verbosity，用来简化运行输出信息。 使用 -q 运行测试用例，仅仅显示很简单的运行信息， 例如：\n.s.. [100%] 3 passed, 1 skipped in 9.60s -k: 可以通过表达式运行指定的测试用例。 它是一种模糊匹配，用 and 或 or 区分各个关键字，匹配范围有文件名、类名、函数名。\n-x: 出现一条测试用例失败就退出测试。 在调试时，这个功能非常有用。当出现测试失败时，停止运行后续的测试。\n-s: 显示print内容 在运行测试脚本时，为了调试或打印一些内容，我们会在代码中加一些print内容，但是在运行pytest时，这些内容不会显示出来。如果带上-s，就可以显示了。\npytest test_se.py -s Pytest 选择测试用例执行 在 Pytest 中，您可以按照测试文件夹、测试文件、测试类和测试方法的不同维度来选择执行测试用例。\n按照测试文件夹执行 # 执行所有当前文件夹及子文件夹下的所有测试用例 pytest . # 执行跟当前文件夹同级的tests文件夹及子文件夹下的所有测试用例 pytest ../tests # 按照测试文件执行 # 运行test_se.py下的所有的测试用例 pytest test_se.py # 按照测试类执行，必须以如下格式： pytest 文件名 .py:: 测试类，其中“::”是分隔符，用于分割测试module和测试类。 # 运行test_se.py文件下的，类名是TestSE下的所有测试用例 pytest test_se.py::TestSE # 测试方法执行，必须以如下格式： pytest 文件名 .py:: 测试类 :: 测试方法，其中 “::” 是分隔符，用于分割测试module、测试类，以及测试方法。 # 运行test_se.py文件下的，类名是TestSE下的，名字为test_get_new_message的测试用例 pytest test_se.py::TestSE::test_get_new_message # 以上选择测试用例的方法均是在**命令行**，如果您想直接在测试程序里执行可以直接在main函数中**调用pytest.main()**,其格式为： pytest.main([模块.py::类::方法]) 此外，Pytest 还支持控制测试用例执行的多种方式，例如过滤执行、多进程运行、重试运行等。\n使用Pytest编写验证 在测试过程中，我们使用之前验证过的加法器，进入Adder文件夹，在picker_out_adder目录下新建一个test_adder.py文件，内容如下： # 导入测试模块和所需的库 from UT_Adder import * import pytest import ctypes import random # 使用 pytest fixture 来初始化和清理资源 @pytest.fixture def adder(): # 创建 DUTAdder 实例，加载动态链接库 dut = DUTAdder() # 执行一次时钟步进，准备 DUT dut.Step(1) # yield 语句之后的代码会在测试结束后执行，用于清理资源 yield dut # 清理DUT资源，并生成测试覆盖率报告和波形 dut.finalize() class TestFullAdder: # 将 full_adder 定义为静态方法，因为它不依赖于类实例 @staticmethod def full_adder(a, b, cin): cin = cin \u0026 0b1 Sum = ctypes.c_uint64(a).value Sum += ctypes.c_uint64(b).value + cin Cout = (Sum \u003e\u003e 64) \u0026 0b1 Sum \u0026= 0xffffffffffffffff return Sum, Cout # 使用 pytest.mark.usefixtures 装饰器指定使用的 fixture @pytest.mark.usefixtures(\"adder\") # 定义测试方法，adder 参数由 pytest 通过 fixture 注入 def test_adder(self, adder): # 进行多次随机测试 for _ in range(114514): # 随机生成 64 位的 a 和 b，以及 1 位的进位 cin a = random.getrandbits(64) b = random.getrandbits(64) cin = random.getrandbits(1) # 设置 DUT 的输入 adder.a.value = a adder.b.value = b adder.cin.value = cin # 执行一次时钟步进 adder.Step(1) # 使用静态方法计算预期结果 sum, cout = self.full_adder(a, b, cin) # 断言 DUT 的输出与预期结果相同 assert sum == adder.sum.value assert cout == adder.cout.value if __name__ == \"__main__\": pytest.main(['-v', 'test_adder.py::TestFullAdder']) 运行测试之后输出如下： collected 1 item test_adder.py ✓ 100% ██████████ Results (4.33s): 测试成功表明，在经过114514次循环之后，我们的设备暂时没有发现bug。然而，使用多次循环的随机数生成测试用例会消耗大量资源，并且这些随机生成的测试用例可能无法有效覆盖所有边界条件。在下一部分，我们将介绍一种更有效的测试用例生成方法。\n","categories":["示例项目","教程"],"description":"可用来管理测试，生成测试报告","excerpt":"可用来管理测试，生成测试报告","ref":"/mlvp/docs/env_usage/frameworks/pytest/","tags":["examples","docs"],"title":"PyTest"},{"body":"Hypothesis In the previous section, we manually wrote test cases and specified inputs and expected outputs for each case. This method has some issues, such as incomplete test case coverage and the tendency to overlook boundary conditions. Hypothesis is a Python library for property-based testing. Its main goal is to make testing simpler, faster, and more reliable. It uses a method called property-based testing, where you can write some hypotheses for your code, and Hypothesis will automatically generate test cases to verify these hypotheses. This makes it easier to write comprehensive and efficient tests. Hypothesis can automatically generate various types of input data, including basic types (e.g., integers, floats, strings), container types (e.g., lists, sets, dictionaries), and custom types. It tests based on the properties (assertions) you provide. If a test fails, it will try to narrow down the input data to find the smallest failing case. With Hypothesis, you can better cover the boundary conditions of your code and uncover errors you might not have considered. This helps improve the quality and reliability of your code.\nBasic Concepts Test Function: The function or method to be tested. Properties: Conditions that the test function should satisfy. Properties are applied to the test function as decorators. Strategy: A generator for test data. Hypothesis provides a range of built-in strategies, such as integers, strings, lists, etc. You can also define custom strategies. Test Generator: A function that generates test data based on strategies. Hypothesis automatically generates test data and passes it as parameters to the test function. This article will briefly introduce Hypothesis based on testing requirements. The complete manual is available for in-depth study.\nInstallation Install with pip and import in Python to use:\npip install hypothesis import hypothesis Basic Usage Properties and Strategies Hypothesis uses property decorators to define the properties of test functions. The most common decorator is @given, which specifies the properties the test function should satisfy. We can define a test function test_addition using the @given decorator and add properties to x. The test generator will automatically generate test data for the function and pass it as parameters, for example:\ndef addition(number: int) -\u003e int: return number + 1 @given(x=integers(), y=integers())　def test_addition(x, y):　assert x + 1 == addition（1） In this example, integers() is a built-in strategy for generating integer test data. Hypothesis offers a variety of built-in strategies for generating different types of test data. Besides integers(), there are strategies for strings, booleans, lists, dictionaries, etc. For instance, using the text() strategy to generate string test data and using lists(text()) to generate lists of strings:\n@given(s=text(), l=lists(text())) def test_string_concatenation(s, l):　result = s + \"\".join(l)　assert len(result) == len(s) + sum(len(x) for x in l) You can also define custom strategies to generate specific types of test data, for example, a strategy for non-negative integers:\ndef non_negative_integers(): return integers(min_value=0) @given(x=non_negative_integers()) def test_positive_addition(x): assert x + 1 \u003e x Expectations We can use expect to specify the expected result of a function:\n@given(x=integers()) def test_addition(x): expected = x + 1 actual = addition(x) Hypotheses and Assertions When using Hypothesis for testing, we can use standard Python assertions to verify the properties of the test function. Hypothesis will automatically generate test data and run the test function based on the properties defined in the decorator. If an assertion fails, Hypothesis will try to narrow down the test data to find the smallest failing case.\nSuppose we have a string reversal function. We can use an assert statement to check if reversing a string twice equals itself:\ndef test_reverse_string(s): expected = x + 1 actual = addition(x) assert actual == expected Writing Tests Tests in Hypothesis consist of two parts: a function that looks like a regular test in your chosen framework but with some extra parameters, and a @given decorator specifying how to provide those parameters. Here’s an example of how to use it to verify a full adder, which we tested previously:\nBased on the previous section’s code, we modify the method of generating test cases from random numbers to the integers() method. The modified code is as follows:\nfrom UT_Adder import * import pytest import ctypes import random from hypothesis import given, strategies as st # Initializing and Cleaning Up Resources Using pytest Fixture from UT_Adder import * import pytest import ctypes from hypothesis import given, strategies as st # Using pytest fixture to initialize and clean up resources @pytest.fixture(scope=\"class\") def adder(): # Create DUTAdder instance and load dynamic library dut = DUTAdder() # Perform a clock step to prepare the DUT dut.Step(1) # Code after yield executes after tests finish, for cleanup yield dut # Clean up DUT resources and generate coverage report and waveform dut.finalize() class TestFullAdder: # Define full_adder as a static method, as it doesn't depend on class instance @staticmethod def full_adder(a, b, cin): cin = cin \u0026 0b1 Sum = ctypes.c_uint64(a).value Sum += ctypes.c_uint64(b).value + cin Cout = (Sum \u003e\u003e 64) \u0026 0b1 Sum \u0026= 0xffffffffffffffff return Sum, Cout # Use Hypothesis to automatically generate test cases @given( a=st.integers(min_value=0, max_value=0xffffffffffffffff), b=st.integers(min_value=0, max_value=0xffffffffffffffff), cin=st.integers(min_value=0, max_value=1) ) # Define test method, adder parameter injected by pytest via fixture def test_full_adder_with_hypothesis(self, adder, a, b, cin): # Calculate expected sum and carry sum_expected, cout_expected = self.full_adder(a, b, cin) # Set DUT inputs adder.a.value = a adder.b.value = b adder.cin.value = cin # Perform a clock step adder.Step(1) # Assert DUT outputs match expected results assert sum_expected == adder.sum.value assert cout_expected == adder.cout.value if __name__ == \"__main__\": # Run specified tests in verbose mode pytest.main(['-v', 'test_adder.py::TestFullAdder']) In this example, the @given decorator and strategies are used to generate random data that meets specified conditions. st.integers() is a strategy for generating integers within a specified range, used to generate numbers between 0 and 0xffffffffffffffff for a and b, and between 0 and 1 for cin. Hypothesis will automatically rerun this test multiple times, each time using different random inputs, helping reveal potential boundary conditions or edge cases.\nRun the tests, and the output will be as follows: collected 1 item test_adder.py ✓ 100% ██████████ Results (0.42s): 1 passed As we can see, the tests were completed in a short amount of time.\n","categories":["Sample Projects","Tutorials"],"description":"Can Be Used to Generate Stimuli","excerpt":"Can Be Used to Generate Stimuli","ref":"/mlvp/en/docs/env_usage/frameworks/hypothesis/","tags":["examples","docs"],"title":"Hypothesis"},{"body":"Hypothesis 在上一节中，我们通过手动编写测试用例，并为每个用例指定输入和预期输出。这种方式存在一些问题，例如测试用例覆盖不全面、边界条件 容易被忽略等。它是一个用于属性基于断言的软件测试的 Python 库。Hypothesis 的主要目标是使测试更简单、更快速、更可靠。它使用了一种称为属性基于断言的测试方法，即你可以为你的代码编写一些假（hypotheses），然后 Hypothesis 将会自动生成测试用例并验证这些假设。这使得编写全面且高效的测试变得更加容易。Hypothesis 可以自动生成各种类型的输入数据，包括基本类型（例如整数、浮点数、字符串等）、容器类型（例如列表、集合、字典等）、自定义类型等。然后，它会根据你提供的属性（即断言）进行测试，如果发现测试失败，它将尝试缩小输入数据的范围以找出最小的失败案例。通过 Hypothesis，你可以更好地覆盖代码的边界条件，并发现那些你可能没有考虑到的错误情况。这有助于提高代码的质量和可靠性。\n基本概念 测试函数：即待测试的函数或方法，我们需要对其进行测试。 属性：定义了测试函数应该满足的条件。属性是以装饰器的形式应用于测试函数上的。 策略：用于生成测试数据的生成器。Hypothesis 提供了一系列内置的策略，如整数、字符串、列表等。我们也可以自定义策略。 测试生成器：基于策略生成测试数据的函数。Hypothesis 会自动为我们生成测试数据，并将其作为参数传递给测试函数。 本文将基于测试需求简单介绍Hypothesis的用法，其完整手册在这里，供同学们进行深入学习。\n安装 使用pip安装，在python中导入即可使用\npip install hypothesis import hypothesis 基本用法 属性和策略 Hypothesis 使用属性装饰器来定义测试函数的属性。最常用的装饰器是 @given，它指定了测试函数应该满足的属性。 我们可以通过@given 装饰器定义了一个测试函数 test_addition。并给x 添加对应的属性，测试生成器会自动为测试函数生成测试数据，并将其作为参数传递给函数，例如\ndef addition(number: int) -\u003e int: return number + 1 @given(x=integers(), y=integers())　def test_addition(x, y):　assert x + 1 == addition（1） 其中integers () 是一个内置的策略，用于生成整数类型的测试数据。Hypothesis 提供了丰富的内置策略，用于生成各种类型的测试数据。除了integers ()之外，还有字符串、布尔值、列表、字典等策略。例如使用 text () 策略生成字符串类型的测试数据，使用 lists (text ()) 策略生成字符串列表类型的测试数据\n@given(s=text(), l=lists(text())) def test_string_concatenation(s, l):　result = s + \"\".join(l)　assert len(result) == len(s) + sum(len(x) for x in l) 除了可以使用内置的策略以外，还可以使用自定义策略来生成特定类型的测试数据，例如我们可以生产一个非负整形的策略\ndef non_negative_integers(): return integers(min_value=0) @given(x=non_negative_integers()) def test_positive_addition(x): assert x + 1 \u003e x 期望 我们可以通过expect 来指明需要的函数期待得到的结果\n@given(x=integers()) def test_addition(x): expected = x + 1 actual = addition(x) 假设和断言 在使用 Hypothesis 进行测试时，我们可以使用标准的 Python 断言来验证测试函数的属性。Hypothesis 会自动为我们生成测试数据，并根据属性装饰器中定义的属性来运行测试函数。如果断言失败，Hypothesis 会尝试缩小测试数据的范围，以找出导致失败的最小样例。\n假如我们有一个字符串反转函数，我们可以通过assert 来判断翻转两次后他是不是等于自身\ndef test_reverse_string(s): expected = x + 1 actual = addition(x) assert actual == expected 编写测试 Hypothesis 中的测试由两部分组成：一个看起来像您选择的测试框架中的常规测试但带有一些附加参数的函数，以及一个@given指定如何提供这些参数的装饰器。以下是如何使用它来验证我们之前验证过的全加器的示例：\n在上一节的代码基础上，我们进行一些修改，将生成测试用例的方法从随机数修改为integers ()方法，修改后的代码如下：\nfrom UT_Adder import * import pytest import ctypes import random from hypothesis import given, strategies as st # 使用 pytest fixture 来初始化和清理资源 from UT_Adder import * import pytest import ctypes from hypothesis import given, strategies as st # 使用 pytest fixture 来初始化和清理资源 @pytest.fixture(scope=\"class\") def adder(): # 创建 DUTAdder 实例，加载动态链接库 dut = DUTAdder() # 执行一次时钟步进，准备 DUT dut.Step(1) # yield 语句之后的代码会在测试结束后执行，用于清理资源 yield dut # 清理DUT资源，并生成测试覆盖率报告和波形 dut.finalize() class TestFullAdder: # 将 full_adder 定义为静态方法，因为它不依赖于类实例 @staticmethod def full_adder(a, b, cin): cin = cin \u0026 0b1 Sum = ctypes.c_uint64(a).value Sum += ctypes.c_uint64(b).value + cin Cout = (Sum \u003e\u003e 64) \u0026 0b1 Sum \u0026= 0xffffffffffffffff return Sum, Cout # 使用 hypothesis 自动生成测试用例 @given( a=st.integers(min_value=0, max_value=0xffffffffffffffff), b=st.integers(min_value=0, max_value=0xffffffffffffffff), cin=st.integers(min_value=0, max_value=1) ) # 定义测试方法，adder 参数由 pytest 通过 fixture 注入 def test_full_adder_with_hypothesis(self, adder, a, b, cin): # 计算预期的和与进位 sum_expected, cout_expected = self.full_adder(a, b, cin) # 设置 DUT 的输入 adder.a.value = a adder.b.value = b adder.cin.value = cin # 执行一次时钟步进 adder.Step(1) # 断言 DUT 的输出与预期结果相同 assert sum_expected == adder.sum.value assert cout_expected == adder.cout.value if __name__ == \"__main__\": # 以详细模式运行指定的测试 pytest.main(['-v', 'test_adder.py::TestFullAdder']) 这个例子中，@given 装饰器和 strategies 用于生成符合条件的随机数据。st.integers() 是生成指定范围整数的策略，用于为 a 和 b 生成 0 到 0xffffffffffffffff 之间的数，以及为 cin 生成 0 或 1。Hypothesis会自动重复运行这个测试，每次都使用不同的随机输入，这有助于揭示潜在的边界条件或异常情况。\n运行测试，输出结果如下： collected 1 item test_adder.py ✓ 100% ██████████ Results (0.42s): 1 passed 可以看到在很短的时间里我们已经完成了测试\n","categories":["示例项目","教程"],"description":"可用来生成激励","excerpt":"可用来生成激励","ref":"/mlvp/docs/env_usage/frameworks/hypothesis/","tags":["examples","docs"],"title":"Hypothesis"},{"body":"","categories":"","description":"","excerpt":"","ref":"/mlvp/en/categories/","tags":"","title":"Categories"},{"body":"","categories":"","description":"","excerpt":"","ref":"/mlvp/categories/","tags":"","title":"Categories"},{"body":"","categories":"","description":"","excerpt":"","ref":"/mlvp/en/tags/docs/","tags":"","title":"Docs"},{"body":"","categories":"","description":"","excerpt":"","ref":"/mlvp/tags/docs/","tags":"","title":"Docs"},{"body":"","categories":"","description":"","excerpt":"","ref":"/mlvp/en/categories/example-projects/","tags":"","title":"Example Projects"},{"body":"","categories":"","description":"","excerpt":"","ref":"/mlvp/en/tags/examples/","tags":"","title":"Examples"},{"body":"","categories":"","description":"","excerpt":"","ref":"/mlvp/tags/examples/","tags":"","title":"Examples"},{"body":"","categories":"","description":"","excerpt":"","ref":"/mlvp/en/tags/","tags":"","title":"Tags"},{"body":"","categories":"","description":"","excerpt":"","ref":"/mlvp/tags/","tags":"","title":"Tags"},{"body":"","categories":"","description":"","excerpt":"","ref":"/mlvp/en/categories/tutorials/","tags":"","title":"Tutorials"},{"body":"","categories":"","description":"","excerpt":"","ref":"/mlvp/categories/%E6%95%99%E7%A8%8B/","tags":"","title":"教程"},{"body":"","categories":"","description":"","excerpt":"","ref":"/mlvp/categories/%E7%A4%BA%E4%BE%8B%E9%A1%B9%E7%9B%AE/","tags":"","title":"示例项目"},{"body":" ","categories":"","description":"","excerpt":" ","ref":"/mlvp/en/","tags":"","title":"Goldydocs"},{"body":" ","categories":"","description":"","excerpt":" ","ref":"/mlvp/","tags":"","title":"Goldydocs"},{"body":"","categories":"","description":"","excerpt":"","ref":"/mlvp/en/categories/learning-materials/","tags":"","title":"Learning Materials"},{"body":"","categories":"","description":"","excerpt":"","ref":"/mlvp/en/categories/sample-projects/","tags":"","title":"Sample Projects"},{"body":"","categories":"","description":"","excerpt":"","ref":"/mlvp/en/search/","tags":"","title":"Search Results"},{"body":"","categories":"","description":"","excerpt":"","ref":"/mlvp/en/categories/tutorial/","tags":"","title":"Tutorial"},{"body":"","categories":"","description":"","excerpt":"","ref":"/mlvp/search/","tags":"","title":"搜索结果"},{"body":"","categories":"","description":"","excerpt":"","ref":"/mlvp/categories/%E5%AD%A6%E4%B9%A0%E6%9D%90%E6%96%99/","tags":"","title":"学习材料"}]