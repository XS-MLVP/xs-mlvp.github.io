<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>取指目标队列（FTQ） on 香山微架构开放验证第一期：昆明湖BPU模块UT验证实战</title>
    <link>https://open-verify.cc/xs-bpu/tags/%E5%8F%96%E6%8C%87%E7%9B%AE%E6%A0%87%E9%98%9F%E5%88%97ftq/</link>
    <description>Recent content in 取指目标队列（FTQ） on 香山微架构开放验证第一期：昆明湖BPU模块UT验证实战</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <atom:link href="https://open-verify.cc/xs-bpu/tags/%E5%8F%96%E6%8C%87%E7%9B%AE%E6%A0%87%E9%98%9F%E5%88%97ftq/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>香山分支预测单元基础</title>
      <link>https://open-verify.cc/xs-bpu/docs/basic/01_xsbpu_basic/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://open-verify.cc/xs-bpu/docs/basic/01_xsbpu_basic/</guid>
      <description>分支预测块思想 对于一般的分支预测器来说，通常会根据给定的 PC 预测出该 PC 所对应的指令的相关信息，如是否是条件分支指令、是否是跳转指令。对于条件分支指令，会预测出是否会跳转，而对于跳转指令，则会预测出跳转目标。然而，这种一条一条地预测指令的方法效率较低，导致前端指令供给过慢。&#xA;相比之下，香山采用的预测方法是每次预测一个指令块。也就是说，给定一个 PC，香山会预测出以这个PC开始的一个分支预测块，包括了接下来若干条指令的情况，如是否存在分支指令、分支指令的位置、是否跳转以及跳转目标等信息。&#xA;这样的预测方法可以一次性地预测出多条指令，并将预测结果送往取指单元（IFU），指导IFU进行取指。此外，由于IFU需要考虑缓存行的性能问题，它可以根据预测块一次性地取出多条指令，从而提高吞吐效率。&#xA;在预测块产生后，分支预测块还会生成执行完本预测块后跳转到的 PC，接着 BPU 会根据该 PC 继续产生下一个分支预测块。&#xA;举个简单的例子&#xA;如上图所示，当 PC 执行到 0x20000118 时，BPU会经历如下几个步骤：&#xA;BPU得知PC 0x20000118 BPU产生以 0x20000118 为开始的分支预测块，内容大致如下 在接下来的若干条指令中 第三条是一个条件分支指令 对于这个条件分支指令，预测他将会跳转 跳转后的地址为 0x20000110 BPU将PC设置为 0x20000110，并继续产生下一个分支预测块 这便是采用了分支预测块的香山 BPU 的基本预测流程&#xA;多预测器、多流水线结构 上图展示了香山BPU的总体架构，其中我们需要关注两个主要方面：&#xA;多预测器 为了确保预测的准确性，香山 BPU 采用了多个预测器，并且这些预测器共同产生 BPU 的预测结果。例如，FTB 会生成基础的预测结果供后续预测器使用，而 TAGE 则对条件分支指令产生更精准的预测结果等。 多流水线 为了满足高性能的需求，香山 BPU 采用了流水线设计。各个预测器处于不同的流水线级别。其中，uFTB（即图中的uBTB）预测器位于第一流水线级别，能够在一个周期内产生预测结果。而其余预测器则需要2-3个周期才能生成预测结果，尽管预测时间较长，但预测结果相对更精确。 但是，如果在第三个周期才能获取到预测结果，并基于新的结果重新开始预测，这样的设计难免导致性能损失。因为这样一来，需要耗费三个时钟周期才可以完成一次预测。&#xA;为了在第一和第二周期就能够获取到某些预测器的预测结果，我们设置了三个预测结果通道，并将三个流水线级别的预测结果同时输出，如下图所示。&#xA;取指目标队列（FTQ） 分支预测结果暂存 尽管 BPU 可以以分支预测块的形式提供预测结果，IFU 也可以一次性取指多条指令，但它们之间仍然存在性能上的差距。通常情况下，BPU产生预测结果的速度更快。&#xA;因此，在 BPU 与 IFU 之间添加了一个取指目标队列（FTQ）作为缓冲。FTQ 本质上是一个队列，用于存储一个个数据项。BPU产生的预测结果会先暂存到FTQ中，然后由 IFU 从 FTQ 中获取预测结果，如下图所示。&#xA;每当 BPU 产生一个预测块，该预测块会被放入 FTQ 的队首。当 IFU 处于空闲状态时，它会从 FTQ 队尾获取下一个预测块。下方的示意图展示了这一过程。</description>
    </item>
  </channel>
</rss>
