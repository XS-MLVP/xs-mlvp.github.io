<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>OpenVerify Courses – Branch Folding History</title>
    <link>https://xs-mlvp.github.io/xs-bpu/en/tags/branch-folding-history/</link>
    <description>Recent content in Branch Folding History on OpenVerify Courses</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    
	  <atom:link href="https://xs-mlvp.github.io/xs-bpu/en/tags/branch-folding-history/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: BPU Top Module</title>
      <link>https://xs-mlvp.github.io/xs-bpu/en/docs/modules/00_bpu_top/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://xs-mlvp.github.io/xs-bpu/en/docs/modules/00_bpu_top/</guid>
      <description>
        
        
        &lt;p&gt;The overall function and structure of the BPU top level have been roughly described in previous documents. For those verifying the BPU top level, a more detailed description might be needed. Due to the many functions of the BPU top level, this section divides the BPU into several major functional points for further description. However, since there are too many details at the BPU top level, further details need to be understood by referring to the code.&lt;/p&gt;
&lt;h2 id=&#34;generator-maintenance-method&#34;&gt;Generator Maintenance Method&lt;/h2&gt;
&lt;p&gt;From the basic design documents of Xiangshan, we know that the BPU top level maintains various variables in the s0 cycle through generators, such as PC, branch history, etc. The core concept is to decide which pipeline level&amp;rsquo;s result to adopt through the redirection signal of the prediction result.&lt;/p&gt;
&lt;p&gt;There are a total of 6 generators in the BPU top level:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;npcGen&lt;/strong&gt; maintains the PC&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ghistPtrGen&lt;/strong&gt; maintains the global history pointer&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ghvBitWriteGens&lt;/strong&gt; maintains global history write data&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;foledGhGen&lt;/strong&gt; maintains the folded history&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;lastBrNumOHGen&lt;/strong&gt; maintains the position of the last effective branch instruction in the previous cycle&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;aheadFhObGen&lt;/strong&gt; maintains the oldest position of the branch history&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Except for &lt;code&gt;npcGen&lt;/code&gt;, the rest of the generators will be introduced in this document. In this section, we will focus on the method of generating the next prediction for the generators.&lt;/p&gt;
&lt;p&gt;In the code, you can see generators defined in a similar way:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Scala&#34; data-lang=&#34;Scala&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;val&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;npcGen&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;new&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;PhyPriorityMuxGenerator&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;UInt&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Next, the code registers the data sources for the generators through multiple statements:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Scala&#34; data-lang=&#34;Scala&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;npcGen&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;register&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;B&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;reg&lt;/span&gt;&lt;span style=&#34;color:#a40000&#34;&gt;，&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;...)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;npcGen&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;register&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;s1_valid&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;s1_target&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;...)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;npcGen&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;register&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;s2_redirect&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;s2_target&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;...)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;npcGen&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;register&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;s3_redirect&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;s3_target&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;...)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;npcGen&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;register&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;do_redirect&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;valid&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;do_redirect&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;bits&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;cfiUpdate&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;target&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;...)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Each line is called a registration. In a registration, the first signal parameter is the data valid signal, and the second signal parameter contains the specific data. The priority of the generator is also determined in the order of registration; the later the registration, the higher the priority. Therefore, the priority at the same time, from low to high, is as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;s0 blocked data&lt;/li&gt;
&lt;li&gt;Data updated based on s1 prediction results&lt;/li&gt;
&lt;li&gt;Data updated based on s2 prediction results&lt;/li&gt;
&lt;li&gt;Data updated based on s3 prediction results&lt;/li&gt;
&lt;li&gt;Data in external redirection of BPU&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this way, when the redirection of the prediction result is valid, we can avoid using the earlier pipeline level&amp;rsquo;s prediction result and adopt the corrected prediction result. This allows us to handle external redirection requests with the highest priority.&lt;/p&gt;
&lt;p&gt;We can conclude the method by which all generators generate s0 signals: &lt;strong&gt;Among all data valid signals, if only one is valid, the corresponding data is selected; if multiple data valid signals are valid, the data with the highest priority is selected&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;global-branch-history&#34;&gt;Global Branch History&lt;/h2&gt;
&lt;p&gt;We know that the global branch history is maintained at the BPU top level, and the maintenance strategy is consistent with the PC maintenance strategy. That is, after the prediction result is generated at each stage of the pipeline, the global branch history is updated based on the corresponding signals.&lt;/p&gt;
&lt;p&gt;The top level defines two sets of signals to maintain the global branch history:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ghv&lt;/strong&gt; stores the global branch history (maximum length 256)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ghist_ptr&lt;/strong&gt; global branch history pointer, pointing to the current position of the global branch history&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Similar to &lt;code&gt;s0_pc&lt;/code&gt;, &lt;code&gt;s1_pc&lt;/code&gt;, &lt;code&gt;s2_pc&lt;/code&gt;, the BPU top level also maintains signals for each stage of the global history pointer: &lt;code&gt;s0_ghist_ptr&lt;/code&gt;, &lt;code&gt;s1_ghist_ptr&lt;/code&gt;, &lt;code&gt;s2_ghist_ptr&lt;/code&gt;. However, the content in &lt;code&gt;ghv&lt;/code&gt; is fixed in position, and we only use &lt;code&gt;ghist_ptr&lt;/code&gt; to locate where the current global branch history starts.&lt;/p&gt;
&lt;h3 id=&#34;calculating-the-current-global-branch-history-with-ghist_ptr&#34;&gt;Calculating the Current Global Branch History with ghist_ptr&lt;/h3&gt;
&lt;p&gt;The use of &lt;code&gt;ghist_ptr&lt;/code&gt; is only visible at the BPU top level. What we pass to the sub-predictors is the global branch history after the data in the global history register is shifted based on &lt;code&gt;ghist_ptr&lt;/code&gt;. In the global branch history obtained by the sub-predictor, the least significant bit corresponds to the newest bit of the global branch history, and the most significant bit corresponds to the oldest bit.&lt;/p&gt;
&lt;p&gt;So how is the shifting done? First, let&amp;rsquo;s see how the global history is stored in &lt;code&gt;ghv&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Plain&#34; data-lang=&#34;Plain&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;|===== ghist =====&amp;gt;| =======&amp;gt;|
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;n                  ^         0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                   ghist_ptr
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;As shown in the figure above, the sequence represents the entire &lt;code&gt;ghv&lt;/code&gt; register, and &lt;code&gt;ghist_ptr&lt;/code&gt; points to a position in &lt;code&gt;ghv&lt;/code&gt;. This position represents the newest bit of the global branch history. When a new global history record needs to be added, &lt;code&gt;ghist_ptr&lt;/code&gt; is first decremented by 1, and then this bit is written to the position it points to. When &lt;code&gt;ghist_ptr&lt;/code&gt; is decremented to 0, it will loop back to point to the highest position, thereby overwriting the previously written global branch history.&lt;/p&gt;
&lt;p&gt;No matter what, starting from the position pointed to by &lt;code&gt;ghist_ptr&lt;/code&gt;, the pointer increases and the history gets older. Therefore, when we need to calculate the current global branch history, we only need to circularly right-shift the &lt;code&gt;ghv&lt;/code&gt; register by &lt;code&gt;ghist_ptr positions&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;updating-global-branch-history&#34;&gt;Updating Global Branch History&lt;/h3&gt;
&lt;p&gt;The strategy for updating the global branch history is consistent with the strategy for updating the &lt;code&gt;pc&lt;/code&gt;. At each pipeline stage, a &lt;strong&gt;pointer for the current stage and an update description of &lt;code&gt;ghv&lt;/code&gt;&lt;/strong&gt; are generated based on the prediction result of the current stage, and all are sent to the relevant generator for processing.&lt;/p&gt;
&lt;p&gt;The update strategy for the global branch history is consistent with the &lt;code&gt;pc&lt;/code&gt; update strategy, requiring the generation of a &lt;strong&gt;current stage pointer and &lt;code&gt;ghv&lt;/code&gt; update instructions&lt;/strong&gt; based on the current stage&amp;rsquo;s prediction results at each pipeline stage. These instructions are ultimately sent to the relevant generators for processing.&lt;/p&gt;
&lt;p&gt;The update description of &lt;code&gt;ghv&lt;/code&gt; is some information used to guide the update of the &lt;code&gt;ghv&lt;/code&gt; register. Xiangshan BPU maintains two pieces of information to fulfill this duty:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ghv_wdata&lt;/code&gt; the data that needs to be written into ghv&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ghv_wens&lt;/code&gt; the write bit mask&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For the final update, only the bits identified by &lt;code&gt;ghv_wens&lt;/code&gt; need to be written with the corresponding bits of &lt;code&gt;ghv_wdata&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Therefore, each pipeline stage needs to generate three sets of information: &lt;code&gt;ghist_ptr&lt;/code&gt;, &lt;code&gt;ghv_wdata&lt;/code&gt;, &lt;code&gt;ghv_wens&lt;/code&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Specifically, the prediction result can contain up to two branch instructions. We only need to set these pieces of information according to the actual situation. Here are some examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Only the first slot is valid, and the conditional branch instruction in it is predicted as not taken. Then the next position of &lt;code&gt;ghv_wens&lt;/code&gt; is set to 0, the corresponding position of &lt;code&gt;ghv_wens&lt;/code&gt; is set to 1, and &lt;code&gt;ghist_ptr&lt;/code&gt; is decremented by one.&lt;/li&gt;
&lt;li&gt;Both slots contain conditional branch instructions, the first is predicted as not taken, and the second is predicted as taken. At this time, &lt;code&gt;ghist_ptr&lt;/code&gt; should be decremented by two, and the other two pieces of information should indicate writing 01 to &lt;code&gt;ghv&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here, only one piece of &lt;code&gt;ghv_wdata&lt;/code&gt; information is maintained in the generator (maintained by the &lt;code&gt;ghvBitWriteGens&lt;/code&gt; generator), and &lt;code&gt;ghv_wens&lt;/code&gt; is not maintained by the generator. This is because a small trick is used here, where the final output of the generator&amp;rsquo;s &lt;code&gt;ghv_wdata&lt;/code&gt; is the result of the selected stage, and &lt;code&gt;ghv_wens&lt;/code&gt; is used by performing a bitwise OR operation on &lt;code&gt;ghv_wens&lt;/code&gt; of all stages.&lt;/p&gt;
&lt;p&gt;This consideration is based on:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If the later pipeline stage is valid, the global history pointer is restored to an older position, even if the history of newer positions is modified by the earlier pipeline&amp;rsquo;s &lt;code&gt;ghv_wens&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If the earlier pipeline stage is valid, the global history pointer continues to update to newer positions, and the later pipeline will not set &lt;code&gt;ghv_wens&lt;/code&gt; due to the ineffective redirect.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;branch-folded-history&#34;&gt;Branch Folded History&lt;/h2&gt;
&lt;p&gt;The branch folded history passed to the predictor is also maintained by the BPU top level. To shorten the update delay of the folded history, the BPU maintains many variables to support the fast update of the branch folded history. We will focus on this strategy and introduce the function of each variable.&lt;/p&gt;
&lt;p&gt;Before we start, let&amp;rsquo;s first look at how the branch folded history is defined and its structure.&lt;/p&gt;
&lt;h3 id=&#34;branch-folded-history-1&#34;&gt;Branch Folded History&lt;/h3&gt;
&lt;p&gt;If you have checked the BPU global interface documentation, you will know that the sub-predictor receives an array of bit vectors of different lengths, representing various lengths of folded history, and these folded histories are compressed from the global branch history.&lt;/p&gt;
&lt;p&gt;For the global branch history, we have a register that stores the global branch history with a length of 256. For example, suppose the length of the global branch history is 15 bits, and after shifting, we get a branch history like this: the least significant bit is the newest history record, and the most significant bit is the oldest history record.&lt;/p&gt;
&lt;p&gt;At this time, if we need to generate a 6-bit folded history from these 15 bits, we will use an XOR strategy for compression. The specific process is as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Plain&#34; data-lang=&#34;Plain&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    h[5]         h[4]       h[3]    h[2]   h[1]   h[0]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    h[11]        h[10]      h[9]    h[8]   h[7]   h[6]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;^                                   h[14]  h[13]  h[12]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;---------------------------------------------------------------
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    h[5]^h[11]   h[4]^h[10]         ...           h[0]^h[6]^h[12]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;That is, after arranging it as shown above, perform an XOR operation on the values at each position, and the result is the folded history of length 6.&lt;/p&gt;
&lt;h3 id=&#34;method-for-updating-branch-folded-history&#34;&gt;Method for Updating Branch Folded History&lt;/h3&gt;
&lt;p&gt;Now we want to update this branch folded history. When we insert a new history into the global branch history, it is inserted from the least significant bit, meaning the original h[0] becomes h[1]. If we want to obtain the folded history at this time, we only need to perform the XOR operation again. But such efficiency is too low, because the XOR operation may become particularly long. We can explore the impact of one update on the branch folded history.&lt;/p&gt;
&lt;p&gt;In the example above, before inserting a new history, the 6-bit folded history is generated in the following arrangement:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Plain&#34; data-lang=&#34;Plain&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;h[5]   h[4]   h[3]  h[2]  h[1]  h[0]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;h[11]  h[10]  h[9]  h[8]  h[7]  h[6]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    h[14] h[13] h[12]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After inserting a new history, it becomes like this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Plain&#34; data-lang=&#34;Plain&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;h[4]   h[3]   h[2]  h[1]  h[0]  h[new]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;h[10]  h[9]   h[8]  h[7]  h[6]  h[5]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;           (h[14])  h[13] h[12] h[11]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can notice some patterns:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Plain&#34; data-lang=&#34;Plain&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Before insertion:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;h[5]   {h[4]   h[3]  h[2]  h[1]  h[0] }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;h[11]  {h[10]  h[9]  h[8]  h[7]  h[6] }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;       {             h[14] h[13] h[12]}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;After insertion:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;{h[4]   h[3]   h[2]  h[1]  h[0] } h[new]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;{h[10]  h[9]   h[8]  h[7]  h[6] } h[5]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;{           (h[14])  h[13] h[12]} h[11]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The content in the curly braces has undergone a complete left shift, with h[5] and h[11] moving from the most significant bit to the least significant bit. So, in the compressed history, isn&amp;rsquo;t this just a typical cyclic left shift that we often encounter!&lt;/p&gt;
&lt;p&gt;However, only two bits have changed: one is the newly inserted h[new], and the other is the discarded h[14]. h[new] must be in the first position, and the discarded position is fixed. &lt;strong&gt;Therefore, to complete an update, we only need to know the value of the newly inserted history and the oldest bit of the previous history&lt;/strong&gt;. After the cyclic shift, modifying these two positions according to the actual situation will give us the updated folded history.&lt;/p&gt;
&lt;h3 id=&#34;implementation-of-update-method&#34;&gt;Implementation of Update Method&lt;/h3&gt;
&lt;p&gt;To achieve this update in the top-level BPU, two additional variables are maintained:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ahead_fh_oldest_bits&lt;/strong&gt;: the oldest bit of the global branch history, with additional bits stored before it&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;last_br_num_oh&lt;/strong&gt;: the slot number of the last effective branch instruction in the previous prediction&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;An optimization in the timing of operations occurs here because the global history pointer can only be updated based on the branch outcome when the pipeline-level prediction result is available. Updating the oldest bit after updating the global history pointer would increase the latency. Therefore, we maintain the branch outcome and update the oldest bit when it is needed in the next cycle.&lt;/p&gt;
&lt;p&gt;The oldest bit also needs to be maintained further back because after updating using the branch outcome, the relatively newer bits will become the oldest bits.&lt;/p&gt;
&lt;p&gt;Thus, there are three generators related to the folded history: &lt;code&gt;foldedGhGen&lt;/code&gt;, &lt;code&gt;lastBrNumOhGen&lt;/code&gt;, and &lt;code&gt;aheadFhObGen&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Information required for each update of the folded history&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Folded history information before the update&lt;/li&gt;
&lt;li&gt;Oldest bit of the global branch history (ahead_fh_oldest_bits)&lt;/li&gt;
&lt;li&gt;Last prediction&amp;rsquo;s branch outcome (last_br_num_oh)&lt;/li&gt;
&lt;li&gt;Whether there is a branch instruction in this update&lt;/li&gt;
&lt;li&gt;The branch outcome of this update: the slot number of the last effective branch instruction&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For each update of the folded history, the true oldest bit needs to be determined based on &lt;code&gt;last_br_num_oh&lt;/code&gt; and &lt;code&gt;ahead_fh_oldest_bits&lt;/code&gt;. Then, based on the oldest bit and the branch outcome of this update, several bits are modified, and finally, a cyclic left shift completes the update operation.&lt;/p&gt;
&lt;h2 id=&#34;pipeline-control-method&#34;&gt;Pipeline Control Method&lt;/h2&gt;
&lt;p&gt;Pipeline control is the core function of the BPU, with complex logic. All pipeline control signals in the top-level BPU are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;s1_valid, s2_valid, s3_valid&lt;/strong&gt;: indicate the corresponding pipeline data is valid&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;s1_ready, s2_ready, s3_ready&lt;/strong&gt;: indicate the corresponding pipeline is ready to continue the prediction of the previous pipeline stage&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;s1_component_ready, s2_component_ready, s3_component_ready&lt;/strong&gt;: indicate the readiness of the corresponding pipeline sub-predictor&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;s0_fire, s1_fire, s2_fire, s3_fire&lt;/strong&gt;: successful handshake signals, indicating that the pipeline data is valid and has been successfully passed to the next pipeline&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;s1_flush, s2_flush, s3_flush&lt;/strong&gt;: indicate whether the current pipeline needs flushing&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;s2_redirect, s3_redirect&lt;/strong&gt;: indicate whether the current pipeline needs to redirect due to a different prediction result&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;valid-ready-与-fire&#34;&gt;valid, ready 与 fire&lt;/h3&gt;
&lt;p&gt;We will introduce the purpose of each signal step by step. First, let&amp;rsquo;s look at the &lt;code&gt;fire&lt;/code&gt; signal, which indicates a successful handshake in the pipeline, meaning that the data has been successfully passed to the next pipeline. This signifies the end of the current cycle and the end of the prediction for this pipeline stage, with the prediction for the next pipeline stage about to begin in the next cycle.&lt;/p&gt;
&lt;p&gt;This requires two conditions:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;valid&lt;/code&gt;: The data in the current pipeline stage is valid.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ready&lt;/code&gt;: Indicates whether the next pipeline stage in the BPU top level and the predictor are ready.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;When these two signals are high simultaneously, the &lt;code&gt;fire&lt;/code&gt; signal is valid, indicating a successful handshake. If we isolate a single prediction, the timing should look like this (in reality, most of the time, each pipeline is valid continuously):&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&#34;1.png&#34; width=&#34;400px&#34;/&gt; 
&lt;/figure&gt;

&lt;p&gt;Of the four sets of signals mentioned earlier, &lt;code&gt;component_ready&lt;/code&gt; is generated by the predictor, while the rest are maintained by the BPU top level, with only the fire set of signals exposed to the sub-predictor.&lt;/p&gt;
&lt;p&gt;Next, let&amp;rsquo;s take s2 as an example to see how each signal is maintained.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ready&lt;/strong&gt; &lt;strong&gt;Signal&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Scala&#34; data-lang=&#34;Scala&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;s2_ready&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;s2_fire&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;||&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;!&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;s2_valid&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This assignment statement is a combinational circuit assignment, meaning that &lt;code&gt;s2_ready&lt;/code&gt; is directly related to &lt;code&gt;s2_fire&lt;/code&gt; and &lt;code&gt;s2_valid&lt;/code&gt; for this cycle, with two possible situations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If &lt;code&gt;s2_valid&lt;/code&gt; is invalid for this cycle, indicating that the s2 pipeline stage is empty and can accept new data, then &lt;code&gt;s2_ready&lt;/code&gt; is valid.&lt;/li&gt;
&lt;li&gt;If &lt;code&gt;s2_valid&lt;/code&gt; is valid for this cycle, indicating that the s2 pipeline stage has data that has not been passed to the next stage yet, but if &lt;code&gt;s2_fire&lt;/code&gt;, then the data will be passed in the next cycle. In this case, &lt;code&gt;s2_ready&lt;/code&gt; is valid, indicating that the data can flow into the next stage.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;valid Signal&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Maintaining ·s2_valid· is relatively simple, as it is only related to &lt;code&gt;s1_fire&lt;/code&gt; and &lt;code&gt;s2_ready&lt;/code&gt; signals. The relationship is as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When &lt;code&gt;s1_fire&lt;/code&gt; is valid, indicating that data is coming in and &lt;code&gt;s2_valid&lt;/code&gt; will be valid in the next cycle.&lt;/li&gt;
&lt;li&gt;When &lt;code&gt;s2_fire&lt;/code&gt; is valid, indicating that data is flowing out and &lt;code&gt;s2_valid&lt;/code&gt; will be invalid in the next cycle.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;fire Signal&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The fire signal is somewhat special, but for intermediate pipeline stages, its maintenance is straightforward. For example,&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Scala&#34; data-lang=&#34;Scala&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;s2_fire&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;s2_valid&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;s3_components_ready&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;s3_ready&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This simply requires considering the &lt;code&gt;valid&lt;/code&gt; of the current pipeline stage and the &lt;code&gt;ready&lt;/code&gt; of the next pipeline stage.&lt;/p&gt;
&lt;p&gt;However, for s0_fire, since there is no valid signal, it is directly set to &lt;code&gt;s1_components_ready &amp;amp;&amp;amp; s1_ready&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For s3_fire, as there is no ready signal for the next stage, it is directly set to &lt;code&gt;s3_valid&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;incorporating-flush-and-redirect&#34;&gt;Incorporating Flush and Redirect&lt;/h3&gt;
&lt;p&gt;When there is a different prediction result in the pipeline, a redirection signal is generated, and the pipeline needs to be flushed. &lt;code&gt;flush&lt;/code&gt; and &lt;code&gt;redirect&lt;/code&gt; handle these two tasks. &lt;code&gt;redirect&lt;/code&gt; indicates whether the current pipeline stage needs redirection, while &lt;code&gt;flush&lt;/code&gt; indicates whether the current pipeline stage needs flushing.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;redirect Signal&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The generation of &lt;code&gt;s2_redirect&lt;/code&gt; is as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Scala&#34; data-lang=&#34;Scala&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;s2_redirect&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;s2_fire&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;s2_redirect_s1_last_pred&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This means that when &lt;code&gt;s2_fire&lt;/code&gt; is valid and the prediction result of s2 is different from the prediction result saved from s1, this signal is valid. Later, this signal will be connected to the input of the sub-predictor and the output of the BPU prediction result, guiding the sub-predictor and FTQ to restore their states.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;flush Signal&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The flush signal is used to guide the flushing of the pipeline. For example, when s3_redirect is valid, it means that the incorrect prediction result has entered the pipeline, and both s1 and s2 are now predicting based on the wrong result. Therefore, the pipeline needs to be flushed to stop the previous stages and wait for new prediction results to enter.&lt;/p&gt;
&lt;p&gt;Specifically, the relationship between them is:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Scala&#34; data-lang=&#34;Scala&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#000&#34;&gt;s2_flush&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;s3_flush&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;||&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;s3_redirect&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#000&#34;&gt;s1_flush&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;s2_flush&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;||&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;s2_redirect&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This means that if a pipeline stage needs redirection, all previous stages will be flushed. The purpose of flush is to guide the valid signal. If the valid signal is valid in this cycle but the fire signal is not, it means that the incorrect data has not been taken by the next pipeline stage. In this case, when flush is valid, valid will immediately become invalid in the next cycle, avoiding storing incorrect data in the pipeline for a long time.&lt;/p&gt;
&lt;p&gt;However, the effect of flush on the valid signal varies depending on each pipeline stage. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For the s1 pipeline stage, although flush is valid, if &lt;code&gt;s0_fire&lt;/code&gt; is valid, indicating that new data is flowing in, valid will remain valid in the next cycle.&lt;/li&gt;
&lt;li&gt;For the s2 pipeline stage, if flush is valid, valid will definitely be invalid in the next cycle (because s1 is also flushed), indicating that valid can be directly set to invalid. However, there is a special case where &lt;code&gt;s2_redirect&lt;/code&gt; occurs but &lt;code&gt;s2_flush&lt;/code&gt; is not set to valid. In this case, if &lt;code&gt;s1_fire&lt;/code&gt; occurs, the incorrect prediction result of s1 may also flow in. In this case, &lt;code&gt;s2_valid&lt;/code&gt; needs to be determined based on the &lt;code&gt;s1_flush&lt;/code&gt; signal.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The use of flush is complex, and more detailed details need to be understood by referring to the code.&lt;/p&gt;
&lt;h2 id=&#34;redirect-recovery-logic&#34;&gt;Redirect Recovery Logic&lt;/h2&gt;
&lt;p&gt;When the redirect request from FTQ to BPU takes effect, it indicates that all stages of the pipeline have incorrect predictions, and all stages should be flushed. This can be achieved by setting &lt;code&gt;s3_flush&lt;/code&gt; to be valid. Therefore, we have:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Scala&#34; data-lang=&#34;Scala&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#000&#34;&gt;s3_flush&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;redirect_req&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;valid&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In the BPU, the redirect request is delayed by one cycle before being officially used. Therefore, the response of &lt;code&gt;s1_valid&lt;/code&gt; to the &lt;code&gt;flush&lt;/code&gt; signal needs to be changed. When the redirect request (before delay) is valid, &lt;code&gt;s1_valid&lt;/code&gt; in the next cycle is immediately set to invalid, without the need to refer to the &lt;code&gt;s0_fire&lt;/code&gt; signal.&lt;/p&gt;
&lt;p&gt;At this point, generators such as &lt;code&gt;npcGen&lt;/code&gt; also need to directly use the data from the redirect request to generate, which is equivalent to redirecting the BPU&amp;rsquo;s state to the state before the error occurred. However, it is important to note that the default redirect level in BPU is &lt;code&gt;flushAfter&lt;/code&gt;, which means that the redirect request corresponds to a predicted erroneous instruction, and the BPU assumes that although this instruction was predicted incorrectly, it has been corrected and executed by the backend. Therefore, the next prediction can start directly from the next instruction.&lt;/p&gt;
&lt;p&gt;Therefore, when recovering from a redirect, it is necessary not only to restore the information from the redirect interface, but also to update the execution status of this predicted erroneous instruction in the history.&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>
