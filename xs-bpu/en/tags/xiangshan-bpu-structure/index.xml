<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>OpenVerify Courses – Xiangshan BPU Structure</title>
    <link>https://xs-mlvp.github.io/xs-bpu/en/tags/xiangshan-bpu-structure/</link>
    <description>Recent content in Xiangshan BPU Structure on OpenVerify Courses</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    
	  <atom:link href="https://xs-mlvp.github.io/xs-bpu/en/tags/xiangshan-bpu-structure/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: Introduction to the Xiangshan Branch Prediction Unit Structure</title>
      <link>https://xs-mlvp.github.io/xs-bpu/en/docs/basic/02_xsbpu_structure/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://xs-mlvp.github.io/xs-bpu/en/docs/basic/02_xsbpu_structure/</guid>
      <description>
        
        
        &lt;h2 id=&#34;how-does-the-bpu-integrate-internal-sub-predictors&#34;&gt;How Does the BPU Integrate Internal Sub-predictors?&lt;/h2&gt;
&lt;p&gt;We already know that the Xiangshan BPU adopts multiple predictors and multiple pipeline schemes. To adapt to multiple pipelines, the BPU uses a three-channel result output interface. But how does it adapt to multiple predictors? This requires us to further explore the internal structure of the BPU.&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&#34;1.png&#34; width=&#34;600px&#34;/&gt; 
&lt;/figure&gt;

&lt;p&gt;The above figure is the BPU architecture diagram from the Xiangshan documentation. Currently, we only need to focus on one piece of information: all internal sub-predictors are encapsulated in a structure called &lt;code&gt;Composer&lt;/code&gt;. The BPU only needs to interact with &lt;code&gt;Composer&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;What is &lt;code&gt;Composer&lt;/code&gt;? Let&amp;rsquo;s first look at their definition in the Xiangshan code.&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&#34;2.png&#34; width=&#34;700px&#34;/&gt; 
&lt;/figure&gt;

&lt;p&gt;It can be seen that &lt;code&gt;Composer&lt;/code&gt; and the five sub-predictors have a common characteristic: they all inherit from the &lt;code&gt;BasePredictor&lt;/code&gt; base class. And the interface has been defined in the &lt;code&gt;BasePredictor&lt;/code&gt; class. In other words, &lt;code&gt;Composer&lt;/code&gt; and &lt;strong&gt;the five sub-predictors all have the same interface&lt;/strong&gt;! The top-level BPU can directly regard &lt;code&gt;Composer&lt;/code&gt; as a sub-predictor, without worrying about how the internal sub-predictors are connected.&lt;/p&gt;
&lt;h2 id=&#34;sub-predictor-interface&#34;&gt;Sub-predictor Interface&lt;/h2&gt;
&lt;p&gt;Next, we will look at what the sub-predictor interface looks like. This interface will involve the interaction between &lt;code&gt;Composer&lt;/code&gt; and the top-level BPU, as well as the interaction between each sub-predictor and &lt;code&gt;Composer&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s take &lt;code&gt;Composer&lt;/code&gt; as an example to illustrate the structure of the sub-predictor interface.&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&#34;3.png&#34; width=&#34;400px&#34;/&gt; 
&lt;/figure&gt;

&lt;p&gt;As shown in the above figure, the three-channel prediction results of &lt;code&gt;Composer&lt;/code&gt; are directly output to the outside of the BPU. There is also a set of three-channel prediction results connected from the inside of the BPU to &lt;code&gt;Composer&lt;/code&gt;. However, since the prediction results are generated by &lt;code&gt;Composer&lt;/code&gt;, the BPU will pass an empty prediction result to &lt;code&gt;Composer&lt;/code&gt;. The significance of this is to make the sub-predictor act as a &amp;ldquo;processor.&amp;rdquo; The sub-predictor will process the input prediction results and then output the processed prediction results.&lt;/p&gt;
&lt;p&gt;Next, the top-level BPU will provide the information needed for prediction to the pipeline. First is the &lt;strong&gt;PC&lt;/strong&gt; and &lt;strong&gt;branch history records&lt;/strong&gt; (including global history and global folding history). Next, the BPU will connect some pipeline control signals between &lt;code&gt;Composer&lt;/code&gt; and the &lt;strong&gt;pipeline control signals&lt;/strong&gt;. Finally, the BPU will directly connect the externally input &lt;strong&gt;redirect request interface&lt;/strong&gt; and &lt;strong&gt;update interface&lt;/strong&gt; to &lt;code&gt;Composer&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In the end, a simple definition of the sub-predictor interface can be given (for detailed definitions, please refer to the interface documentation):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;in&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;(s1, s2, s3)&lt;/strong&gt; Prediction information input&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;s0_pc&lt;/strong&gt;         PC to be predicted&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ghist&lt;/strong&gt;         Global branch history&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;folded_hist&lt;/strong&gt; Global folding history&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;out  (s1, s2, s3)&lt;/strong&gt; Prediction information output&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;流水线控制信号&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;s0_fire, s1_fire, s2_fire, s3_fire&lt;/strong&gt; Whether the corresponding pipeline stage is working&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;s2_redirect, s3_redirect&lt;/strong&gt;              Redirect signals when a prediction error is discovered in the subsequent pipeline stage&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;s1_ready, s2_ready, s3_ready&lt;/strong&gt;    Whether the sub-predictor corresponding pipeline stage is ready&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;update&lt;/strong&gt;        Update request&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;redirect&lt;/strong&gt;      Redirect request&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;connection-between-sub-predictors&#34;&gt;Connection Between Sub-predictors&lt;/h2&gt;
&lt;p&gt;We now know that the interfaces between each sub-predictor and &lt;code&gt;Composer&lt;/code&gt; are the same, and we also know how &lt;code&gt;Composer&lt;/code&gt; is connected to the top-level BPU. This section will explain how sub-predictors are connected within &lt;code&gt;Composer&lt;/code&gt;.&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&#34;4.png&#34; width=&#34;400px&#34;/&gt; 
&lt;/figure&gt;

&lt;p&gt;The above figure shows the connection structure of sub-predictors in &lt;code&gt;Composer&lt;/code&gt;. It can be seen that after the three-channel prediction results are input into &lt;code&gt;Composer&lt;/code&gt;, they are first processed by &lt;code&gt;uFTB&lt;/code&gt; and then output. They are then successively processed by &lt;code&gt;TAGE-SC&lt;/code&gt;, &lt;code&gt;FTB&lt;/code&gt;, &lt;code&gt;ITTAGE&lt;/code&gt;, and &lt;code&gt;RAS&lt;/code&gt;, and finally connected to the prediction result output of &lt;code&gt;Composer&lt;/code&gt;, which is then directly connected to the outside of the BPU by &lt;code&gt;Composer&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For other signals, because the interfaces between &lt;code&gt;Composer&lt;/code&gt; and each sub-predictor are the same, they are directly connected to the corresponding interfaces of each predictor by &lt;code&gt;Composer&lt;/code&gt;, without much additional processing.&lt;/p&gt;
&lt;h3 id=&#34;prediction-result-interface-connection&#34;&gt;Prediction Result Interface Connection&lt;/h3&gt;
&lt;p&gt;For sub-predictors, the connection of their prediction result is that the prediction result output of one predictor is the input of the next predictor. However, it should be noted that this connection is a combinational circuit connection and is not affected by timing.&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&#34;5.png&#34; width=&#34;400px&#34;/&gt; 
&lt;/figure&gt;

&lt;p&gt;As shown in the above figure, taking the s1 channel as an example, from input to the output of the last predictor, it is all modified by combinational circuits, unaffected by timing. Registers only exist between the s1, s2, and s3 channels.&lt;/p&gt;
&lt;p&gt;Therefore, increasing the number of sub-predictors will not increase the number of cycles required for prediction, but will only increase the delay required for prediction per cycle.&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>
