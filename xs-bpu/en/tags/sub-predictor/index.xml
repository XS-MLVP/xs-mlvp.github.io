<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>OpenVerify Courses – Sub-Predictor</title>
    <link>https://xs-mlvp.github.io/xs-bpu/en/tags/sub-predictor/</link>
    <description>Recent content in Sub-Predictor on OpenVerify Courses</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    
	  <atom:link href="https://xs-mlvp.github.io/xs-bpu/en/tags/sub-predictor/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: uFTB Branch Predictor</title>
      <link>https://xs-mlvp.github.io/xs-bpu/en/docs/modules/01_uftb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://xs-mlvp.github.io/xs-bpu/en/docs/modules/01_uftb/</guid>
      <description>
        
        
        &lt;h2 id=&#34;introduction-to-uftb&#34;&gt;Introduction to uFTB&lt;/h2&gt;
&lt;p&gt;uFTB is the first predictor among all the predictors in Xiangshan, and it serves as the cornerstone for other predictors to generate prediction results. uFTB works in the s1 stage. It can generate prediction results within the current cycle after obtaining s1_pc and output them in the s1 channel, without modifying other channels. It provides the position of the branch instruction and the target of the instruction. Subsequent predictors will further predict based on this result.&lt;/p&gt;
&lt;p&gt;Its essence is an FTB item cache, which stores FTB items, and the basic prediction result will be directly generated from the read-out FTB item.&lt;/p&gt;
&lt;p&gt;Therefore, before you start reading the document, make sure you understand the FTB items and their meanings, as well as the specific details of the prediction result interface.&lt;/p&gt;
&lt;h2 id=&#34;functionality-of-uftb&#34;&gt;Functionality of uFTB&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Cache FTB items and generate one-cycle prediction results&lt;/strong&gt;: uFTB maintains a small FTB item cache. After receiving PC, it reads out the FTB item corresponding to the PC within one cycle and generates an s1 stage prediction result from the FTB item.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Maintain two-bit saturating counters to provide basic conditional branch results&lt;/strong&gt;: uFTB maintains two-bit saturating counters for each line of the FTB item cache. The direction prediction result is reflected in the prediction result output of uFTB.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Update the FTB cache and two-bit saturating counters based on update requests&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;uftb-cache-structure&#34;&gt;uFTB Cache Structure&lt;/h2&gt;
&lt;p&gt;As mentioned above, uFTB is essentially a small cache that stores FTB items. Its approximate structure is shown in the figure below.&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&#34;1.png&#34; width=&#34;400px&#34;/&gt; 
&lt;/figure&gt;

&lt;p&gt;In the current version of Xiangshan, uFTB has a total of 32 cache lines, each cache line is called &lt;code&gt;FauFTBWay&lt;/code&gt;, and one FTB item can be stored in each cache line.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;When s1 pipeline is valid&lt;/strong&gt;, uFTB will use &lt;code&gt;s1_pc&lt;/code&gt; to determine which item of the uFTB cache to read out. The cache is indexed based on the tag field in PC, which is defined as pc[16:1], i.e., taking 16 bits from PC as an identifier to match a certain line in the cache.&lt;/p&gt;
&lt;p&gt;Each line in the cache, i.e., the data request interface in &lt;code&gt;FauFTBWay&lt;/code&gt;, has three items:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;req_tag&lt;/strong&gt;: Input tag identifier extracted from pc&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;resp&lt;/strong&gt;: Output the FTB item stored in this line&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;resp_hit&lt;/strong&gt;: Output indicates whether the FTB item in this line matches req_tag
uFTB connects the tag to the data request interface of each line in the cache and selects the hit FTB item based on the &lt;code&gt;resp_hit&lt;/code&gt; signal. Subsequent steps will generate a complete prediction result based on this FTB item.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;two-bit-saturating-counters&#34;&gt;Two-Bit Saturating Counters&lt;/h2&gt;
&lt;p&gt;uFTB maintains two-bit saturating counters for each line of the FTB item cache. As we know, an FTB item can store up to two conditional branch instructions, so each line&amp;rsquo;s two-bit saturating counters also have two, responsible for providing rough prediction results for the conditional branch instructions in them.&lt;/p&gt;
&lt;p&gt;When indexing the FTB item, uFTB also indexes the corresponding two-bit saturating counters.&lt;/p&gt;
&lt;p&gt;When the prediction result is generated, it will be based on the FTB item and the contents of the two two-bit saturating counters corresponding to it.&lt;/p&gt;
&lt;h2 id=&#34;prediction-result-generation&#34;&gt;Prediction Result Generation&lt;/h2&gt;
&lt;p&gt;After indexing the corresponding FTB item and two two-bit saturating counters based on s1_pc, uFTB needs to generate a prediction result based on them. The prediction result generated by uFTB will be outputted through the s1 channel when s1 pipeline is valid, and will not be modified for s2 and s3 channels.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The signal generation method in the s1 prediction result can refer to the following list:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;hit&lt;/strong&gt;Whether the FTB item hits
&lt;ul&gt;
&lt;li&gt;Generation method: &lt;code&gt;resp_hit&lt;/code&gt; signal in &lt;code&gt;FauFTBWay&lt;/code&gt;, one of them is valid&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;slot_valids&lt;/strong&gt;: Slot valid bit, indicating whether each slot in the ftb item is valid&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;targets&lt;/strong&gt;: Jump target address corresponding to each slot&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;offsets&lt;/strong&gt;: The offset of each instruction in the slot relative to the starting address of the prediction block&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;is_jal&lt;/strong&gt;: Whether the prediction block contains a jal instruction&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;is_jalr&lt;/strong&gt;: Whether the prediction block contains a jalr instruction&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;is_call&lt;/strong&gt;: Whether the prediction block contains a call instruction&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;is_ret&lt;/strong&gt;: Whether the prediction block contains a ret instruction&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;last_may_be_rvi_call&lt;/strong&gt;: Signal indicating that the last slot in the prediction block may be an RVI type call instruction&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;is_br_sharing&lt;/strong&gt;: The signal stored in the last slot (tailSlot) indicates a conditional branch instruction.
&lt;ul&gt;
&lt;li&gt;Generation: Exported from the corresponding field in the FTB entry.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;fallThroughErr&lt;/strong&gt;: The &lt;code&gt;pftAddr&lt;/code&gt; recorded in the FTB entry is incorrect.
&lt;ul&gt;
&lt;li&gt;Generation: Compare whether the end address represented by &lt;code&gt;pftAddr&lt;/code&gt; is greater than the start address of the predicted block. If it is smaller, an error has occurred, and this signal is set to valid. This situation may occur when the PC indexes an incorrect FTB entry.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;fallThroughAddr&lt;/strong&gt;: The end address of the predicted block.
&lt;ul&gt;
&lt;li&gt;Generation: If &lt;code&gt;fallThroughErr&lt;/code&gt; is invalid, it is generated based on &lt;code&gt;pftAddr&lt;/code&gt;. Otherwise, it is set to the start address + prediction width.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;br_taken_mask&lt;/strong&gt;: Branch prediction result, with each branch (slot) corresponding to a bit indicating whether the branch is predicted as taken.
&lt;ul&gt;
&lt;li&gt;Generation: Generated based on the &lt;code&gt;always_taken&lt;/code&gt; field in the FTB entry and the result indicated by the two-bit saturating counter.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;jalr_target&lt;/strong&gt;: The jump target of the jalr in this predicted block.
-Generation: From the jump target in the tailSlot of the FTB entry.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;uftb-update&#34;&gt;uFTB Update&lt;/h2&gt;
&lt;p&gt;The update of uFTB involves updating the FTB entry cache and the two-bit saturating counter, with the update content obtained through the update interface.&lt;/p&gt;
&lt;p&gt;In the uFTB predictor, the reading and writing of the cache and the two-bit saturating counter do not conflict, so we do not need to consider timing conflicts between reading and updating and can consider them as two independent parts.&lt;/p&gt;
&lt;h3 id=&#34;ftb-cache-update&#34;&gt;FTB Cache Update&lt;/h3&gt;
&lt;p&gt;The update process of the FTB cache is simple. The update channel has already specified the PC and the newly generated FTB entry, so it only needs to be written to the specified position in the cache.&lt;/p&gt;
&lt;p&gt;FTB cache updating requires two cycles:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In the first cycle, calculate the following based on the signals in the update:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Which row in the cache corresponds to the update request&lt;/strong&gt; The PC extracted from the update request is sent to the update request channel of FauFTBWay, and the hit signal returned by each row is calculated.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;In the second cycle, update according to the position calculated in the first cycle. If no row is hit, uFTB will use a &lt;strong&gt;pseudo-LRU replacement algorithm&lt;/strong&gt; to select the row to be written.
Specifically, the ftb_entry signal group in the update channel contains the complete information of the new FTB entry, which is sent to the cache row that needs to be updated.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;two-bit-saturating-counter-update&#34;&gt;Two-Bit Saturating Counter Update&lt;/h3&gt;
&lt;p&gt;The update of the two-bit saturating counter needs to be combined with the actual execution of the subsequent program and the branch instruction information recorded in the FTB entry, which can be obtained from the update channel.&lt;/p&gt;
&lt;p&gt;The update of the two-bit saturating counter also requires two cycles:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In the first cycle, calculate which two-bit saturating counter corresponding to the conditional branch instruction in the slot needs to be updated, which needs to meet the following conditions:
&lt;ul&gt;
&lt;li&gt;The current branch instruction slot is valid and contains a conditional branch instruction.&lt;/li&gt;
&lt;li&gt;The current branch instruction slot is not marked as always_taken. (Because after being marked as always_taken, the result of the two-bit saturating counter will not be used.)&lt;/li&gt;
&lt;li&gt;The current branch instruction slot is not after the branch instruction slot where an actual jump occurred.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;In the second cycle, update the saturating counter based on the mask generated in the first cycle and the &lt;code&gt;br_taken_mask&lt;/code&gt; information in the update channel.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;interface-list&#34;&gt;Interface List&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;信号类型&lt;/th&gt;
&lt;th&gt;信号位&lt;/th&gt;
&lt;th&gt;信号名&lt;/th&gt;
&lt;th&gt;信号描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;clock&lt;/td&gt;
&lt;td&gt;输入时钟&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;reset&lt;/td&gt;
&lt;td&gt;复位信号&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;[35:0]&lt;/td&gt;
&lt;td&gt;io_reset_vector&lt;/td&gt;
&lt;td&gt;用于reset时，reset s1_pc_dup_0 提供的值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_in_bits_s0_pc_0&lt;/td&gt;
&lt;td&gt;输入位s0_pc 的 第0个复制&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_in_bits_s0_pc_1&lt;/td&gt;
&lt;td&gt;同上 第1个&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_in_bits_s0_pc_2&lt;/td&gt;
&lt;td&gt;同上 第2个&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_in_bits_s0_pc_3&lt;/td&gt;
&lt;td&gt;同上 第3个&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s1_pc_0&lt;/td&gt;
&lt;td&gt;输出s1_pc 的 第0个复制&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s1_pc_1&lt;/td&gt;
&lt;td&gt;同上 第1个&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s1_pc_2&lt;/td&gt;
&lt;td&gt;同上 第2个&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s1_pc_3&lt;/td&gt;
&lt;td&gt;同上 第3个&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_0_br_taken_mask_0&lt;/td&gt;
&lt;td&gt;solt 0 是否被预测为 always taken&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_0_br_taken_mask_1&lt;/td&gt;
&lt;td&gt;solt 1 是否被预测为 always taken&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_0_slot_valids_0&lt;/td&gt;
&lt;td&gt;solt 0 是否启用&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_0_slot_valids_1&lt;/td&gt;
&lt;td&gt;solt 1 是否启用&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_0_targets_0&lt;/td&gt;
&lt;td&gt;solt 0 对应的跳转目标地址&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_0_targets_1&lt;/td&gt;
&lt;td&gt;solt 1 对应的跳转目标地址&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[3:0]&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_0_offsets_0&lt;/td&gt;
&lt;td&gt;solt 0 中分支指令相对于地址块起始pc的偏移&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[3:0]&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_0_offsets_1&lt;/td&gt;
&lt;td&gt;solt 1 中分支指令相对于地址块起始pc的偏移&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_0_fallThroughAddr&lt;/td&gt;
&lt;td&gt;预测块的结束地址&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_0_is_br_sharing&lt;/td&gt;
&lt;td&gt;solt 1（无条件跳转）是否被共享为有条件跳转指令&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_0_hit&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_1_br_taken_mask_0&lt;/td&gt;
&lt;td&gt;类似 io_out_s1_pc_1 io_out_s1_full_pred_0的复制&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_1_br_taken_mask_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_1_slot_valids_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_1_slot_valids_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_1_targets_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_1_targets_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[3:0]&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_1_offsets_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[3:0]&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_1_offsets_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_1_fallThroughAddr&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_1_is_br_sharing&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_1_hit&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_2_br_taken_mask_0&lt;/td&gt;
&lt;td&gt;同上&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_2_br_taken_mask_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_2_slot_valids_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_2_slot_valids_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_2_targets_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_2_targets_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[3:0]&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_2_offsets_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[3:0]&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_2_offsets_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_2_fallThroughAddr&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_2_is_br_sharing&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_2_hit&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_3_br_taken_mask_0&lt;/td&gt;
&lt;td&gt;同上&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_3_br_taken_mask_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_3_slot_valids_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_3_slot_valids_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_3_targets_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_3_targets_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[3:0]&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_3_offsets_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[3:0]&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_3_offsets_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_3_fallThroughAddr&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_3_fallThroughErr&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_3_is_br_sharing&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s1_full_pred_3_hit&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[222:0]&lt;/td&gt;
&lt;td&gt;io_out_last_stage_meta&lt;/td&gt;
&lt;td&gt;输出最后阶段的元信息 io_out_last_stage_meta = {213&amp;rsquo;h0, resp_meta_pred_way_r_1, resp_meta_hit_r_1}&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_ctrl_ubtb_enable&lt;/td&gt;
&lt;td&gt;控制ubtb是否启用&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_s0_fire_0&lt;/td&gt;
&lt;td&gt;输入s0_fire_0，与 io_out_s1_pc_0 &amp;lt;= io_in_bits_s0_pc_0 的时钟门控相关&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_s0_fire_1&lt;/td&gt;
&lt;td&gt;输入s0_fire_1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_s0_fire_2&lt;/td&gt;
&lt;td&gt;输入s0_fire_2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_s0_fire_3&lt;/td&gt;
&lt;td&gt;输入s0_fire_3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_s1_fire_0&lt;/td&gt;
&lt;td&gt;输入s1_fire_0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_s2_fire_0&lt;/td&gt;
&lt;td&gt;输入s2_fire_0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_update_valid&lt;/td&gt;
&lt;td&gt;更新有效性&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_update_bits_pc&lt;/td&gt;
&lt;td&gt;传回的预测块pc（用于指示更新的预测块）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;[3:0]&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_brSlots_0_offset&lt;/td&gt;
&lt;td&gt;solt 0 中分支指令相对于地址块起始pc的偏移&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;[11:0]&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_brSlots_0_lower&lt;/td&gt;
&lt;td&gt;跳转目标地址的低位&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;[1:0]&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_brSlots_0_tarStat&lt;/td&gt;
&lt;td&gt;跳转后的 pc 高位是否进退位&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_brSlots_0_valid&lt;/td&gt;
&lt;td&gt;是否启用&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;[3:0]&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_tailSlot_offset&lt;/td&gt;
&lt;td&gt;solt 1 中分支指令相对于地址块起始pc的偏移&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;[19:0]&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_tailSlot_lower&lt;/td&gt;
&lt;td&gt;跳转目标地址的低位&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;[1:0]&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_tailSlot_tarStat&lt;/td&gt;
&lt;td&gt;跳转后的 pc 高位是否进退位&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_tailSlot_sharing&lt;/td&gt;
&lt;td&gt;无条件跳转指令槽中存储条件分支指令&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_tailSlot_valid&lt;/td&gt;
&lt;td&gt;是否启用&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;[3:0]&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_pftAddr&lt;/td&gt;
&lt;td&gt;Partial Fallthrough Addr 如果预测块中没有跳转，那么程序将会顺序执行到达的地址，预测块的结束地址。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_carry&lt;/td&gt;
&lt;td&gt;pc+pft时是否产生进位&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_always_taken_0&lt;/td&gt;
&lt;td&gt;是否预测为总是跳转&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_always_taken_1&lt;/td&gt;
&lt;td&gt;是否预测为总是跳转&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_update_bits_br_taken_mask_0&lt;/td&gt;
&lt;td&gt;是否跳转&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_update_bits_br_taken_mask_1&lt;/td&gt;
&lt;td&gt;是否跳转&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Base Predictor Class and Sub Predictor Interface</title>
      <link>https://xs-mlvp.github.io/xs-bpu/en/docs/ports/03_subpredictor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://xs-mlvp.github.io/xs-bpu/en/docs/ports/03_subpredictor/</guid>
      <description>
        
        
        &lt;p&gt;In the Xiangshan branch prediction unit, all its sub-predictors and the class implementations of Composer are inherited from the sub-predictor base class (BasePredictor). The sub-predictor interface (BasePredictorIO) is also defined in the sub-predictor base class. Therefore, we can consider that Composer and all sub-predictors have the same interface.&lt;/p&gt;
&lt;p&gt;In the understanding and verification of sub-prediction, our most direct external interaction occurs in the sub-predictor interface and some variables defined in the sub-predictor base class. Therefore, before verifying the sub-predictor, it is strongly recommended that you read and understand this section of the document.&lt;/p&gt;
&lt;p&gt;The general content and usage of the sub-branch predictor interface have been introduced in the &lt;code&gt;Xiangshan Branch Prediction Unit (BPU) Basic Design&lt;/code&gt; section. This document will focus on the signal details of the interface.&lt;/p&gt;
&lt;h2 id=&#34;sub-branch-predictor-interface-basepredictorio&#34;&gt;&lt;strong&gt;Sub-Branch Predictor Interface (BasePredictorIO)&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Interface Definition: &lt;code&gt;src/main/scala/xiangshan/frontend/BPU.scala&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Each sub-branch predictor needs to implement this interface, which defines the input and output interfaces of the sub-branch predictor.&lt;/p&gt;
&lt;p&gt;Note: Some signals are defined as &lt;code&gt;numDup&lt;/code&gt; quantities, where each signal is exactly the same. Multiple identical signals are for other considerations.&lt;/p&gt;
&lt;p&gt;The detailed signal list is as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;reset_vector&lt;/strong&gt; Reset vector, when reset occurs, the BPU&amp;rsquo;s pc will be reset to this value.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Interface Type：&lt;code&gt;UInt(PAddrBits.W)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;in&lt;/strong&gt; Information sent from the BPU to the sub-branch predictor&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Interface Type：&lt;code&gt;DecoupledIO(new BasePredictorInput)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Signal List：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;s0_pc&lt;/strong&gt; PC of the s0 pipeline stage
&lt;ul&gt;
&lt;li&gt;Interface Type：&lt;code&gt;Vec(numDup, UInt(VAddrBits.W))&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;folded_hist&lt;/strong&gt; Global folded history information
&lt;ul&gt;
&lt;li&gt;Interface Type：&lt;code&gt;Vec(numDup, new AllFoldedHistories(foldedGHistInfos))&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Signal List：See（&lt;code&gt;AllFoldedHistories&lt;/code&gt;）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ghist&lt;/strong&gt; Global branch history information
&lt;ul&gt;
&lt;li&gt;Interface Type：&lt;code&gt;UInt(HistoryLength.W)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;resp_in&lt;/strong&gt;  Global branch prediction information (including s1, s2, s3 prediction result information)
&lt;ul&gt;
&lt;li&gt;Interface Type：&lt;code&gt;BranchPredictionResp&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Signal List：See（&lt;code&gt;BranchPredictionResp&lt;/code&gt;）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;out&lt;/strong&gt; Information sent from the sub-branch predictor to the BPU (including s1, s2, s3 prediction result information)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Interface Type：&lt;code&gt;new BasePredictorOutput&lt;/code&gt; 继承自 &lt;code&gt;BranchPredictionResp&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Signal List：See（&lt;code&gt;BranchPredictionResp&lt;/code&gt;）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ctrl&lt;/strong&gt; BPU sub-predictor enable control signal, mainly used to control whether each predictor is enabled&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Interface Type：&lt;code&gt;BPUCtrl&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Interface Type：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ubtb_enable&lt;/strong&gt;: UBTB predictor enable
&lt;ul&gt;
&lt;li&gt;Interface Type：&lt;code&gt;Bool()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;btb_enable&lt;/strong&gt;: BTB predictor enable
&lt;ul&gt;
&lt;li&gt;接Interface Type：&lt;code&gt;Bool()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bim_enable&lt;/strong&gt;: BIM predictor enable
&lt;ul&gt;
&lt;li&gt;Interface Type：&lt;code&gt;Bool()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;tage_enable&lt;/strong&gt;: TAGE predictor enable
&lt;ul&gt;
&lt;li&gt;Interface Type：&lt;code&gt;Bool()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;sc_enable&lt;/strong&gt;: SC predictor enable
&lt;ul&gt;
&lt;li&gt;Interface Type：&lt;code&gt;Bool()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ras_enable&lt;/strong&gt;: RAS predictor enable
&lt;ul&gt;
&lt;li&gt;Interface Type：&lt;code&gt;Bool()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;loop_enable&lt;/strong&gt;: LOOP predictor enable
&lt;ul&gt;
&lt;li&gt;Interface Type：&lt;code&gt;Bool()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;s0_fire&lt;/strong&gt; s0 stage handshake success signal&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Interface Type：&lt;code&gt;Vec(numDup, Bool())&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;s1_fire&lt;/strong&gt; s1 stage handshake success signal&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Interface Type：&lt;code&gt;Vec(numDup, Bool())&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;s2_fire&lt;/strong&gt; s2 stage handshake success signal&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Interface Type：&lt;code&gt;Vec(numDup, Bool())&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;s3_fire&lt;/strong&gt; s3 stage handshake success signal&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Interface Type：&lt;code&gt;Vec(numDup, Bool())&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;s2_redirect&lt;/strong&gt; s2 stage redirection signal&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Interface Type：&lt;code&gt;Vec(numDup, Bool())&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;s3_redirect&lt;/strong&gt; s3 stage redirection signal&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Interface Type：&lt;code&gt;Vec(numDup, Bool())&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;s1_ready&lt;/strong&gt; s1 stage ready to receive information (Direction: output from the sub-predictor)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Interface Type：&lt;code&gt;Bool()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;s2_ready&lt;/strong&gt; s2 stage ready to receive information (Direction: output from the sub-predictor)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Interface Type：&lt;code&gt;Bool()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;s3_ready&lt;/strong&gt; s3 stage ready to receive information (Direction: output from the sub-predictor)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Interface Type：&lt;code&gt;Bool()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;update&lt;/strong&gt; Update request forwarded from the BPU to the sub-branch predictor&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Interface Type：&lt;code&gt;Valid(new BranchPredictionUpdate)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Signal List：See（&lt;code&gt;BranchPredictionUpdate&lt;/code&gt;）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;redirect&lt;/strong&gt; Redirect request forwarded from the BPU to the sub-branch predictor&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Interface Type：&lt;code&gt;Valid(new BranchPredictionRedirect)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Signal List：See（&lt;code&gt;BranchPredictionRedirect&lt;/code&gt;）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The pipeline control signals will be further explained in the following content.&lt;/p&gt;
&lt;h3 id=&#34;global-folding-history-allfoldedhistories&#34;&gt;Global Folding History (AllFoldedHistories)&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Interface Definition：&lt;/strong&gt;&lt;code&gt;src/main/scala/xiangshan/frontend/FrontendBundle.scala&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Interface Type：&lt;/strong&gt;&lt;code&gt;AllFoldedHistories(foldedGHistInfos))&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The interface information of the global folding history consists of only one &lt;code&gt;FoldedHistory&lt;/code&gt; list.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;hist&lt;/strong&gt; List of folded histories
&lt;ul&gt;
&lt;li&gt;Interface Type：&lt;code&gt;MixedVec(gen.map{case (l, cl) =&amp;gt; new FoldedHistory(l, cl, numBr)})&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The interface information of &lt;code&gt;FoldedHistory&lt;/code&gt; also has only one item.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;folded_hist&lt;/strong&gt; Single folded history, with a bit width equal to the compressed history length.
&lt;ul&gt;
&lt;li&gt;Interface Type：&lt;code&gt;UInt(compLen.W)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This means that the interface of the global folding history is actually a list that stores folded histories, where each item is a folded history of a specific length.&lt;/p&gt;
&lt;h2 id=&#34;base-predictor-class&#34;&gt;Base Predictor Class&lt;/h2&gt;
&lt;p&gt;The base predictor class defines several signals, which can be accessed in each sub-predictor, and several connections are made within it.&lt;/p&gt;
&lt;p&gt;Most of the signals are relatively easy to understand. We need to pay particular attention to the pc of each pipeline, which also involves your understanding of pipeline control signals. Therefore, next, we will introduce the meanings of pipeline control signals that need to be paid attention to in sub-predictors, as well as the meanings of the s1_pc, s2_pc, s3_pc signals.&lt;/p&gt;
&lt;p&gt;There are three groups of pipeline control signals:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;fire signals  (s0, s1, s2, s3)&lt;/li&gt;
&lt;li&gt;redirect signals  (s2, s3)&lt;/li&gt;
&lt;li&gt;ready signals  (s1, s2, s3)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The pc signals in the base predictor class are divided into four groups, &lt;code&gt;s0_pc_dup&lt;/code&gt;, &lt;code&gt;s1_pc_dup&lt;/code&gt;, &lt;code&gt;s2_pc_dup&lt;/code&gt;, &lt;code&gt;s3_pc_dup&lt;/code&gt;. Each group of signals contains multiple pc signals, which are exactly the same and are duplicated for some other reasons. Therefore, we can simply consider them as &lt;code&gt;s0_pc&lt;/code&gt;, &lt;code&gt;s1_pc&lt;/code&gt;, &lt;code&gt;s2_pc&lt;/code&gt;, &lt;code&gt;s3_pc&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Their usage can be seen in the following diagram:&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&#34;1.png&#34; width=&#34;700px&#34;/&gt; 
&lt;/figure&gt;

&lt;p&gt;Their relationship with the pipeline control signals is as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;s0_pc&lt;/code&gt; is directly connected from the &lt;code&gt;in.s0_pc&lt;/code&gt; in the input interface.&lt;/li&gt;
&lt;li&gt;When &lt;code&gt;s0_fire&lt;/code&gt; is active, the next cycle &lt;code&gt;s1_pc&lt;/code&gt; will output the value of &lt;code&gt;s0_pc&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;When &lt;code&gt;s1_fire&lt;/code&gt; is active, the next cycle &lt;code&gt;s2_pc&lt;/code&gt; will output the value of &lt;code&gt;s1_pc&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;When &lt;code&gt;s2_fire&lt;/code&gt; is active, the next cycle &lt;code&gt;s3_pc&lt;/code&gt; will output the value of &lt;code&gt;s2_pc&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In other words, the &lt;code&gt;fire&lt;/code&gt; signal affects whether the data of the next cycle is valid. For example, the &lt;code&gt;s0_fire&lt;/code&gt; signal affects whether the data of the s1 pipeline is valid, and the &lt;code&gt;s1_fire&lt;/code&gt; signal affects whether the data of the s2 pipeline is valid.&lt;/p&gt;
&lt;p&gt;Whether the &lt;code&gt;fire&lt;/code&gt; signal is valid depends on whether the data of this pipeline stage is valid and whether the next pipeline stage is ready. For example, the &lt;code&gt;s1_fire&lt;/code&gt; signal is valid only if the data of the s1 stage is valid and the &lt;code&gt;s2_ready&lt;/code&gt; signal from the sub-predictor output is valid. At this point, it can be considered that the data processing of the s1 stage is completed, the s2 stage is ready, and the data of the next cycle will be directly sent to the s2 stage.&lt;/p&gt;
&lt;p&gt;Therefore, in the sub-predictor, taking the s1 stage as an example, &lt;code&gt;s1_ready&lt;/code&gt; can block data from entering the s1 stage. When &lt;code&gt;s1_ready&lt;/code&gt; is active, the data for the s1 stage will be valid in the next cycle. &lt;strong&gt;When &lt;code&gt;s1_fire&lt;/code&gt; is active, it indicates that the data in the s1 stage is already valid and the predictor has generated the result for the s1 stage&lt;/strong&gt;. The data will then be directly sent to the s2 stage in the next cycle.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;redirect&lt;/code&gt; signal is relatively clear. For example, in the s2 stage, when &lt;code&gt;s2_redirect&lt;/code&gt; is valid, it indicates that when &lt;code&gt;s2_fire&lt;/code&gt; is valid, the s2 prediction result is different from the s1 prediction result in the previous cycle.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: FTB Branch Predictor</title>
      <link>https://xs-mlvp.github.io/xs-bpu/en/docs/modules/03_ftb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://xs-mlvp.github.io/xs-bpu/en/docs/modules/03_ftb/</guid>
      <description>
        
        
        &lt;h2 id=&#34;introduction-to-ftb&#34;&gt;Introduction to FTB&lt;/h2&gt;
&lt;p&gt;FTB is the third sub-predictor of the Xiangshan BPU, and it can also get the outputs of uFTB and TAGE-SC together. In the input interface of FTB, the s1 channel contains the basic prediction results of uFTB, and the s2 and s3 channels are filled with only one group of signals, &lt;code&gt;br_taken_mask&lt;/code&gt;, by TAGE-SC, without the basic prediction results generated by the FTB entry. The function of FTB is to provide basic prediction results for the s2 and s3 channels.&lt;/p&gt;
&lt;p&gt;In terms of functionality and structure, FTB is similar to uFTB. The main difference is that FTB can accommodate more FTB entries, and the prediction results of FTB are output in the s2 and s3 channels. Due to its large capacity, the readout speed of FTB is slower than that of uFTB, and it cannot be placed in the first cycle to generate prediction results. However, the large capacity enables it to obtain more accurate prediction results.&lt;/p&gt;
&lt;h2 id=&#34;function-of-uftb&#34;&gt;Function of uFTB&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Cache more FTB entries and provide basic prediction results for the s2 and s3 channels&lt;/strong&gt;. The FTB predictor is essentially a storage with a large capacity. It reads the corresponding FTB entry based on the current predicted PC and outputs it in the s2 stage. At the same time, this FTB entry will be saved for one more cycle to generate the s3 stage prediction result. One thing to note is to consider the &lt;code&gt;br_taken_mask&lt;/code&gt; field inputted by the previous predictor to avoid losing it during generation.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Update FTB entries based on update requests.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ftb-storage-structure&#34;&gt;FTB Storage Structure&lt;/h2&gt;
&lt;p&gt;FTB entries in the FTB predictor are placed in a dedicated storage structure called &lt;code&gt;FTBBank&lt;/code&gt;. Before further examining the structure of &lt;code&gt;FTBBank&lt;/code&gt;, let&amp;rsquo;s first see how &lt;code&gt;FTBBank&lt;/code&gt; is used.&lt;/p&gt;
&lt;h3 id=&#34;ftb-read-request&#34;&gt;FTB Read Request&lt;/h3&gt;
&lt;p&gt;The read request interface of &lt;code&gt;FTBBank&lt;/code&gt; is as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;req_pc&lt;/strong&gt; Requested PC
&lt;ul&gt;
&lt;li&gt;Interface type: Flipped(DecoupledIO(UInt(VAddrBits.W)))&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;read_resp&lt;/strong&gt; Read out FTB entry
&lt;ul&gt;
&lt;li&gt;Interface type: FTBEntry&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;read_hits&lt;/strong&gt; Which way (row) is hit
&lt;ul&gt;
&lt;li&gt;Interface type: Valid(UInt(log2Ceil(numWays).W))&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Among, &lt;code&gt;req_pc&lt;/code&gt; interface is Decoupled, meaning it contains valid and ready signals. FTB needs to get the PC before the s1 stage starts, so &lt;code&gt;s0_pc&lt;/code&gt; is sent to the &lt;code&gt;req_pc&lt;/code&gt; interface, &lt;code&gt;s0_fire&lt;/code&gt; signal is connected to the valid signal of &lt;code&gt;req_pc&lt;/code&gt;, and the &lt;code&gt;ready&lt;/code&gt; signal is connected to the pipeline control signal &lt;code&gt;s1_ready&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;When &lt;code&gt;s0_fire&lt;/code&gt; enters the s1 stage, in the next cycle, when &lt;code&gt;s0_fire&lt;/code&gt; is at the same time as &lt;code&gt;s1_fire&lt;/code&gt;, FTBBank has already outputted the readout FTB entry to the &lt;code&gt;read_resp&lt;/code&gt; interface, and calculated &lt;code&gt;read_hits&lt;/code&gt;. However, at this time, because the readout has wasted too much delay, it cannot be outputted in the s1 stage. Therefore, this readout result is saved in an internal register. It will be read out from the register in the s2 and s3 stages to generate the prediction result.&lt;/p&gt;
&lt;h3 id=&#34;ftbbank&#34;&gt;FTBBank&lt;/h3&gt;
&lt;p&gt;FTBBank defines a storage to store all FTB entries. The storage adopts a group-associative structure, with 512 groups (Sets) in total, each group has 4 ways, and can store up to 2048 FTB entries. Besides storing FTB entries, it also stores the tag corresponding to each FTB entry for matching.&lt;/p&gt;
&lt;p&gt;Specifically, the tag is defined as &lt;code&gt;pc[29:10]&lt;/code&gt;, which takes 20 bits from the PC to identify the FTB entry. The PC is divided as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Plain&#34; data-lang=&#34;Plain&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  pc: | ... |&amp;lt;-- tag(20 bits) --&amp;gt;|&amp;lt;-- idx(9 bits) --&amp;gt;|&amp;lt;-- instOffset(1 bit) --&amp;gt;|
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;When reading, provide the group number (idx) to the storage, read out all ways in that group, and then check if there is a way whose tag matches the current tag. If there is a match, it means a hit, and the readout FTB entry is sent out through the &lt;code&gt;read_resp&lt;/code&gt; interface, and the hit way number is sent out through the &lt;code&gt;read_hits&lt;/code&gt; interface.&lt;/p&gt;
&lt;h2 id=&#34;generation-of-prediction-results&#34;&gt;Generation of Prediction Results&lt;/h2&gt;
&lt;p&gt;As mentioned earlier, for the FTB predictor, it needs to provide basic prediction results derived from FTB entries to the s2 and s3 channels. The FTB entries have been read and saved in the s1 stage. In the s2 and s3 stages, they only need to be read out to generate the prediction results. However, one thing to note is to preserve the &lt;code&gt;br_taken_mask&lt;/code&gt; field generated by TAGE-SC in the s2 and s3 prediction results, which provides precise prediction results for conditional branch instructions. For the s1 channel, the FTB predictor does not make any changes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The generation of signals in the s2 and s3 prediction results can refer to the following list:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;hit&lt;/strong&gt; Whether the FTB entry is hit
&lt;ul&gt;
&lt;li&gt;Generation method: The &lt;code&gt;read_hits&lt;/code&gt; signal valid bit from &lt;code&gt;FTBBank&lt;/code&gt; is valid.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;slot_valids&lt;/strong&gt; Slot valid bit, indicating whether each slot in the ftb entry is valid&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;targets&lt;/strong&gt; Jump target address corresponding to each slot&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;offsets&lt;/strong&gt; Instruction offset relative to the start address of the predicted block in each slot&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;is_jal&lt;/strong&gt; Whether the predicted block contains a jal instruction&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;is_jalr&lt;/strong&gt; Whether the predicted block contains a jalr instruction&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;is_call&lt;/strong&gt; Whether the predicted block contains a call instruction&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;is_ret&lt;/strong&gt; Whether the predicted block contains a ret instruction&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;last_may_be_rvi_call&lt;/strong&gt; Signal indicating that the end of the predicted block may be an RVI type call instruction&lt;/li&gt;
&lt;li&gt;**is_br_sharing Whether the last slot (tailSlot) stores a conditional branch instruction signal
&lt;ul&gt;
&lt;li&gt;Generation method**: Export from the corresponding field in the FTB entry&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;fallThroughErr&lt;/strong&gt; Error in the &lt;code&gt;pftAddr&lt;/code&gt; recorded in the FTB entry
&lt;ul&gt;
&lt;li&gt;Generation method: Compare whether the address represented by &lt;code&gt;pftAddr&lt;/code&gt; is greater than the start address of the predicted block. If it is less than, it indicates an error, and this signal is set to valid. This situation may occur when the PC indexes an incorrect FTB entry.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;fallThroughAddr&lt;/strong&gt; End address of the predicted block
&lt;ul&gt;
&lt;li&gt;Generation method: If &lt;code&gt;fallThroughErr&lt;/code&gt; is invalid, it is generated according to &lt;code&gt;pftAddr&lt;/code&gt;. Otherwise, it is set to the start address + prediction width.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;br_taken_mask&lt;/strong&gt; Branch prediction result, each branch (slot) corresponds to a bit, indicating whether the branch is predicted as taken
&lt;ul&gt;
&lt;li&gt;Generation method: Generated based on the &lt;code&gt;always_taken&lt;/code&gt; field in the FTB entry and the indication result of the two-bit saturation counter.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;jalr_target&lt;/strong&gt; Jump target of jalr in this predicted block
&lt;ul&gt;
&lt;li&gt;Generation method: Jump target in the tailSlot of the FTB entry.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ftb-meta&#34;&gt;FTB meta&lt;/h3&gt;
&lt;p&gt;In the third cycle of prediction, the FTB predictor outputs some auxiliary information of this prediction to &lt;code&gt;last_stage_meta&lt;/code&gt; and also sends the read FTB entry to the &lt;code&gt;last_stage_ftrb_entry&lt;/code&gt; interface.&lt;/p&gt;
&lt;p&gt;The FTB meta contains two pieces of information, &lt;code&gt;hit&lt;/code&gt; and &lt;code&gt;writeWay&lt;/code&gt;, indicating whether the prediction hits and in which way it is read. Subsequently, the update channel generates the update information for this prediction, and these two pieces of information are also sent to guide the writing of the updated FTB entry.&lt;/p&gt;
&lt;h2 id=&#34;ftb-update&#34;&gt;FTB Update&lt;/h2&gt;
&lt;p&gt;In the update channel, the pc and the new FTB entry are already specified for us, along with the &lt;code&gt;hit&lt;/code&gt; and &lt;code&gt;writeWay&lt;/code&gt; in the meta information. If &lt;code&gt;hit&lt;/code&gt; in the meta is valid, it means that the FTB entry corresponding to this pc was stored in the memory, and we only need to write it to the corresponding way.&lt;/p&gt;
&lt;p&gt;If it is invalid, it means that there was no storage before, but we do not know whether it is stored now. It is possible that before this update request, the FTB entry corresponding to this pc was written by another update request. Therefore, we still need to send a read request to FTBBank to check if there is a corresponding FTB entry. If it exists, it can be directly written to this position in the next cycle, otherwise, FTBBank will be notified to allocate a new position.&lt;/p&gt;
&lt;p&gt;Therefore, the number of cycles required for updating FTB entries depends on the hit situation.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s first look at how FTBBank handles updates.&lt;/p&gt;
&lt;h3 id=&#34;ftbbank-update&#34;&gt;FTBBank Update&lt;/h3&gt;
&lt;p&gt;FTBBank&amp;rsquo;s update interface is divided into two parts, the update read interface and the update write interface.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;u_req_pc&lt;/strong&gt;: Update read request pc
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Flipped(DecoupledIO(UInt(VAddrBits.W)))&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;update_hits&lt;/strong&gt;: Hit information read out
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Valid(UInt(log2Ceil(numWays).W))&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;update_access&lt;/strong&gt;: There is an update request but the meta information indicates a miss
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Bool()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;update_pc&lt;/strong&gt;: Update write request pc
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;UInt(VAddrBits.W))&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;update_write_data&lt;/strong&gt;: Data to be written in the update request, write when valid
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Flipped(Valid(new FTBEntryWithTag))&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;update_write_way&lt;/strong&gt;: Way index to write in the update request
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;UInt(log2Ceil(numWays).W))&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;update_write_alloc&lt;/strong&gt;: Whether a new FTB entry needs to be allocated (missed before)
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Bool()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;For the update read interface&lt;/strong&gt;, FTBBank obtains the update read request through &lt;code&gt;u_req_pc&lt;/code&gt; signal. This request has a higher priority than the read request during prediction. In the next cycle, FTBBank will output the hit information through the &lt;code&gt;update_hits&lt;/code&gt; interface. &lt;code&gt;update_access&lt;/code&gt; is only used for some internal status judgments of FTBBank.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;For the update write interface&lt;/strong&gt;, FTBBank obtains the pc of the update write request through the &lt;code&gt;update_pc&lt;/code&gt; signal, and when &lt;code&gt;update_write_data&lt;/code&gt; is valid, it writes the data into the corresponding position specified by &lt;code&gt;update_write_way&lt;/code&gt;. If &lt;code&gt;update_write_alloc&lt;/code&gt; is valid, it means that it cannot be directly written to the position specified in the request, but a new position needs to be allocated.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The allocation strategy is as follows&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If all ways are filled, use the pseudo LRU replacement algorithm to select the way to replace&lt;/li&gt;
&lt;li&gt;If there is an empty way, select the empty way.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;update-request-timing&#34;&gt;Update Request Timing&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Meta hit is valid&lt;/strong&gt;: If hit in the update request meta is valid, then we only need to specify the address and data to be written according to the information in the update request, and the writing only takes one cycle.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Meta hit is invalid&lt;/strong&gt;: In this case, after receiving the update request, we connect the pc in the request to the read port of FTBBank. The read port will return the result in the next cycle. Due to timing issues, we save this result and use it in the next cycle. Depending on the hit status in the result, we decide whether to set &lt;code&gt;update_write_alloc&lt;/code&gt; and send a write request. The entire update process takes three cycles.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;interface-list&#34;&gt;Interface List&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;信号类型&lt;/th&gt;
&lt;th&gt;信号位&lt;/th&gt;
&lt;th&gt;信号名&lt;/th&gt;
&lt;th&gt;信号描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;clock&lt;/td&gt;
&lt;td&gt;输入时钟&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;reset&lt;/td&gt;
&lt;td&gt;复位信号&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;[35:0]&lt;/td&gt;
&lt;td&gt;io_reset_vector&lt;/td&gt;
&lt;td&gt;用于reset时，reset s1_pc_dup_0 提供的值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_in_bits_s0_pc_0&lt;/td&gt;
&lt;td&gt;输入位s0_pc 的 第0个复制&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_in_bits_s0_pc_1&lt;/td&gt;
&lt;td&gt;同上 第1个&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_in_bits_s0_pc_2&lt;/td&gt;
&lt;td&gt;同上 第2个&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_in_bits_s0_pc_3&lt;/td&gt;
&lt;td&gt;同上 第3个&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_in_bits_resp_in_0_s2_full_pred_0_br_taken_mask_0&lt;/td&gt;
&lt;td&gt;预测结果输入&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_in_bits_resp_in_0_s2_full_pred_0_br_taken_mask_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_in_bits_resp_in_0_s2_full_pred_1_br_taken_mask_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_in_bits_resp_in_0_s2_full_pred_1_br_taken_mask_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_in_bits_resp_in_0_s2_full_pred_2_br_taken_mask_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_in_bits_resp_in_0_s2_full_pred_2_br_taken_mask_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_in_bits_resp_in_0_s2_full_pred_3_br_taken_mask_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_in_bits_resp_in_0_s2_full_pred_3_br_taken_mask_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_in_bits_resp_in_0_s3_full_pred_0_br_taken_mask_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_in_bits_resp_in_0_s3_full_pred_0_br_taken_mask_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_in_bits_resp_in_0_s3_full_pred_1_br_taken_mask_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_in_bits_resp_in_0_s3_full_pred_1_br_taken_mask_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_in_bits_resp_in_0_s3_full_pred_2_br_taken_mask_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_in_bits_resp_in_0_s3_full_pred_2_br_taken_mask_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_in_bits_resp_in_0_s3_full_pred_3_br_taken_mask_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_in_bits_resp_in_0_s3_full_pred_3_br_taken_mask_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_0_br_taken_mask_0&lt;/td&gt;
&lt;td&gt;s2 阶段输出的完整预测结果&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_0_br_taken_mask_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_0_slot_valids_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_0_slot_valids_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_0_targets_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_0_targets_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_0_jalr_target&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[3:0]&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_0_offsets_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[3:0]&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_0_offsets_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_0_fallThroughAddr&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_0_is_br_sharing&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_0_hit&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_1_br_taken_mask_0&lt;/td&gt;
&lt;td&gt;同上&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_1_br_taken_mask_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_1_slot_valids_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_1_slot_valids_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_1_targets_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_1_targets_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_1_jalr_target&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[3:0]&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_1_offsets_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[3:0]&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_1_offsets_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_1_fallThroughAddr&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_1_is_br_sharing&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_1_hit&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_2_br_taken_mask_0&lt;/td&gt;
&lt;td&gt;同上&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_2_br_taken_mask_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_2_slot_valids_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_2_slot_valids_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_2_targets_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_2_targets_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_2_jalr_target&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[3:0]&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_2_offsets_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[3:0]&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_2_offsets_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_2_fallThroughAddr&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_2_is_jalr&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_2_is_call&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_2_is_ret&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_2_last_may_be_rvi_call&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_2_is_br_sharing&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_2_hit&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_3_br_taken_mask_0&lt;/td&gt;
&lt;td&gt;同上&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_3_br_taken_mask_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_3_slot_valids_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_3_slot_valids_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_3_targets_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_3_targets_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_3_jalr_target&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[3:0]&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_3_offsets_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[3:0]&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_3_offsets_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_3_fallThroughAddr&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_3_fallThroughErr&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_3_is_br_sharing&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s2_full_pred_3_hit&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_0_br_taken_mask_0&lt;/td&gt;
&lt;td&gt;s3 阶段输出的完整预测结果&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_0_br_taken_mask_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_0_slot_valids_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_0_slot_valids_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_0_targets_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_0_targets_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_0_jalr_target&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_0_fallThroughAddr&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_0_fallThroughErr&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_0_is_br_sharing&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_0_hit&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_1_br_taken_mask_0&lt;/td&gt;
&lt;td&gt;同上&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_1_br_taken_mask_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_1_slot_valids_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_1_slot_valids_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_1_targets_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_1_targets_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_1_jalr_target&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_1_fallThroughAddr&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_1_fallThroughErr&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_1_is_br_sharing&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_1_hit&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_2_br_taken_mask_0&lt;/td&gt;
&lt;td&gt;同上&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_2_br_taken_mask_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_2_slot_valids_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_2_slot_valids_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_2_targets_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_2_targets_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_2_jalr_target&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_2_fallThroughAddr&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_2_fallThroughErr&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_2_is_jalr&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_2_is_call&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_2_is_ret&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_2_is_br_sharing&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_2_hit&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_3_br_taken_mask_0&lt;/td&gt;
&lt;td&gt;同上&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_3_br_taken_mask_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_3_slot_valids_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_3_slot_valids_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_3_targets_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_3_targets_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_3_jalr_target&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[3:0]&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_3_offsets_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[3:0]&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_3_offsets_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_3_fallThroughAddr&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_3_fallThroughErr&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_3_is_br_sharing&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_s3_full_pred_3_hit&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[222:0]&lt;/td&gt;
&lt;td&gt;io_out_last_stage_meta&lt;/td&gt;
&lt;td&gt;最后一个阶段输出的 meta 信息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_last_stage_ftb_entry_valid&lt;/td&gt;
&lt;td&gt;最后一个阶段输出的 FTB 项&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[3:0]&lt;/td&gt;
&lt;td&gt;io_out_last_stage_ftb_entry_brSlots_0_offset&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[11:0]&lt;/td&gt;
&lt;td&gt;io_out_last_stage_ftb_entry_brSlots_0_lower&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[1:0]&lt;/td&gt;
&lt;td&gt;io_out_last_stage_ftb_entry_brSlots_0_tarStat&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_last_stage_ftb_entry_brSlots_0_sharing&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_last_stage_ftb_entry_brSlots_0_valid&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[3:0]&lt;/td&gt;
&lt;td&gt;io_out_last_stage_ftb_entry_tailSlot_offset&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[19:0]&lt;/td&gt;
&lt;td&gt;io_out_last_stage_ftb_entry_tailSlot_lower&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[1:0]&lt;/td&gt;
&lt;td&gt;io_out_last_stage_ftb_entry_tailSlot_tarStat&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_last_stage_ftb_entry_tailSlot_sharing&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_last_stage_ftb_entry_tailSlot_valid&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;[3:0]&lt;/td&gt;
&lt;td&gt;io_out_last_stage_ftb_entry_pftAddr&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_last_stage_ftb_entry_carry&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_last_stage_ftb_entry_isCall&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_last_stage_ftb_entry_isRet&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_last_stage_ftb_entry_isJalr&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_last_stage_ftb_entry_last_may_be_rvi_call&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_last_stage_ftb_entry_always_taken_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_out_last_stage_ftb_entry_always_taken_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_ctrl_btb_enable&lt;/td&gt;
&lt;td&gt;使能信号&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_s0_fire_0&lt;/td&gt;
&lt;td&gt;s0 阶段流水线控制信号&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_s0_fire_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_s0_fire_2&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_s0_fire_3&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;output&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_s1_ready&lt;/td&gt;
&lt;td&gt;s1 阶段流水线控制信号&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_s1_fire_0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_s1_fire_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_s1_fire_2&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_s1_fire_3&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_s2_fire_0&lt;/td&gt;
&lt;td&gt;s2 阶段流水线控制信号&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_s2_fire_1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_s2_fire_2&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_s2_fire_3&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_update_valid&lt;/td&gt;
&lt;td&gt;更新有效性&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;[40:0]&lt;/td&gt;
&lt;td&gt;io_update_bits_pc&lt;/td&gt;
&lt;td&gt;传回的预测块pc（用于指示更新的预测块）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_valid&lt;/td&gt;
&lt;td&gt;是否启用&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;[3:0]&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_brSlots_0_offset&lt;/td&gt;
&lt;td&gt;solt 0 中分支指令相对于地址块起始pc的偏移&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;[11:0]&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_brSlots_0_lower&lt;/td&gt;
&lt;td&gt;跳转目标地址的低位&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;[1:0]&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_brSlots_0_tarStat&lt;/td&gt;
&lt;td&gt;跳转后的 pc 高位是否进退位&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_brSlots_0_sharing&lt;/td&gt;
&lt;td&gt;无条件跳转指令槽中存储条件分支指令&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_brSlots_0_valid&lt;/td&gt;
&lt;td&gt;是否启用&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;[3:0]&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_tailSlot_offset&lt;/td&gt;
&lt;td&gt;solt 1 中分支指令相对于地址块起始pc的偏移&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;[19:0]&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_tailSlot_lower&lt;/td&gt;
&lt;td&gt;跳转目标地址的低位&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;[1:0]&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_tailSlot_tarStat&lt;/td&gt;
&lt;td&gt;跳转后的 pc 高位是否进退位&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_tailSlot_sharing&lt;/td&gt;
&lt;td&gt;无条件跳转指令槽中存储条件分支指令&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_tailSlot_valid&lt;/td&gt;
&lt;td&gt;是否启用&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;[3:0]&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_pftAddr&lt;/td&gt;
&lt;td&gt;Partial Fallthrough Addr 如果预测块中没有跳转，那么程序将会顺序执行到达的地址，预测块的结束地址。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_carry&lt;/td&gt;
&lt;td&gt;pc+pft时是否产生进位&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_isCall&lt;/td&gt;
&lt;td&gt;是否是函数调用&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_isRet&lt;/td&gt;
&lt;td&gt;是否是函数返回&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_isJalr&lt;/td&gt;
&lt;td&gt;是否是 jalr 指令&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_last_may_be_rvi_call&lt;/td&gt;
&lt;td&gt;最后一个指令槽存储的可能是 rvi 的 call 指令&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_always_taken_0&lt;/td&gt;
&lt;td&gt;是否预测为总是跳转&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_update_bits_ftb_entry_always_taken_1&lt;/td&gt;
&lt;td&gt;是否预测为总是跳转&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;io_update_bits_old_entry&lt;/td&gt;
&lt;td&gt;是否是旧的 FTB 项&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;input&lt;/td&gt;
&lt;td&gt;[222:0]&lt;/td&gt;
&lt;td&gt;io_update_bits_meta&lt;/td&gt;
&lt;td&gt;meta 信息&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: RAS Branch Predictor</title>
      <link>https://xs-mlvp.github.io/xs-bpu/en/docs/modules/05_ras/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://xs-mlvp.github.io/xs-bpu/en/docs/modules/05_ras/</guid>
      <description>
        
        
        &lt;h2 id=&#34;ras介绍&#34;&gt;RAS介绍&lt;/h2&gt;
&lt;p&gt;RAS stands for &amp;ldquo;Return Address Stack.&amp;rdquo; It helps determine branch behavior in programs by tracking return addresses. As previously mentioned, there are many branches in a program: if/else, switch/case, while/for loop, iteration, call/return, etc. The RAS branch predictor specifically targets call/return types.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;_add&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;a&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;b&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#a40000&#34;&gt;?&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;)&lt;/span&gt;  &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;b&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#a40000&#34;&gt;?&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;b&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;add&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;a&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;b&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;b&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;sub&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;a&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;b&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;b&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;main&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;b&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;c&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;add&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;a&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;b&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#000&#34;&gt;d&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;sub&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;a&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;b&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;As shown above, the main function calls add and sub, and add calls the function _add. In this process, each call&amp;rsquo;s jump address and return address are fixed, and the return address can be obtained at the time of the call. The function call process is a &amp;ldquo;stack push and pop&amp;rdquo; process, so branch prediction can be performed using a &amp;ldquo;stack&amp;rdquo; structure: each time a call instruction is encountered, the current PC+4 (compressed instructions and regular instructions have different offsets) is pushed onto the stack; when a return instruction is encountered, a pop operation is performed, and the address obtained is the target jump address. In the block-based BPU, RAS cannot know whether the current block is a call or ret, so it relies on other predictors, using the results of previous predictors for RAS operations.&lt;/p&gt;
&lt;p&gt;Specifically, in Xiangshan&amp;rsquo;s RAS predictor, at the s2 stage, it needs to determine whether the previous stage&amp;rsquo;s s2 output predicts a call or ret (i.e., the input signal io.s2_full_pred.hit_taken_on_call/ret is valid). If it&amp;rsquo;s a call, it pushes the subsequent instruction address onto the stack; if it&amp;rsquo;s a ret, it pops the address from the stack as the prediction result. Because in the BPU predictor, the result obtained at the s3 stage is assumed to be better than the s2 stage, the RAS predictor needs to check at the s3 stage. If the previous stage&amp;rsquo;s s3 prediction result is inconsistent with s2, the s3 result is taken, and it needs to determine whether to cancel or complete the stack operations of the previous s2 stage as needed. For example, if the s2 stage predicted a call instruction and performed a push operation, but s3 predicted a regular branch instruction with no need for any operation, the push must be canceled; if s2 predicted a regular branch instruction and s3 predicted a call, a push operation must be performed to complete.&lt;/p&gt;
&lt;h2 id=&#34;ras-stack-operations&#34;&gt;RAS Stack Operations&lt;/h2&gt;
&lt;p&gt;In RAS design, function return addresses are predicted using a stack. Ideally, this section assumes that RAS can be backed up at any time, with the stack top pointer represented by sp and the predicted address represented by paddr. The basic RAS operations are as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;h3 id=&#34;push&#34;&gt;PUSH&lt;/h3&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Since predictions can be wrong, the current stack state needs to be backed up (often referred to as a &amp;ldquo;snapshot&amp;rdquo; in software; this term is also used in subsequent content). When encountering a call instruction, get the return address of the call instruction addr = current pc + 4 (if it&amp;rsquo;s a compressed instruction, addr = pc+2), then push onto the stack: sp = addr; sp += 1.&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;
&lt;h3 id=&#34;pop&#34;&gt;POP&lt;/h3&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For the same reason, take a snapshot of the current stack, marked as s. When encountering a ret instruction, the predicted jump address is paddr = sp, then pop: sp = sp - 1. Take a snapshot of the current stack, marked as s.&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;
&lt;h3 id=&#34;redirect-operation&#34;&gt;Redirect Operation&lt;/h3&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Since the BPU predicts program branches, there are &amp;ldquo;correct predictions&amp;rdquo; and &amp;ldquo;wrong predictions.&amp;rdquo; When the CPU backend detects a branch prediction error, it performs a redirect operation, informing the BPU where the prediction was wrong and what the correct result is. During redirection, the RAS module receives the correct branch and the RAS stack information at the time of prediction. Depending on the type of correct branch instruction, the following snapshot recovery situations arise:&lt;/p&gt;
&lt;p&gt;(1) The previously predicted instruction is actually a call instruction, and the push operation is executed based on the addr address provided in the redirect.
(2) The previously predicted instruction is actually a ret instruction, and the pop operation is executed.&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;
&lt;h3 id=&#34;commit-operation&#34;&gt;Commit Operation&lt;/h3&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The commit operation is when the backend informs the frontend that the previous prediction was correct. Ideally, the RAS predictor doesn&amp;rsquo;t need to perform any operations at this time.&lt;/p&gt;
&lt;h2 id=&#34;implementation-of-ras-in-kunming-lake&#34;&gt;Implementation of RAS in Kunming Lake&lt;/h2&gt;
&lt;p&gt;In actual circuit design, an infinitely large stack is impossible, and constant backups are not feasible. Therefore, in Kunming Lake&amp;rsquo;s RAS implementation, the problems and solutions are as follows:&lt;/p&gt;
&lt;h3 id=&#34;how-to-obtain-ras-stack-snapshots-for-each-prediction&#34;&gt;&lt;strong&gt;How to obtain RAS stack snapshots for each prediction?&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;To achieve the function of taking snapshots of the RAS stack, Kunming Lake adopts a &lt;strong&gt;linked representation&lt;/strong&gt; based on a circular array. The design is as follows:&lt;/p&gt;
&lt;image src=&#34;Linked_RAS.png&#34; width=&#34;800px&#34;&gt;
&lt;p&gt;As shown above, a circular array is used for data management. The circular array has a starting address marked as BOS and a tail pointer marked as TOSW. The data between them are valid, and the data outside are free. Within the valid data, a linked structure represents the &amp;ldquo;RAS stack,&amp;rdquo; where each stack element records the number of its previous data. When performing stack operations, the corresponding previous element can be obtained through this number. The RAS stack&amp;rsquo;s bottom pointer shares the BOS. In the initial state S in the figure, the RAS stack elements are 0, 1, 3, 5. Element 5 records the position of its previous element 3, and element 3 records the position of its previous element 1. When a push operation is needed, the RAS stack top pointer TOSR = TOSW, the new element is stored at the new TOSR position 7, and the position of its previous element 5 is recorded in the new element, then TOSW is moved back (TOSW = TOSW+1). When a pop operation is performed, the RAS stack top pointer TOSR moves to the previous element&amp;rsquo;s position 3 based on the index saved in the stack top element. Therefore, under the condition that the stack does not overflow, the above RAS stack always allocates new data on the array through TOSW during normal Push/Pop operations, so all process states and intermediate data are saved. So, to restore to the state S, it only needs to reset the corresponding stack pointers. Therefore, in each prediction, the corresponding stack pointers (BOS, TOSR, TOSW) also need to be saved in the prediction result for later restoration in case of redirection. The advantage of this structure is that it can save complete process data, but frequent push operations can lead to large space resource consumption.&lt;/p&gt;
&lt;h3 id=&#34;chain-ra-storage-space-waste&#34;&gt;&lt;strong&gt;Chain RA storage space waste?&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Since the prediction result is correct after commit, the stack will not roll back. When the RAS predictor receives the commit message of the prediction block &amp;ldquo;P,&amp;rdquo; it will no longer receive the redirect message of block P, so the snapshot taken during the push operation for block P will not be used again. Therefore, the RAS stack elements can be categorized, with uncommitted elements stored in a &amp;ldquo;linked&amp;rdquo; structure and committed elements stored in a regular stack structure (the original RAS stack is split into two parts: the uncommitted part stored in a snapshot-saving linked structure and the committed part stored in a regular stack structure). The optimized RAS structure is shown below:&lt;/p&gt;
&lt;image src=&#34;RAS_Arch.png&#34; width=&#34;800px&#34;&gt;
&lt;p&gt;As shown above, based on the normal call/ret predictions and commit call/ret, the original RAS stack can be split into two independent stacks, called the &amp;ldquo;speculative stack&amp;rdquo; (spec_stack, linked structure) and the &amp;ldquo;commit stack&amp;rdquo; (commit_stack, regular structure). Due to the change in stack structure, the specific Pop/Push operations are as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Encounter normal call and ret:
(1) The call predicted by the prediction block is correct, and a push operation is performed on the spec_stack, specifically the linked stack Push process mentioned above.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;(2) The ret predicted by the prediction block is correct, and the stack top of the spec_stack is used as the prediction value, then a pop operation is performed. If the spec_stack is empty, the stack top element of the commit_stack is used as the prediction result (no pop operation is performed).&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Commit operation:
(1) The FTQ execution result is call correct, and a regular push operation is performed on the commit_stack.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;(2) The FTQ execution result is ret correct, and a regular pop operation is performed on the commit_stack.&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Redirect operation:
(1) Obtain the stack pointers (BOS, TOSR, TOSW, ssp) from the redirect message during the previous prediction and cover the current pointer values to complete the speculative stack rollback.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;(2) This operation does not affect the commit stack.&lt;/p&gt;
&lt;h3 id=&#34;how-to-handle-when-the-s3-prediction-result-is-inconsistent-with-s2-at-the-input-end&#34;&gt;&lt;strong&gt;How to handle when the S3 prediction result is inconsistent with S2 at the input end?&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Since the S3 result is assumed to be better than S2, the RAS stack needs to be repaired again in case of inconsistency. The specific inconsistency and corresponding repair operations are shown in the table below:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;S2 Pred. Res.&lt;/th&gt;
&lt;th&gt;S3 Pred. Res.&lt;/th&gt;
&lt;th&gt;Repair Operation&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;push&lt;/td&gt;
&lt;td&gt;keep&lt;/td&gt;
&lt;td&gt;pop&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;keep&lt;/td&gt;
&lt;td&gt;pop&lt;/td&gt;
&lt;td&gt;pop&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;pop&lt;/td&gt;
&lt;td&gt;keep&lt;/td&gt;
&lt;td&gt;push&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;keep&lt;/td&gt;
&lt;td&gt;push&lt;/td&gt;
&lt;td&gt;push&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;S2 and S3 operations do not exist, pop/push or push/pop scenarios (Why not exist?)&lt;/p&gt;
&lt;h2 id=&#34;other-optimizations&#34;&gt;Other Optimizations&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Each element in the RAS stack has a counter, which is used to save repeated values (for recursive calls). For example, when the address pushed for the first time is 0xff00, and the address pushed for the second time is also 0xff00, only the counter of the top element of the stack needs to be incremented, and there is no need to actually push the address onto the stack.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;interface-description&#34;&gt;Interface Description&lt;/h2&gt;
&lt;p&gt;In the RAS predictor, the core component is the &lt;strong&gt;RASStack&lt;/strong&gt;, with the following interface:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;接口名称&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;功能描述&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;接口名称&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;功能描述&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;in.spec_push_valid&lt;/td&gt;
&lt;td&gt;预测有Call指令，Spec压栈&lt;/td&gt;
&lt;td&gt;in.s2_fire&lt;/td&gt;
&lt;td&gt;s2信号有效&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;in.spec_pop_valid&lt;/td&gt;
&lt;td&gt;预测有Ret指令，Spec出栈&lt;/td&gt;
&lt;td&gt;in.s3_fire&lt;/td&gt;
&lt;td&gt;s3信号有效&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;in.spec_push_addr&lt;/td&gt;
&lt;td&gt;Ret地址&lt;/td&gt;
&lt;td&gt;in.s3_cancel&lt;/td&gt;
&lt;td&gt;s3和s2的预测结果不一样，需要撤销s2的操作&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;out.spec_pop_addr&lt;/td&gt;
&lt;td&gt;RAS的栈顶数据&lt;/td&gt;
&lt;td&gt;in.s3_meta&lt;/td&gt;
&lt;td&gt;s3需要的s2时的现场信息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;out.ssp&lt;/td&gt;
&lt;td&gt;commit栈顶指针&lt;/td&gt;
&lt;td&gt;in.s3_missed_pop&lt;/td&gt;
&lt;td&gt;s3判断需要再次进行pop&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;out.sctr&lt;/td&gt;
&lt;td&gt;commit栈顶重复元素计数器&lt;/td&gt;
&lt;td&gt;in.s3_missed_push&lt;/td&gt;
&lt;td&gt;s3判断需要再次进行push&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;out.nsp&lt;/td&gt;
&lt;td&gt;commit栈顶，会被ssp覆盖&lt;/td&gt;
&lt;td&gt;in.s3_pushAddr&lt;/td&gt;
&lt;td&gt;需要再次push时的地址&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;out.TOSR&lt;/td&gt;
&lt;td&gt;spec栈栈顶指针&lt;/td&gt;
&lt;td&gt;in.redirect_valid&lt;/td&gt;
&lt;td&gt;需要重定向&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;out.TOSW&lt;/td&gt;
&lt;td&gt;spec栈数据分配指针&lt;/td&gt;
&lt;td&gt;in.redirect_isCall&lt;/td&gt;
&lt;td&gt;真实执行情况是Call&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;out.BOS&lt;/td&gt;
&lt;td&gt;spec栈栈低指针&lt;/td&gt;
&lt;td&gt;in.redirect_isRet&lt;/td&gt;
&lt;td&gt;真实执行情况是Return&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;in.commit_push_valid&lt;/td&gt;
&lt;td&gt;push操作正确&lt;/td&gt;
&lt;td&gt;in.redirect_meta_ssp&lt;/td&gt;
&lt;td&gt;之前预测时的现场信息ssp&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;in.commit_pop_valid&lt;/td&gt;
&lt;td&gt;FTQ执行结果为Call正确&lt;/td&gt;
&lt;td&gt;in.redirect_meta_sctr&lt;/td&gt;
&lt;td&gt;之前预测时的现场信息sctr&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;in.commit_push_addr&lt;/td&gt;
&lt;td&gt;更新信息中的Ret地址&lt;/td&gt;
&lt;td&gt;in.redirect_meta_TOSW&lt;/td&gt;
&lt;td&gt;之前预测时的现场信息TOSW&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;in.commit_meta_TOSW&lt;/td&gt;
&lt;td&gt;更新信息中的TOSW&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;in.redirect_meta_TOSR&lt;/td&gt;
&lt;td&gt;之前预测时的现场信息TOSR&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;in.commit_meta_TOSR&lt;/td&gt;
&lt;td&gt;更新信息中的TOSR&lt;/td&gt;
&lt;td&gt;in.redirect_meta_NOS&lt;/td&gt;
&lt;td&gt;之前预测时的现场信息NOS&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;in.commit_meta_ssp&lt;/td&gt;
&lt;td&gt;更新信息中的现场信息SSP&lt;/td&gt;
&lt;td&gt;in.redirect_callAddr&lt;/td&gt;
&lt;td&gt;重定向地址&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;in.commit_meta_sctr&lt;/td&gt;
&lt;td&gt;更新信息中的现场信息SCTR&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The relationship between the RASStack module and the BasePredictor interface is as follows:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;stack接口&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;转换过程&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;描述&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;s.spec_push_valid&lt;/td&gt;
&lt;td&gt;io.s2_fire(2) &amp;amp;&amp;amp; s2_full_pred.hit_taken_on_call &amp;amp;&amp;amp; !io.s3_redirect(2)&lt;/td&gt;
&lt;td&gt;s2输入有效，且上级预测为call跳转&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;s.spec_pop_valid&lt;/td&gt;
&lt;td&gt;io.s2_fire(2) &amp;amp;&amp;amp; s2_full_pred.hit_taken_on_ret  &amp;amp;&amp;amp; !io.s3_redirect(2)&lt;/td&gt;
&lt;td&gt;s2输入有效，且上级预测为ret跳转&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;s.spec_push_addr&lt;/td&gt;
&lt;td&gt;s2_full_pred.fallThroughAddr + Mux(s2_full_pred.last_may_be_rvi_call, 2.U, 0.U)&lt;/td&gt;
&lt;td&gt;上级预测器s2预测的fallThroughAddr（即PC+2），判断是否压缩指令是否需要 +2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;s.redirect_isCall&lt;/td&gt;
&lt;td&gt;redirect.bits.level === 0.U &amp;amp;&amp;amp; recover_cfi.pd.isCall&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;s.redirect_isRet&lt;/td&gt;
&lt;td&gt;redirect.bits.level === 0.U &amp;amp;&amp;amp; recover_cfi.pd.isRet&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;s.redirect_meta_*&lt;/td&gt;
&lt;td&gt;redirect.bits.cfiUpdate.*&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;s.commit_push_valid&lt;/td&gt;
&lt;td&gt;io.update.is_call_taken&lt;/td&gt;
&lt;td&gt;call指令预测正确&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;s.commit_push_valid&lt;/td&gt;
&lt;td&gt;io.update.is_ret_taken&lt;/td&gt;
&lt;td&gt;ret指令预测正确&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;s.commit_push_addr&lt;/td&gt;
&lt;td&gt;update.ftb_entry.getFallThrough(update.pc) + Mux(update.ftb_entry.last_may_be_rvi_call, 2.U, 0.U)&lt;/td&gt;
&lt;td&gt;根据是否为压缩指令，进行地址+2或者+0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;s.commit_meta_*&lt;/td&gt;
&lt;td&gt;io.update.bits.meta.asTypeOf(new RASMeta)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;io.out.last_stage_spec_info.*&lt;/td&gt;
&lt;td&gt;s3_meta.*&lt;/td&gt;
&lt;td&gt;s3_meta = RegEnable(s2_meta, io.s2_fire(2))由s2_meta延迟一怕得到&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;io.out.last_stage_meta&lt;/td&gt;
&lt;td&gt;s3_meta&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;io.out.s2.full_pred.*.jalr_target&lt;/td&gt;
&lt;td&gt;:=stack.spec_pop_addr&lt;/td&gt;
&lt;td&gt;预测地址（栈顶地址，只预测ret）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;io.out.s3.full_pred.*.jalr_target&lt;/td&gt;
&lt;td&gt;:=RegEnable(stack.spec_pop_addr, io.s2_fire(2))&lt;/td&gt;
&lt;td&gt;由s2延迟一拍得到&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;io.out.s2/3.full_pred.targets.last&lt;/td&gt;
&lt;td&gt;:=Mux(s2/3_is_jalr, s2/3_jalr_target, s2/3_last_target_in)&lt;/td&gt;
&lt;td&gt;如果时call执行，更新targets.last的结果&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;timing-description&#34;&gt;Timing Description&lt;/h2&gt;
&lt;p&gt;In RAS, there are only 2 stages, S2 and S3.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Main tasks in S2&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Based on the S2 prediction result of the previous predictor, complete the prediction through the push/pop process and obtain the result spec_pop_addr.&lt;/li&gt;
&lt;li&gt;Perform update operations based on commit signal.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Main tasks in S3&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Based on the prediction result in the previous predictor S3 and the operations in S2, determine whether to undo the Pop/Push operation. The predictor assumes that the S3 prediction result is better than S2. If S2 and S3 predictions are inconsistent, the RAS predictor accepts the S3 result for stack operation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The prediction process in S3 is the same as in S2, but the data is different.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Perform redirection operations (redirection information obtained from the previous cycle).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Since the RASStack appears to complete its tasks within a cycle, data bypassing is needed inside the stack to cache data for processing.&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>
